<!DOCTYPE html>
<html lang="ru" data-vue-meta="%7B%22lang%22:%7B%22ssr%22:%22ru%22%7D%7D">
<head >
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width,initial-scale=1.0,viewport-fit=cover">
  <title>GPFS. Часть 2. Эксплуатация GPFS кластера / Блог компании Оверсан-Скалакси / Хабр</title>
  <style>
    /* cyrillic-ext */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveSxf6TF0.woff2) format('woff2');
      unicode-range: U+0460-052F, U+1C80-1C88, U+20B4, U+2DE0-2DFF, U+A640-A69F, U+FE2E-FE2F;
    }

    /* cyrillic */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveQhf6TF0.woff2) format('woff2');
      unicode-range: U+0400-045F, U+0490-0491, U+04B0-04B1, U+2116;
    }

    /* latin-ext */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveSBf6TF0.woff2) format('woff2');
      unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
    }

    /* latin */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveRhf6.woff2) format('woff2');
      unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
    }
  </style>
  <link rel="preload" href="https://assets.habr.com/habr-web/css/chunk-vendors.0f7bdd8f.css" as="style"><link rel="preload" href="https://assets.habr.com/habr-web/js/chunk-vendors.670ab961.js" as="script"><link rel="preload" href="https://assets.habr.com/habr-web/css/app.01bb2993.css" as="style"><link rel="preload" href="https://assets.habr.com/habr-web/js/app.76acc47b.js" as="script"><link rel="preload" href="https://assets.habr.com/habr-web/css/chunk-f458c7c4.e48e8f79.css" as="style"><link rel="preload" href="https://assets.habr.com/habr-web/js/chunk-f458c7c4.6e221df6.js" as="script"><link rel="preload" href="https://assets.habr.com/habr-web/css/page-article.6d4ce2a5.css" as="style"><link rel="preload" href="https://assets.habr.com/habr-web/js/page-article.edfb668d.js" as="script">
  <link rel="stylesheet" href="https://assets.habr.com/habr-web/css/chunk-vendors.0f7bdd8f.css"><link rel="stylesheet" href="https://assets.habr.com/habr-web/css/app.01bb2993.css"><link rel="stylesheet" href="https://assets.habr.com/habr-web/css/chunk-f458c7c4.e48e8f79.css"><link rel="stylesheet" href="https://assets.habr.com/habr-web/css/page-article.6d4ce2a5.css">
  <script>window.i18nFetch = new Promise((res, rej) => {
          const xhr = new XMLHttpRequest();
          xhr.open('GET', '/js/i18n/ru-compiled.4f7c12b4e1b1b4c0e44ef6f9f33b1f9f.json');
          xhr.responseType = 'json';
          xhr.onload = function(e) {
            if (this.status === 200) {
              res({ru: xhr.response});
            } else {
              rej(e);
            }
          };
          xhr.send();
        });</script>
  
  <script data-vue-meta="ssr" src="/js/ads.js" onload="window['zhY4i4nJ9K'] = true" data-vmid="checkad"></script><script data-vue-meta="ssr" type="application/ld+json" data-vmid="ldjson-schema">{"@context":"http:\/\/schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/habr.com\/ru\/company\/scalaxy\/blog\/83353\/"},"headline":"GPFS. Часть 2. Эксплуатация GPFS кластера","datePublished":"2010-02-08T14:05:01+03:00","dateModified":"2010-03-29T22:52:32+04:00","author":{"@type":"Person","name":"Алексей"},"publisher":{"@type":"Organization","name":"Habr","logo":{"@type":"ImageObject","url":"https:\/\/habrastorage.org\/webt\/a_\/lk\/9m\/a_lk9mjkccjox-zccjrpfolmkmq.png"}},"description":"В продолжение моего предыдущего поста о настройке GPFS-кластера, как и обещал, перехожу к описанию весьма распространённых ситуаций, с которыми можно столкнуться...","url":"https:\/\/habr.com\/ru\/company\/scalaxy\/blog\/83353\/#post-content-body","about":["c_scalaxy"],"image":["http:\/\/img23.imageshack.us\/img23\/8917\/ibmv.gif"]}</script>
  <script src="//www.googletagservices.com/tag/js/gpt.js" async></script>
  <style>.grecaptcha-badge{visibility: hidden;}</style>
  <meta name="habr-version" content="2.47.1">
  
  <meta data-vue-meta="ssr" property="fb:app_id" content="444736788986613"><meta data-vue-meta="ssr" property="fb:pages" content="472597926099084"><meta data-vue-meta="ssr" name="twitter:card" content="summary_large_image"><meta data-vue-meta="ssr" name="twitter:site" content="@habr_eng"><meta data-vue-meta="ssr" property="og:title" content="GPFS. Часть 2. Эксплуатация GPFS кластера" data-vmid="og:title"><meta data-vue-meta="ssr" name="twitter:title" content="GPFS. Часть 2. Эксплуатация GPFS кластера" data-vmid="twitter:title"><meta data-vue-meta="ssr" name="aiturec:title" content="GPFS. Часть 2. Эксплуатация GPFS кластера" data-vmid="aiturec:title"><meta data-vue-meta="ssr" name="description" content="В продолжение моего предыдущего поста о настройке GPFS-кластера, как и обещал, перехожу к описанию весьма распространённых ситуаций, с которыми можно столкнуться при работе с..." data-vmid="description"><meta data-vue-meta="ssr" itemprop="description" content="В продолжение моего предыдущего поста о настройке GPFS-кластера, как и обещал, перехожу к описанию весьма распространённых ситуаций, с которыми можно столкнуться при работе с..." data-vmid="description:itemprop"><meta data-vue-meta="ssr" property="og:description" content="В продолжение моего предыдущего поста о настройке GPFS-кластера, как и обещал, перехожу к описанию весьма распространённых ситуаций, с которыми можно столкнуться при работе с..." data-vmid="og:description"><meta data-vue-meta="ssr" name="twitter:description" content="В продолжение моего предыдущего поста о настройке GPFS-кластера, как и обещал, перехожу к описанию весьма распространённых ситуаций, с которыми можно столкнуться при работе с..." data-vmid="twitter:description"><meta data-vue-meta="ssr" property="aiturec:description" content="В продолжение моего предыдущего поста о настройке GPFS-кластера, как и обещал, перехожу к описанию весьма распространённых ситуаций, с которыми можно столкнуться при работе с..." data-vmid="aiturec:description"><meta data-vue-meta="ssr" itemprop="image" content="https://habr.com/share/publication/83353/501bbfd6798b8ee4103d4d6c2e293789/" data-vmid="image:itemprop"><meta data-vue-meta="ssr" property="og:image" content="https://habr.com/share/publication/83353/501bbfd6798b8ee4103d4d6c2e293789/" data-vmid="og:image"><meta data-vue-meta="ssr" property="aiturec:image" content="https://habr.com/share/publication/83353/501bbfd6798b8ee4103d4d6c2e293789/" data-vmid="aiturec:image"><meta data-vue-meta="ssr" name="twitter:image" content="https://habr.com/share/publication/83353/501bbfd6798b8ee4103d4d6c2e293789/" data-vmid="twitter:image"><meta data-vue-meta="ssr" property="vk:image" content="https://habr.com/share/publication/83353/501bbfd6798b8ee4103d4d6c2e293789/" data-vmid="vk:image"><meta data-vue-meta="ssr" property="aiturec:item_id" content="83353" data-vmid="aiturec:item_id"><meta data-vue-meta="ssr" property="aiturec:datetime" content="2010-02-08T11:05:01.000Z" data-vmid="aiturec:datetime"><meta data-vue-meta="ssr" property="og:type" content="article" data-vmid="og:type"><meta data-vue-meta="ssr" property="og:locale" content="ru_RU" data-vmid="og:locale"><meta data-vue-meta="ssr" property="og:image:width" content="1200" data-vmid="og:image:width"><meta data-vue-meta="ssr" property="og:image:height" content="630" data-vmid="og:image:height">
  <link data-vue-meta="ssr" href="https://habr.com/ru/rss/post/83353/?fl=ru" type="application/rss+xml" title="" rel="alternate" name="rss"><link data-vue-meta="ssr" href="https://habr.com/ru/company/scalaxy/blog/83353/" rel="canonical" data-vmid="canonical"><link data-vue-meta="ssr" data-vmid="hreflang"><link data-vue-meta="ssr" image_src="image" href="https://habr.com/share/publication/83353/501bbfd6798b8ee4103d4d6c2e293789/" data-vmid="image:href">
  <meta name="apple-mobile-web-app-status-bar-style" content="#303b44">
  <meta name="msapplication-TileColor" content="#629FBC">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="mobile-web-app-capable" content="yes">
  <link
    rel="shortcut icon"
    type="image/png"
    sizes="16x16"
    href="https://assets.habr.com/habr-web/img/favicons/favicon-16.png"
  >
  <link
    rel="shortcut icon"
    type="image/png"
    sizes="32x32"
    href="https://assets.habr.com/habr-web/img/favicons/favicon-32.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="76x76"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-76.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="120x120"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-120.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="152x152"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-152.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="180x180"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-180.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="256x256"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-256.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 320px) and (device-height: 568px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1136x640.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2436x1125.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1792x828.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_828x1792.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1334x750.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1242x2668.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2208x1242.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1125x2436.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1242x2208.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2732x2048.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2688x1242.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2224x1668.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_750x1334.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2048x2732.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2388x1668.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1668x2224.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 320px) and (device-height: 568px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_640x1136.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1668x2388.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2048x1536.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1536x2048.png"
  >
  <link
    rel="mask-icon"
    color="#77a2b6"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-120.svg"
  >
  <link
    crossorigin="use-credentials"
    href="/manifest.webmanifest"
    rel="manifest"
  >
</head>
<body>


<div id="app" data-server-rendered="true" data-async-called="true"><div class="tm-layout__wrapper"><!----> <div></div> <!----> <header class="tm-header"><div class="tm-page-width"><div class="tm-header__container"><!----> <span class="tm-header__logo-wrap"><a href="/ru/" class="tm-header__logo tm-header__logo_ru"><svg height="16" width="16" class="tm-svg-img tm-header__icon"><title>Хабр</title> <use xlink:href="/img/habr-logo-ru.svg#logo"></use></svg></a> <span class="tm-header__beta-sign" style="display:none;">β</span></span> <div class="tm-dropdown tm-header__projects"><div class="tm-dropdown__head"><button class="tm-header__dropdown-toggle"><svg height="16" width="16" class="tm-svg-img tm-header__icon tm-header__icon_dropdown"><title>Открыть список</title> <use xlink:href="/img/megazord-v24.cee85629.svg#arrow-down"></use></svg></button></div> <!----></div> <a href="/ru/sandbox/start/" class="tm-header__become-author-btn">
              Как стать автором
            </a> <div class="tm-feature tm-header__feature tm-feature_variant-inline"><!----></div> <!----> <!----></div></div></header> <div class="tm-layout"><div class="tm-page-progress-bar"></div> <div data-menu-sticky="true" class="tm-base-layout__header tm-base-layout__header_is-sticky"><div class="tm-page-width"><div class="tm-base-layout__header-wrapper"><div class="tm-main-menu"><div class="tm-main-menu__section"><nav class="tm-main-menu__section-content"><!----> <a href="/ru/all/" class="tm-main-menu__item">
        Все потоки
      </a> <a href="/ru/flows/develop/" class="tm-main-menu__item">
          Разработка
        </a><a href="/ru/flows/admin/" class="tm-main-menu__item">
          Администрирование
        </a><a href="/ru/flows/design/" class="tm-main-menu__item">
          Дизайн
        </a><a href="/ru/flows/management/" class="tm-main-menu__item">
          Менеджмент
        </a><a href="/ru/flows/marketing/" class="tm-main-menu__item">
          Маркетинг
        </a><a href="/ru/flows/popsci/" class="tm-main-menu__item">
          Научпоп
        </a></nav></div></div> <div class="tm-header-user-menu tm-base-layout__user-menu"><a href="/ru/search/" class="tm-header-user-menu__item tm-header-user-menu__search"><svg height="24" width="24" class="tm-svg-img tm-header-user-menu__icon tm-header-user-menu__icon_search tm-header-user-menu__icon_dark"><title>Поиск</title> <use xlink:href="/img/megazord-v24.cee85629.svg#search"></use></svg></a> <!----> <!----> <!----> <div class="tm-header-user-menu__item tm-header-user-menu__user_desktop"><div class="tm-dropdown"><div class="tm-dropdown__head"><svg height="24" width="24" data-test-id="menu-toggle-guest" class="tm-svg-img tm-header-user-menu__icon"><title>Профиль</title> <use xlink:href="/img/megazord-v24.cee85629.svg#header-user"></use></svg> <!----></div> <!----></div> <!----></div> <!----></div></div></div></div> <!----> <div class="tm-page-width"></div> <main class="tm-layout__container"><div hl="ru" companyName="scalaxy" data-async-called="true" class="tm-page"><div class="tm-page-width"><div class="tm-page__header"><!----></div> <div class="tm-page__wrapper"><div class="tm-page__main tm-page__main_has-sidebar"><div class="pull-down"><div class="pull-down__header" style="height:0px;"><div class="pull-down__content" style="bottom:10px;"><svg height="24" width="24" class="tm-svg-img pull-down__arrow"><title>Обновить</title> <use xlink:href="/img/megazord-v24.cee85629.svg#pull-arrow"></use></svg></div></div> <div show-title="" class="tm-company-card"><div class="tm-company-card__info"><div class="tm-company-card__header"><a href="/ru/company/scalaxy/profile/" class="tm-company-card__avatar"><div class="tm-entity-image"><img alt="" height="48" src="//habrastorage.org/getpro/habr/companies/f40/0aa/5b2/f400aa5b20687ff8671097ec4f4016ed.png" width="48" class="tm-entity-image__pic"></div></a> <!----> <div class="tm-rating tm-company-card__rating"><div class="tm-rating__header"> <div class="tm-rating__counter">0</div></div> <div class="tm-rating__text">
    Рейтинг
  </div></div></div> <div class="tm-company-card__info"><a href="/ru/company/scalaxy/profile/" class="tm-company-card__name">
        Оверсан-Скалакси
      </a> <div class="tm-company-card__description"></div></div></div> <div class="tm-company-card__buttons"><!----> <!----></div></div> <div class="tm-page-article__body"><article class="tm-page-article__content tm-page-article__content_inner"><div class="tm-page-article__head-wrapper"><!----> <div class="tm-article-snippet tm-page-article__snippet"><div class="tm-article-snippet__meta-container"><div class="tm-article-snippet__meta"><span class="tm-user-info tm-article-snippet__author"><a href="/ru/users/SaveTheRbtz/" title="SaveTheRbtz" class="tm-user-info__userpic"><div class="tm-entity-image"><img alt="" height="24" loading="lazy" src="//habrastorage.org/r/w32/getpro/habr/avatars/b37/3dd/c4b/b373ddc4b2783a8cbe583cd7eeece149.jpg" width="24" class="tm-entity-image__pic"></div></a> <span class="tm-user-info__user"><a href="/ru/users/SaveTheRbtz/" class="tm-user-info__username">
      SaveTheRbtz
    </a> </span></span> <span class="tm-article-snippet__datetime-published"><time datetime="2010-02-08T11:05:01.000Z" title="2010-02-08, 14:05">8  февраля  2010 в 14:05</time></span></div> <!----></div> <h1 lang="ru" class="tm-article-snippet__title tm-article-snippet__title_h1"><span>GPFS. Часть 2. Эксплуатация GPFS кластера</span></h1> <div class="tm-article-snippet__hubs"><span class="tm-article-snippet__hubs-item"><a href="/ru/company/scalaxy/blog/" class="tm-article-snippet__hubs-item-link router-link-active"><span>Блог компании Оверсан-Скалакси</span> <!----></a></span></div> <!----> <!----> <!----></div></div> <!----> <div data-gallery-root="" lang="ru" class="tm-article-body"><div id="post-content-body" class="article-formatted-body article-formatted-body_version-1"><div xmlns="http://www.w3.org/1999/xhtml"><img src="/img/image-loader.svg" alt="IBM GPFS" align="left" data-src="http://img23.imageshack.us/img23/8917/ibmv.gif"/>В продолжение моего <a href="http://habrahabr.ru/company/scalaxy/blog/82997/">предыдущего поста</a> о настройке GPFS-кластера, как и обещал, перехожу к описанию весьма распространённых ситуаций, с которыми можно столкнуться при работе с GPFS.<br/>
<br/>
<br/>
<br/>
<br/>
<a name="habracut"></a><br/>
<br/>
<b>Изменение параметров GPFS</b><br/>
<br/>
Представим ситуацию, что нам необходимо сменить точку монтирования для нашей GPFS:<br/>
<br/>
<code>gpfs00:~ # mmchfs /dev/gpfs0 -T /gpfs-howto<br/>
<br/>
File system /dev/gpfs0 is mounted on nodes:<br/>
 10.35.2.66 gpfs04 gpfs-cluster.edu.scalaxy.local 11.05 (3.3.0.2)<br/>
 10.35.2.63 gpfs01 gpfs-cluster.edu.scalaxy.local 11.05 (3.3.0.2)<br/>
 10.35.2.64 gpfs02 gpfs-cluster.edu.scalaxy.local 11.05 (3.3.0.2)<br/>
 10.35.2.65 gpfs03 gpfs-cluster.edu.scalaxy.local 11.05 (3.3.0.2)<br/>
 10.35.2.62 gpfs00 gpfs-cluster.edu.scalaxy.local 11.05 (3.3.0.2)<br/>
mmchfs: Command failed. Examine previous error messages to determine cause.</code><br/>
<br/>
В ответ мы получили ошибку, что FS примонтирована на нескольких нодах.<br/>
<br/>
Попытаемся отмонтировать GPFS на всех машинах:<br/>
<br/>
<code>gpfs00:~ # mmumount gpfs0 -a<br/>
gpfs04.edu.scalaxy.local: umount: /gpfs-storage: device is busy.<br/>
gpfs04.edu.scalaxy.local: (In some cases useful info about processes that use<br/>
gpfs04.edu.scalaxy.local: the device is found by lsof(8) or fuser(1))</code><br/>
<br/>
Обратите внимание, что ошибка приходит от ноды <i>gpfs04</i>, на которой я в данный момент нахожусь в директории <i>/gpfs-storage</i>. Только после выхода из неё можно без проблем отмонтировать на всех нодах и сменить точку монтирования.<br/>
<br/>
<code>gpfs00:~ # mmchfs /dev/gpfs0 -T /gpfs-howto</code><br/>
<br/>
<blockquote>Не все параметры заданные на этапе <i>mmcrfs</i> можно изменить командой <i>mmchfs</i>. Подробнее в мануале.</blockquote><br/>
<br/>
<b>Мониторинг GPFS</b><br/>
<br/>
Давайте теперь примонтируем всё на место и посмотрим, какие есть самые распространённые команды для мониторинга нашей новосозданной GPFS:<br/>
<br/>
<code>gpfs00:~ # mmmount gpfs0 -a</code><br/>
<br/>
<blockquote><i>-a</i> — монтирует все FS на всех нодах кластера</blockquote><br/>
<br/>
Смотрим, какие ноды есть в кластере:<br/>
<br/>
<code>gpfs00:~ # mmlsnode<br/>
GPFS nodeset Node list<br/>
------------- -------------------------------------------------------<br/>
 gpfs-cluster gpfs00 gpfs01 gpfs02 gpfs03 gpfs04</code><br/>
<br/>
Список NSD в кластере:<br/>
<br/>
<code>gpfs00:~ # mmlsnsd -X<br/>
<br/>
Disk name NSD volume ID Device Devtype Node name Remarks <br/>
---------------------------------------------------------------------------------------------------<br/>
 gpfs1nsd 0A23023E4B5DC633 /dev/sdb1 generic gpfs00.edu.scalaxy.local server node<br/>
 gpfs2nsd 0A23023F4B5DC633 /dev/sdb1 generic gpfs01.edu.scalaxy.local server node<br/>
 gpfs3nsd 0A2302404B5DC634 /dev/sdb1 generic gpfs02.edu.scalaxy.local server node</code><br/>
<br/>
<blockquote><i>-X</i> — отображает расширенную информацию. Довольно медленная операция, рекомендуется применять только при диагностике неисправностей.<br/>
<i>-F</i> — показывает NSD, которые не привязаны к какой-либо FS</blockquote><br/>
<br/>
Можно посмотреть, сколько осталось места / inode'ов на GPFS:<br/>
<br/>
<code>gpfs00:~ # mmdf gpfs0<br/>
disk disk size failure holds holds&amp;nbsp; free KB    free KB<br/>
name   in KB group metadata data in full blocks in fragments<br/>
--------------- ------------- -------- -------- ----- -------------------- -------------------<br/>
Disks in storage pool: system (Maximum disk size allowed is 125 GB)<br/>
gpfs1nsd 2097152 1 yes yes 1934336 ( 92%) 1952 ( 0%)<br/>
gpfs2nsd 2097152 2 yes yes 1933312 ( 92%) 2080 ( 0%)<br/>
gpfs3nsd 2097152 3 no no 0 ( 0%) 0 ( 0%)<br/>
 ------------- -------------------- -------------------<br/>
(pool total) 6291456 3867648 ( 61%) 4032 ( 0%)<br/>
<br/>
============= ==================== ===================<br/>
(total) 6291456   3867648 ( 61%) 4032 ( 0%)<br/>
<br/>
Inode Information<br/>
-----------------<br/>
Number of used inodes: 4071<br/>
Number of free inodes: 32793<br/>
Number of allocated inodes: 36864<br/>
Maximum number of inodes: 36864</code><br/>
<br/>
В <a href="http://publib.boulder.ibm.com/infocenter/clresctr/vxrx/index.jsp?topic=/com.ibm.cluster.gpfs33.basicadm.doc/bl1adm_mmdf.html">документации</a> написано, что <i>mmdf</i> весьма трудоёмка, и её стоит применять только когда система слабо загружена.<br/>
<br/>
<code>gpfs00:~ # mmlsdisk gpfs0<br/>
disk driver sector failure holds holds storage<br/>
name type size group metadata data status availability pool<br/>
------------ -------- ------ ------- -------- ----- ------------- ------------ ------------<br/>
gpfs1nsd nsd 512 1 yes yes ready up system <br/>
gpfs2nsd nsd 512 2 yes yes ready up system <br/>
gpfs3nsd nsd 512 3 no no ready up system <br/>
<br/>
gpfs00:~ # mmlspool gpfs0<br/>
Storage pools in file system at '/gpfs-howto':<br/>
Name Id BlkSize Data Meta Total Data KB Free Data KB Total Meta KB Free Meta KB<br/>
system 0 1024 KB yes yes 4194304 3867648 ( 92%) 4194304 3870720 ( 92%)</code><br/>
<br/>
Также можно посмотреть информацию по кластеру целиком:<br/>
<br/>
<code>gpfs00:~ # mmlscluster<br/>
<br/>
GPFS cluster information<br/>
========================<br/>
 GPFS cluster name: gpfs-cluster.edu.scalaxy.local<br/>
 GPFS cluster id: 730430031139815289<br/>
 GPFS UID domain: gpfs-cluster.edu.scalaxy.local<br/>
 Remote shell command: /usr/bin/ssh<br/>
 Remote file copy command: /usr/bin/scp<br/>
<br/>
GPFS cluster configuration servers:<br/>
-----------------------------------<br/>
 Primary server: gpfs00.edu.scalaxy.local<br/>
 Secondary server: gpfs01.edu.scalaxy.local<br/>
<br/>
Node Daemon node name IP address Admin node name Designation <br/>
-----------------------------------------------------------------------------------------------<br/>
 1 gpfs00.edu.scalaxy.local 10.35.2.62 gpfs00.edu.scalaxy.local quorum-manager<br/>
 2 gpfs01.edu.scalaxy.local 10.35.2.63 gpfs01.edu.scalaxy.local quorum-manager<br/>
 3 gpfs02.edu.scalaxy.local 10.35.2.64   gpfs02.edu.scalaxy.local quorum<br/>
  4 gpfs03.edu.scalaxy.local 10.35.2.65 gpfs03.edu.scalaxy.local <br/>
 5  gpfs04.edu.scalaxy.local 10.35.2.66 gpfs04.edu.scalaxy.local</code><br/>
<br/>
Следующая команда выводит статус нод в кластере:<br/>
<br/>
<code>gpfs00:/home/aivanov # mmgetstate -Lsa<br/>
<br/>
Node number Node name Quorum Nodes up Total nodes GPFS state Remarks <br/>
------------------------------------------------------------------------------------<br/>
 1 gpfs00 2 3 5 active quorum node<br/>
 2 gpfs01 2 3 5 active quorum node<br/>
 3 gpfs02 2 3 5 active quorum node<br/>
 4 gpfs03 2 3 5 active <br/>
 5 gpfs04 2 3 5 active <br/>
<br/>
Summary information<br/>
---------------------<br/>
Number of nodes defined in the cluster: 5<br/>
Number of local nodes active in the cluster: 5<br/>
Number of remote nodes joined in this cluster: 0<br/>
Number of quorum nodes defined in the cluster:   3<br/>
Number of quorum nodes active in the cluster: 3<br/>
Quorum = 2, Quorum achieved</code><br/>
<br/>
<blockquote><i>-a</i> — для всех нод кластера<br/>
<i>-L</i> — отображать кворум, количество поднятых нод, общее количество нод и дополнительную информацию<br/>
<i>-s</i> — отображать summary</blockquote><br/>
<br/>
GPFS state бывают следующие:<br/>
<br/>
<blockquote><i>active</i> — всё ОК<br/>
<i>arbitrating</i> — нода пытается присоединится к кворуму<br/>
<i>down</i> — GPFS демон не запущен или перезапускается<br/>
<i>unknown</i> — статус машины неизвестен. В большинстве случаев означает, что машина недоступна по сети</blockquote><br/>
<br/>
Посмотреть какие лицензии установлены и на каких нодах можно следующей командой:<br/>
<br/>
<code>gpfs00:~ # mmlslicense -L<br/>
<br/>
Node name Required license Designated license<br/>
-------------------------------------------------------------------<br/>
gpfs00.edu.scalaxy.local server server<br/>
gpfs01.edu.scalaxy.local server server<br/>
gpfs02.edu.scalaxy.local server server<br/>
gpfs03.edu.scalaxy.local client client<br/>
gpfs04.edu.scalaxy.local client client<br/>
<br/>
Summary information<br/>
---------------------<br/>
Number of nodes defined in the cluster: 5<br/>
Number of nodes with server license designation: 3<br/>
Number of nodes with client license designation: 2<br/>
Number of nodes still requiring server license designation: 0<br/>
Number of nodes still requiring client license designation: 0</code><br/>
<br/>
<blockquote><i>-L</i> — детальная информация по лицензиям, а не только summary</blockquote><br/>
<br/>
Также можно посмотреть текущую конфигурацию кластера, но так как я на тестовых виртуалках не пользовался командой <i><a href="http://publib.boulder.ibm.com/infocenter/clresctr/vxrx/index.jsp?topic=/com.ibm.cluster.gpfs33.basicadm.doc/bl1adm_mmchcl.html">mmchconfig</a></i>, то она будет весьма не информативной.<br/>
 <br/>
<code>gpfs00:~ # mmlsconfig<br/>
Configuration data for cluster gpfs-cluster.edu.scalaxy.local:<br/>
--------------------------------------------------------------<br/>
clusterName gpfs-cluster.edu.scalaxy.local<br/>
clusterId 730430031139815289<br/>
autoload yes<br/>
minReleaseLevel 3.3.0.2<br/>
dmapiFileHandleSize 32<br/>
[gpfs02]<br/>
unmountOnDiskFail yes<br/>
[common]<br/>
adminMode central<br/>
<br/>
File systems in cluster gpfs-cluster.edu.scalaxy.local:<br/>
-------------------------------------------------------<br/>
/dev/gpfs0</code><br/>
<br/>
<h4>Манипуляции со структурой GPFS</h4><br/>
<br/>
Наполняем GPFS-диск:<br/>
<br/>
<code>cp -r /usr/src/linux/* /gpfs-howto/</code><br/>
<br/>
<b>Добавление дисков в GPFS</b><br/>
<br/>
Давайте теперь сделаем ещё пару NSD дисков на <i>gpfs00.edu.scalaxy.local</i> и <i>gpfs01.edu.scalaxy.local</i>.<br/>
<br/>
Процедура уже была <a href="http://habrahabr.ru/company/scalaxy/blog/82997/">описана</a> ранее:<br/>
<br/>
<code>gpfs00:~ # cat &lt;&lt;EOF >>gpfs.00.disk<br/>
/dev/sdb2:gpfs00.edu.scalaxy.local::dataAndMetadata:1<br/>
EOF<br/>
<br/>
gpfs00:~ # cat &lt;&lt;EOF >>gpfs.01.disk<br/>
/dev/sdb2:gpfs01.edu.scalaxy.local::dataAndMetadata:2<br/>
EOF<br/>
<br/>
gpfs00:~ # mmcrnsd -F gpfs.00.disk -v no<br/>
gpfs00:~ # mmcrnsd -F gpfs.01.disk -v no</code><br/>
<br/>
Теперь сама <a href="http://publib.boulder.ibm.com/infocenter/clresctr/vxrx/index.jsp?topic=/com.ibm.cluster.gpfs33.basicadm.doc/bl1adm_mmchcl.html">процедура добавления дисков</a> в gpfs0:<br/>
<br/>
<code>gpfs00:~ # mmadddisk gpfs0 -F gpfs.00.disk<br/>
The following disks of gpfs0 will be formatted on node gpfs00.edu.scalaxy.local:<br/>
 gpfs8nsd: size 2097152 KB<br/>
Extending Allocation Map<br/>
Checking Allocation Map for storage pool 'system'<br/>
Completed adding disks to file system gpfs0.<br/>
mmadddisk: Propagating the cluster configuration data to all<br/>
 affected nodes. This is an asynchronous process.<br/>
<br/>
gpfs00:~ # mmadddisk gpfs0 -F gpfs.01.disk<br/>
The following disks of gpfs0 will be formatted on node gpfs00.edu.scalaxy.local:<br/>
 gpfs9nsd: size 2097152 KB<br/>
Extending Allocation Map<br/>
Checking Allocation Map for storage pool 'system'<br/>
Completed adding disks to file system gpfs0.<br/>
mmadddisk: Propagating the cluster configuration data to all<br/>
 affected nodes. This is an asynchronous process.</code><br/>
<br/>
Также у <i>mmadddisk</i> есть параметр <i>-r</i>, который перераспределяет файлы по файловой системе с учётом новых дисков. Мы же этот флаг не используем, а в место него будем применять <i>mmrestripefs</i>.<br/>
<br/>
Если теперь посмотреть на вывод команды <i>mmdf</i>:<br/>
<br/>
<code>gpfs00:~ # mmdf gpfs0<br/>
disk disk size failure holds holds free KB free KB<br/>
name in KB group metadata data in full blocks in fragments<br/>
--------------- ------------- -------- -------- ----- -------------------- -------------------<br/>
Disks in storage pool: system (Maximum disk size allowed is 125 GB)<br/>
gpfs1nsd 2097152 1 yes yes 911360 ( 43%) 27712 ( 1%)<br/>
gpfs8nsd 2097152 1 yes yes 2094080 (100%) 992 ( 0%)<br/>
gpfs9nsd 2097152 2 yes yes 2094080 (100%) 992 ( 0%)<br/>
gpfs2nsd 2097152 2 yes yes 904192 ( 43%) 34880 ( 2%)<br/>
gpfs3nsd 2097152 3 no no 0 ( 0%) 0 ( 0%)<br/>
 ------------- -------------------- -------------------<br/>
(pool total) 10485760 6003712 ( 57%) 64576 ( 1%)<br/>
<br/>
============= ==================== ===================<br/>
(total) 10485760 6003712 ( 57%) 64576 ( 1%)<br/>
<br/>
Inode Information<br/>
-----------------<br/>
Number of used inodes: 31531<br/>
Number of free inodes: 5333<br/>
Number of allocated inodes: 36864<br/>
Maximum number of inodes: 36864</code><br/>
<br/>
то видно, что диски заняты неравномерно. Дабы <a href="http://publib.boulder.ibm.com/infocenter/clresctr/vxrx/index.jsp?topic=/com.ibm.cluster.gpfs33.basicadm.doc/bl1adm_mmrestr.html">это исправить</a> набираем:<br/>
<br/>
<code>gpfs00:~ # mmrestripefs gpfs0 -b<br/>
Scanning file system metadata, phase 1 ...<br/>
Scan completed successfully.<br/>
Scanning file system metadata, phase 2 ...<br/>
Scan completed successfully.<br/>
Scanning file system metadata, phase 3 ...<br/>
Scan completed successfully.<br/>
Scanning file system metadata, phase 4 ...<br/>
Scan completed successfully.<br/>
Scanning user file metadata ...<br/>
 11.64 % complete on Wed Jan 27 22:45:13 2010 ( 7435 inodes 502 MB)<br/>
 18.72 % complete on Wed Jan 27 22:45:33 2010 ( 12453 inodes 807 MB)<br/>
 25.88 % complete on Wed Jan 27 22:45:53 2010 ( 18590 inodes 1116 MB)<br/>
 33.05 % complete on Wed Jan 27 22:46:13 2010 ( 24020 inodes 1425 MB)<br/>
 39.77 % complete on Wed Jan 27 22:46:33 2010 ( 28585 inodes 1715 MB)<br/>
 46.10 % complete on Wed Jan 27 22:46:54 2010 ( 32828 inodes 1988 MB)<br/>
 100.00 % complete on Wed Jan 27 22:47:06 2010<br/>
Scan completed successfully.</code><br/>
<br/>
После чего GPFS рестрайпит данные на разделе:<br/>
<br/>
<code>gpfs00:~ # mmdf gpfs0<br/>
disk disk size failure holds holds free KB free KB<br/>
name in KB group metadata data in full blocks in fragments<br/>
--------------- ------------- -------- -------- ----- -------------------- -------------------<br/>
Disks in storage pool: system (Maximum disk size allowed is 125 GB)<br/>
gpfs1nsd 2097152 1 yes yes 635904 ( 30%) 808768 (39%)<br/>
gpfs8nsd 2097152 1 yes yes 1421312 ( 68%) 168160 ( 8%)<br/>
gpfs9nsd   2097152 2 yes yes 1431552 ( 68%) 166944 ( 8%)<br/>
gpfs2nsd 2097152 2 yes yes 615424 ( 29%) 820224 (39%)<br/>
gpfs3nsd 2097152 3 no no 0 ( 0%) 0 ( 0%)<br/>
 ------------- -------------------- -------------------<br/>
(pool total) 10485760 4104192 ( 39%) 1964096 (19%)<br/>
<br/>
============= ==================== ===================<br/>
(total) 10485760 4104192 ( 39%) 1964096 (19%)</code><br/>
<br/>
<b>Добавление нод в кластер</b><br/>
<br/>
Далее «на живую» перетащим дополнительные диски из quorum-виртуалок в nonquourum, и поднимем их статус до quorum.<br/>
<br/>
Для начала удалим дополнительные диски у <i>gpfs00.edu.scalaxy.local</i> и <i>gpfs01.edu.scalaxy.local</i>:<br/>
<br/>
<code>gpfs00:~ # mmdeldisk gpfs0 gpfs8nsd -b<br/>
gpfs00:~ # mmdeldisk gpfs0 gpfs9nsd -b</code><br/>
<br/>
<blockquote><i>-b</i> — говорит <i>mmdeldisk</i> перераспределить данные на файловой системе таким образом, как это сделал бы последующий запуск <i>mmrestripefs</i></blockquote><br/>
<br/>
Процесс удаления диска с параметром <i>-b</i> весьма похож на <i>mmrestripefs</i>, так что вывод команды указывать не буду.<br/>
<br/>
В случае какой-либо ошибки <i>mmdeldisk</i> напишет:<br/>
<br/>
<code>Attention: No disks were deleted, but some data was migrated.<br/>
 The file system may no longer be properly balanced.</code><br/>
<br/>
Это означает, что диск удалён не был, но файловая система перестала быть сбалансированной, и её требуется «отрестрайпить».<br/>
<br/>
Теперь, используя флаг <i>-F</i>, <a href="http://publib.boulder.ibm.com/infocenter/clresctr/vxrx/index.jsp?topic=/com.ibm.cluster.gpfs33.basicadm.doc/bl1adm_mmlsnsd.html">можно увидеть NSD</a>, которые не присвоены никакой файловой системе:<br/>
<br/>
<code>gpfs00:~ # mmlsnsd -F<br/>
 File system Disk name NSD servers <br/>
---------------------------------------------------------------------------<br/>
 (free disk) gpfs8nsd gpfs00.edu.scalaxy.local<br/>
 (free disk) gpfs9nsd gpfs01.edu.scalaxy.local</code><br/>
<br/>
Удалим эти NSD <a href="http://publib.boulder.ibm.com/infocenter/clresctr/vxrx/index.jsp?topic=/com.ibm.cluster.gpfs33.basicadm.doc/bl1adm_mmdelns.html">насовсем</a>:<br/>
<br/>
<code>gpfs00:~ # mmdelnsd gpfs9nsd<br/>
gpfs00:~ # mmdelnsd gpfs8nsd</code><br/>
<br/>
Далее, в <b>XEN Dom0</b> нужно перетащить «на живую» блочные устройства с машин <i>gpfs00.edu.scalaxy.local</i> и <i>gpfs01.edu.scalaxy.local</i> на <i>gpfs03.edu.scalaxy.local</i> и <i>gpfs04.edu.scalaxy.local</i> соответственно.<br/>
<br/>
<code>Dom0-0212:~ # xm shell</code><br/>
<br/>
Смотрим id'шники устройств:<br/>
<br/>
<code>xm> xm block-list gpfs00.edu.scalaxy.local<br/>
xm> xm block-list gpfs01.edu.scalaxy.local</code><br/>
<br/>
Удаляем со старых машин:<br/>
<br/>
<code>xm> xm block-detach gpfs00.edu.scalaxy.local 2066<br/>
xm> xm block-detach gpfs01.edu.scalaxy.local 2066</code><br/>
<br/>
Добавляем на новые:<br/>
<br/>
<code>xm> xm block-attach gpfs03.edu.scalaxy.local phy:/dev/user/gpfs00-disk1 sdb1 w<br/>
xm> xm block-attach gpfs04.edu.scalaxy.local phy:/dev/user/gpfs01-disk1 sdb1 w</code><br/>
<br/>
Помните, в <a href="http://habrahabr.ru/company/scalaxy/blog/82997/">первой части</a> я говорил про то, как удобен Xen для тестов? =)<br/>
<br/>
Меняем лицензии двух других машинах на серверные:<br/>
<br/>
<code>gpfs00:~ # mmchlicense server --accept -N gpfs04.edu.scalaxy.local,gpfs03.edu.scalaxy.local<br/>
gpfs00:~ # mmlslicense<br/>
<br/>
Summary information<br/>
---------------------<br/>
Number of nodes defined in the cluster: 5<br/>
Number of nodes with server license designation: 5<br/>
Number of nodes with client license designation: 0<br/>
Number of nodes still requiring server license designation: 0<br/>
Number of nodes still requiring client license designation: 0<br/>
<br/>
gpfs00:~ # cat &lt;&lt;EOF >> gpfs.03.disk<br/>
/dev/sdb1:gpfs03.edu.scalaxy.local::dataAndMetadata:1<br/>
EOF<br/>
<br/>
gpfs00:~ # cat &lt;&lt;EOF >> gpfs.04.disk<br/>
/dev/sdb1:gpfs04.edu.scalaxy.local::dataAndMetadata:2<br/>
EOF</code><br/>
<br/>
Для чистоты эксперимента удаляем всё, что было на <i>gpfs0</i> и запускаем копирование на GPFS исходников Linux в фоне:<br/>
<br/>
<code>gpfs00:~ # cp -r /usr/src/linux/* /gpfs-howto/&amp;</code><br/>
<br/>
Создаём NSD из свежеподключённых дисков и добавляем эти NSD в <i>gpfs0</i>:<br/>
<br/>
<code>gpfs00:~ # mmcrnsd -F gpfs.03.disk -v no<br/>
gpfs00:~ # mmadddisk gpfs0 -F gpfs.03.disk<br/>
<br/>
gpfs00:~ # mmcrnsd -F gpfs.04.disk -v no<br/>
gpfs00:~ # mmadddisk gpfs0 -F gpfs.04.disk</code><br/>
<br/>
Заметьте, что всё это время у нас производилось копирование файлов на GPFS.<br/>
<br/>
Теперь на любой из нод можем проверить, что все файлы на месте:<br/>
<br/>
<code>gpfs02:/gpfs-howto # ls<br/>
arch Documentation init lib net REPORTING-BUGS usr<br/>
block drivers ipc .mailmap .patches samples virt<br/>
COPYING firmware Kbuild MAINTAINERS perfmon scripts<br/>
CREDITS fs kdb Makefile README security<br/>
crypto include kernel mm README.SUSE sound</code><br/>
<br/>
Так как мы добавили диски только на середине копирования файлов, а в <i>mmadddisk</i> мы не использовали опцию <i>-r</i>, то в выводе <i>mmdf</i> мы увидим несбалансированность распределения файлов на GPFS. Так что нам потребуется выполнить уже известную процедуру:<br/>
<br/>
<code>gpfs00:~ # mmrestripefs gpfs0 -b</code><br/>
<br/>
<b>Разваливаем GPFS кластер</b><br/>
<br/>
Каждая единица данных и метаданных в GPFS-кластере хранится в максимум двух экземплярах. Поэтому, чтобы часть данных стала недоступна, нам нужно положить 2 ноды из разных failure-групп. Чтобы развалить кластер нам нужно либо не соблюсти quorum по дискам (более половины дисков <i>down</i>), либо по нодам (более половины нод окажется недоступно, например при <i>net split</i>).<br/>
<br/>
Мы развалим кворум по дискам, положив 2 ноды в разных failure-группах, тем самым нарушив quorum по дискам:<br/>
 <br/>
<code>gpfs03:~ # halt<br/>
gpfs04:~ # halt</code><br/>
<br/>
Проверяем, что показывает статус:<br/>
<br/>
<code>gpfs00:~ # mmgetstate -Lsa<br/>
<br/>
Node number Node name Quorum Nodes up Total nodes GPFS state Remarks <br/>
------------------------------------------------------------------------------------<br/>
 1 gpfs00 2 3 5 active quorum node<br/>
 2 gpfs01 2 3 5 active quorum node<br/>
 3 gpfs02 2 3 5 active quorum node<br/>
 4 gpfs03 0 0 5 unknown <br/>
 5 gpfs04 0 0 5 unknown <br/>
<br/>
Summary information<br/>
---------------------<br/>
Number of nodes defined in the cluster: 5<br/>
Number of local nodes active in the cluster: 3<br/>
Number of remote nodes joined in this cluster: 0<br/>
Number of quorum nodes defined in the cluster: 3<br/>
Number of quorum nodes active in the cluster:  3<br/>
Quorum = 2, Quorum achieved</code><br/>
<br/>
Видим, что quorum по нодам соблюдён, однако:<br/>
<br/>
<code>gpfs00:~ # ls /gpfs-howto<br/>
ls: cannot access /gpfs-howto: Stale NFS file handle</code><br/>
<br/>
Логи, <i>mmlsdisk</i> и <i>mmlsnsd</i> показывают, что 2 диска отвалились:<br/>
<br/>
<code>gpfs00:~ # grep "mmfs:" /var/log/messages<br/>
Jan 28 12:36:14 gpfs00 mmfs: Error=MMFS_DISKFAIL, ID=0x9C6C05FA, Tag=6368843: Disk failure. Volume gpfs0. rc = 5. Physical volume gpfs10nsd<br/>
Jan 28 14:43:11 gpfs00 mmfs: Error=MMFS_DISKFAIL, ID=0x9C6C05FA, Tag=6368846: Disk failure. Volume gpfs0. rc = 19. Physical volume gpfs11nsd<br/>
<br/>
gpfs00:~ # less /var/adm/ras/mmfs.log.latest<br/>
Thu Jan 28 12:36:14.863 2010: Disk failure from node 10.35.2.64 (gpfs02) Volume<br/>
gpfs0. Physical volume gpfs10nsd.<br/>
Thu Jan 28 14:43:11.688 2010: Disk failure. Volume gpfs0. rc = 19. Physical vol<br/>
ume gpfs11nsd.<br/>
<br/>
gpfs00:~ # mmlsdisk gpfs0 -L<br/>
disk driver sector failure holds holds storage<br/>
name type size group metadata data status availability disk id pool remarks <br/>
------------ -------- ------ ------- -------- ----- ------------- ------------ ------- ------------ ---------<br/>
gpfs1nsd nsd 512 1 yes yes ready up 1 system desc<br/>
gpfs2nsd nsd 512 2 yes yes ready up 2 system desc<br/>
gpfs3nsd nsd 512 3 no no ready up 3 system desc<br/>
gpfs10nsd nsd 512 1 yes yes ready down 4 system desc<br/>
gpfs11nsd nsd 512 2 yes yes ready down 5 system desc<br/>
Number of quorum disks: 5<br/>
Read quorum value: 3<br/>
Write quorum value: 3<br/>
<br/>
gpfs00:~ # mmlsnsd -X<br/>
<br/>
Disk name NSD volume ID Device Devtype Node name Remarks <br/>
---------------------------------------------------------------------------------------------------<br/>
 gpfs10nsd 0A2302414B6154F4 - - gpfs03.edu.scalaxy.local (not found) server node<br/>
 gpfs11nsd 0A2302424B6154F8 - - gpfs04.edu.scalaxy.local (not found) server node<br/>
 gpfs1nsd 0A23023E4B5DC633 /dev/sdb1 generic gpfs00.edu.scalaxy.local server node<br/>
 gpfs2nsd 0A23023F4B5DC633 /dev/sdb1 generic gpfs01.edu.scalaxy.local server node<br/>
 gpfs3nsd 0A2302404B5DC634 /dev/sdb1 generic gpfs02.edu.scalaxy.local server node<br/>
<br/>
mmlsnsd: The following nodes could not be reached:<br/>
<br/>
gpfs03.edu.scalaxy.local<br/>
gpfs04.edu.scalaxy.local</code><br/>
<br/>
<b>Восстановление GPFS кластера после сбоя</b><br/>
<br/>
Запускаем все остановленные виртуалки с <b>Dom0</b>:<br/>
<br/>
<code>Dom0-0212:/etc/xen/vm # for i in gpfs*.edu.scalaxy.local ; do xm create $i; done</code><br/>
<br/>
После загрузки машин проверим, поднялся ли GPFS-демон на серверах:<br/>
<br/>
<code>gpfs00:~ # mmgetstate -a<br/>
<br/>
Node number Node name GPFS state<br/>
------------------------------------------<br/>
 1 gpfs00 active<br/>
 2 gpfs01 active<br/>
 3 gpfs02 active<br/>
 4 gpfs03 active<br/>
 5 gpfs04 active</code><br/>
<br/>
После того, как машины запустились, прилегающие к ним NSD-устройства остаются в состоянии «down» и не поднимаются автоматически. Сделано это из-за того, что причины смерти системы могут быть совершенно разные, и оператор должен сам решить, стоит ли эту систему отправлять обратно в бой или нет. Если же наблюдается серьёзная проблема с системой, то, чтобы подстраховаться от двойного сбоя, лучше выполнить <i>mmrestripefs -m</i>, которая мигрирует данные и метаданные, которые, в свою очередь, после выхода из строя одной машины остались в единичном экземпляре. Однако, данную команду лучше использовать с умом, ибо она потребляет много ресурсов и занимает кучу времени.<br/>
<br/>
Однако, вернувшись к нашему GPFSу: чтобы вернуть в строй диски и собрать заново GPFS, нужно выполнить команду:<br/>
<br/>
<code>gpfs00:~ # mmchdisk gpfs0 start -a<br/>
Scanning file system metadata, phase 1 ...<br/>
Scan completed successfully.<br/>
Scanning file system metadata, phase 2 ...<br/>
Scan completed successfully.<br/>
Scanning file system metadata, phase 3 ...<br/>
Scan completed successfully.<br/>
Scanning file system metadata, phase 4 ...<br/>
Scan completed successfully.<br/>
Scanning user file metadata ...<br/>
 100.00 % complete on Thu Jan 28 16:38:47 2010<br/>
Scan completed successfully.</code><br/>
<br/>
Параметр <i>-a</i> запустит все остановленные диски.<br/>
<br/>
В случае, если какой-то диск не поднялся — команда может выдать ошибку:<br/>
<br/>
<code>No such device<br/>
Initial disk state was updated successfully, but another error may have changed the state again.<br/>
mmchdisk: Command failed. Examine previous error messages to determine cause.</code><br/>
<br/>
Команда <i>mmlsdisk</i> пометит этот диск как «unrecovered»:<br/>
<br/>
<code>gpfs00:~ # mmlsdisk gpfs0<br/>
disk driver sector failure holds holds storage<br/>
name type size group metadata data status availability pool<br/>
------------ -------- ------ ------- -------- ----- ------------- ------------ ------------<br/>
gpfs1nsd nsd 512 1 yes yes ready up system <br/>
gpfs2nsd nsd 512 2 yes yes ready up system <br/>
gpfs3nsd nsd 512 3 no no ready up system <br/>
gpfs10nsd nsd 512 2 yes yes ready up system <br/>
gpfs11nsd nsd 512 1 yes yes ready unrecovered system</code> <br/>
<br/>
Но даже с одним мёртвым NSD файловая система будет вполне работоспособна на всех нодах кластера.<br/>
<br/>
В нашем случае, с дисками всё нормально и наш мини-кластер собрался нормально, так что необходимо примонтировать GPFS-раздел на всех нодах командой:<br/>
<br/>
<code>gpfs00:~ # mmmount gpfs0 -a</code><br/>
<br/>
После сборки развалившегося кластера проверим, действительно ли все данные выжили:<br/>
<br/>
<code>gpfs00:~ # diff -ru /usr/src/linux/ /gpfs-howto/<br/>
gpfs00:~ #</code><br/>
<br/>
Да, все данные оказались нетронутыми даже после полного развала всего кластера.<br/>
<br/>
Теперь можно удалить подключённые для теста диски, с ребалансировкой данных:<br/>
<br/>
<code>gpfs00:~ # mmdeldisk gpfs0 gpfs10nsd -b<br/>
Deleting disks ...<br/>
Scanning system storage pool<br/>
Scanning file system metadata, phase 1 ...<br/>
Scan completed successfully.<br/>
Scanning file system metadata, phase 2 ...<br/>
Scan completed successfully.<br/>
Scanning file system metadata, phase 3 ...<br/>
Scan completed successfully.<br/>
Scanning file system metadata, phase 4 ...<br/>
Scan completed successfully.<br/>
Scanning user file metadata ...<br/>
 100.00 % complete on Thu Jan 28 17:18:41 2010<br/>
Scan completed successfully.<br/>
Checking Allocation Map for storage pool 'system'<br/>
tsdeldisk completed.<br/>
mmdeldisk: Propagating the cluster configuration data to all<br/>
 affected nodes. This is an asynchronous process.</code><br/>
<br/>
Если одновременно с другого узла попытаться удалить ещё один диск, то мы будем ждать пока предыдущая операция освободит Lock:<br/>
<br/>
<code>gpfs01:~ # mmdeldisk gpfs0 gpfs6nsd -b<br/>
mmdeldisk: The main GPFS cluster configuration file is locked. Retrying...<br/>
mmdeldisk: Lock creation successful.</code><br/>
<br/>
Если GPFS поймёт, что после удаления диска файлы не влезут на файловую систему, то <i>mmdeldisk</i> выдаст следующую ошибку:<br/>
<br/>
<code>Deleting disks ...<br/>
Scanning system storage pool<br/>
Scanning file system metadata, phase 1 ...<br/>
Error processing inodes.<br/>
No space left on device<br/>
Attention: No disks were deleted, but some data was migrated.<br/>
 The file system may no longer be properly balanced.<br/>
tsdeldisk completed.<br/>
mmdeldisk: tsdeldisk failed.<br/>
Verifying file system configuration information ...<br/>
mmdeldisk: Propagating the cluster configuration data to all<br/>
 affected nodes. This is an asynchronous process.<br/>
mmdeldisk: Command failed. Examine previous error messages to determine cause.</code><br/>
<br/>
<b>Падение quorum-ноды при копировании файлов</b><br/>
<br/>
Теперь мы «положим» нашу <i>gpfs00.edu.scalaxy.local</i> во время интенсивной работы с диском другими нодами.<br/>
<br/>
Я проверял бесперебойность работы на команде:<br/>
<br/>
<code>gpfs03:/gpfs-howto# dd if=/dev/zero bs=1M | pv | dd of=zero03 bs=1M</code><br/>
<br/>
<blockquote>Обратите внимание, что размер буфера равен страйпу файловой системы, заданному на этапе <i>mmcrfs</i></blockquote><br/>
<br/>
Машину я «прибивал» как <i>shutdown -h now</i> так и <i>xm destroy</i><br/>
<br/>
Всё прошло успешно — поднятия и остановки <i>gpfs00.edu.scalaxy.local</i> никак не повлияли на скорость копирования.<br/>
<br/>
<b>Что происходит при нехватке inode'ов</b><br/>
<br/>
Вспомним наш пример с исходниками Linux. При создании файловой системы мы неправильно выбрали размер блока потому, что файлы исходников крайне малы и им никак не подходит размер блока 1M, а соответственно, минимальный размер файла будет равняться 32Kb.<br/>
<br/>
<code>gpfs04:/gpfs-howto # make oldconfig<br/>
gpfs04:/gpfs-howto # make<br/>
.....<br/>
.....<br/>
fs/dmapi/dmapi_session.c:1824: fatal error: opening dependency file fs/dmapi/.dmapi_session.o.d: No space left on device</code><br/>
<br/>
Вот и всё, inode'ы кончились, можем это проверить:<br/>
<br/>
<code>gpfs04:/gpfs-howto # mmdf gpfs0 -F<br/>
Inode Information<br/>
-----------------<br/>
Number of used inodes: 36864<br/>
Number of free inodes: 0<br/>
Number of allocated inodes: 36864<br/>
Maximum number of inodes: 36864</code><br/>
<br/>
Если посмотреть лог, то будет видно, что на самом деле GPFS предупредил нас об этом заранее, правда мы этого не увидели:<br/>
 <br/>
<code>gpfs04:/gpfs-howto # grep "mmfs:" /var/log/messages<br/>
Jan 25 22:36:31 gpfs01 mmfs: Error=MMFS_SYSTEM_WARNING, ID=0x4DC797C6, Tag=6153238: File system warning. Volume gpfs0. Reason: File system gpfs0 is approaching the limit for the maximum number of inodes/files.</code><br/>
<br/>
Чтобы решить эту проблему нужно увеличить количество inode'ов:<br/>
<br/>
<code>gpfs00:~ # mmchfs gpfs0 -F 100000</code><br/>
<br/>
Также желательно не оставлять на GPFS inode'ов меньше 5%:<br/>
<br/>
<blockquote>For file systems that will be creating parallel files, if the total number of free inodes is not greater than 5% of the total number of inodes, file system access might slow down. Take this into consideration when creating your file system</blockquote><br/>
<br/>
<b>Снапшоты в GPFS</b><br/>
<br/>
Их я опишу совсем вкратце.<br/>
<br/>
Возьмём README файл линукса и скопируем его на GPFS:<br/>
<br/>
<code>gpfs00:~ # cp /usr/src/linux/README /gpfs-howto/</code><br/>
<br/>
<a href="http://publib.boulder.ibm.com/infocenter/clresctr/vxrx/index.jsp?topic=/com.ibm.cluster.gpfs33.basicadm.doc/bl1adm_crsnap.html">Сделаем снапшот</a> файловой системы:<br/>
<br/>
<code>gpfs00:~ # mmcrsnapshot gpfs0 gpfs-snapshot-`date +%Y-%m-%d`<br/>
Writing dirty data to disk<br/>
Quiescing all file system operations<br/>
Writing dirty data to disk again<br/>
Creating snapshot.<br/>
Resuming operations.</code><br/>
<br/>
Удаляем файл, который только что скопировали:<br/>
<br/>
<code>gpfs00:~ # rm /gpfs-howto/README</code><br/>
<br/>
И смотрим, остался ли он жив в подпапке <i>.snapshots</i>:<br/>
<br/>
<code>gpfs00:~ # ls -al /gpfs-howto/.snapshots/gpfs-snapshot-2010-01-28/<br/>
-rw-r--r-- 1 root root 16930 2010-01-26 19:58 README</code><br/>
<br/>
<b>Тесты производительности GPFS</b><br/>
<br/>
Тесты, скорее всего выложу позже, когда развернём всё это на InfiniBand-ферме, а не на 5-ти виртуалках в одном Dom0.<br/>
<br/>
Тесты производительности, которые обитают в интернете, в основном направлены на сравнении производительности MPI-I/O vs POSIX, threaded I/O, block sizes. Интересные сравнения можно посмотреть тут:<br/>
<br/>
<a href="http://www.nersc.gov/news/reports/technical/seaborg_scaling/io.php">www.nersc.gov/news/reports/technical/seaborg_scaling/io.php</a><br/>
<a href="http://arcos.inf.uc3m.es/~dcio/ALEX-gpfs.ppt">http://arcos.inf.uc3m.es/~dcio/ALEX-gpfs.ppt</a><br/>
<br/>
<b>Что осталось за кадром?</b><br/>
<br/>
<ul>
<li>Квоты</li>
<li>Политики</li>
<li>Пулы</li>
<li>Filesets</li>
<li>DMAPI</li>
<li>Windows и AIX специфика GPFS</li>
</ul><br/>
<br/>
… а также доверенный доступ GPFS-кластеров друг к другу и внутренний API gpfs, через который можно вытянуть метаданные миллиарда файлов за пару секунд :)<br/>
<br/>
За кадром осталась и замечательная команда, которая может всё-всё-всё =)<br/>
<br/>
<code>gpfs00:~ # mmfsadm</code><br/>
<br/>
<code>Enter commands (type "help" or "?" for help):<br/>
<br/>
mmfsadm> help<br/>
Commands:<br/>
dump what Dump data structures and statistics, where 'what' can be:<br/>
 alloc, alloc all, alloc stats, allocmgr, allocmgr all,<br/>
 allocmgr stats, allocmgr hint, brt, buffers, cfgmgr,<br/>
 condvar, config, DACspy, dealloc, dealloc stats,<br/>
 dealloc all, disk, dmapi, eventsExporter, files, filesets,<br/>
 filocks, fs, fsck, fsmgr, ialloc, ialloc all, iallocmgr,<br/>
 iallocmgr all, indblocks, indirect, instance, iocounters,<br/>
 iohist, kthread, llfile, lock, log, lstat, malloc, mb,<br/>
 mmap, mutex, mutex all, nsd, pcache, perfmon,<br/>
 pgalloc, pgalloc all, pit, quorumState, quota, reclock,<br/>
 reclockSleepers, reclockStats, res, sanergy, sgmgr, stripe,<br/>
 sxlock, thread, thread all, threadstacks, threadstats,<br/>
 tmstats, tokenmgr, tokens, tmcomm, updatelogger,<br/>
 disk, verbs, version, vfsstats, vnodes, waiters, winsec,<br/>
 or all<br/>
saferdump what Like the dump command but with safety locks. (Might hang)<br/>
eventsExporter Control event exporter<br/>
showCfgValue parm Show the value of the requested parameter<br/>
showtrace Show current trace levels and trace flag settings<br/>
showprocs Display the process table<br/>
vfsstats [keyword] Display vfs statistics. Keywords are enable, disable,<br/>
 reset, show<br/>
verifytrace Verify trace levels and trace flag settings<br/>
<br/>
trace class n Set level for given trace class to n, where "class" can be:<br/>
 alloc, allocmgr, basic, brl, cleanup, cmd, defrag,<br/>
 dentryexit, disk, dmapi, ds, errlog, fs, fsck,<br/>
 kentryexit, io, klockl, ksvfs, lock, log, malloc, mb,<br/>
 memmgr, mnode, msg, mutex, perfmon, pgalloc, pin, pit,<br/>
 quota, sp, tasking, thread, tm, ts, user1, user2, vnode,<br/>
 vnop, block, dentry, ialloc, file, super, shared, nsd,<br/>
 disklease, smb, eventsExporter, sec, sanergy, kernel,<br/>
 mmpmon, vdisk, rdma, pcache, vdb, vhosp, or all<br/>
shutdown -or- sd Shutdown the system<br/>
cleanup Clean up the shared segment, etc.<br/>
<br/>
quorum reset or n Set quorum to value n or reset<br/>
tokenmgr Token manager command<br/>
recOrient create/{open inodeNum} create/open record oriented file and run debug function<br/>
dumpmem addr [len] [width]<br/>
 Dump memory at address addr (hex) for length len (decimal)<br/>
 using given word width<br/>
test what Invoke test routine in mmfsd. The "what" string is<br/>
 interpreted by the daemon<br/>
errlog on/off Activate or deactivate error logging<br/>
errlog query Display error logging info<br/>
quiesce Disable new sessions<br/>
resume Enable new sessions<br/>
nomessages Accept no session messages at all<br/>
resume thread Resume the thread with the given address<br/>
signalcond cond Signal the condition variable with the given address<br/>
sleep n.m Sleep for requested number of seconds (floating point<br/>
 number, so fractional seconds are allowed.) Sleeps the<br/>
 mmfsadm command parser, not the daemon.<br/>
writecore [type] Write a core dump without terminating the daemon.<br/>
graceperiod [t] Start grace period for t seconds.<br/>
 set t to 0 to get default grace period.<br/>
<br/>
exit, quit -or- q Terminate this program</code><br/>
<br/>
<b>Ссылки по теме</b><br/>
<br/>
<ul>
<li><a href="http://publib.boulder.ibm.com/infocenter/clresctr/vxrx/index.jsp?topic=/com.ibm.cluster.gpfs33.diagnosis.doc/bl1pdg11_xtoc.html">GPFS V3.3 Advanced Administration Guide</a><br/>
</li>
<li><a href="http://publib.boulder.ibm.com/infocenter/clresctr/vxrx/index.jsp?topic=/com.ibm.cluster.gpfs33.basicadm.doc/bl1adm11_xtoc.html">GPFS V3.3 Administration and Programming Reference</a></li>
<li><a href="http://publib.boulder.ibm.com/infocenter/clresctr/vxrx/index.jsp?topic=/com.ibm.cluster.gpfs33.install.doc/bl1ins11_xtoc.html">GPFS V3.3 Concepts, Planning, and Installation Guide</a></li>
<li><a href="http://publib.boulder.ibm.com/infocenter/clresctr/vxrx/index.jsp?topic=/com.ibm.cluster.gpfs33.diagnosis.doc/bl1pdg11_xtoc.html">GPFS V3.3 Problem Determination Guide</a></li>
<li><a href="http://publib.boulder.ibm.com/infocenter/clresctr/vxrx/index.jsp?topic=/com.ibm.cluster.gpfs33.dmapi.doc/bl1dmp11_xtoc.html">GPFS V3.3 Data Management API Guide</a></li>
<li><a href="http://book.opensourceproject.org.cn/enterprise/cluster/ibmcluster/index.html?page=opensource/7819/ddu0080.html">Linux Clustering with CSM and GPFS Linux Clustering with CSM and GPFS</a></li>
<li><a href="http://www.ibm.com/developerworks/forums/forum.jspa?forumID=479">General Parallel File System (GPFS) Forum</a></li>
<li><a href="http://www.ibm.com/developerworks/forums/forum.jspa?forumID=1606&amp;start=0">General Parallel File System — Announce (GPFS — Announce) Forum</a></li>
<li><a href="http://docs.google.com/viewer?a=v&amp;q=cache:_vIGaw5NX98J:www.cs.berkeley.edu/~andreye/papers/gpfs_dr.pdf+DescOnly+GPFS&amp;hl=ru&amp;gl=ru&amp;sig=AHIEtbT8546CoPxEP7LDkIIo2haLiaHbWw">Disaster Recovery with General Parallel File System</a></li>
<li><a href="http://docs.google.com/viewer?a=v&amp;q=cache:_vIGaw5NX98J:www.cs.berkeley.edu/~andreye/papers/gpfs_dr.pdf+DescOnly+GPFS&amp;hl=ru&amp;gl=ru&amp;sig=AHIEtbT8546CoPxEP7LDkIIo2haLiaHbWw">Disaster Recovery with General Parallel File System</a></li>
<li><a href="http://www.linux.org.ru/wiki/en/GPFS">GPFS@LOR</a></li>
<li><a href="https://help.ubuntu.com/community/SettingUpGPFSHowTo">GPFS@Ubuntu</a></li>
<li><a href="http://www.ibm.com/developerworks/wikis/display/hpccentral/General+Parallel+File+System+%28GPFS%29">GPFS@IBM wiki</a><br/>
</li>
</ul></div></div> <!----> <!----></div> <div class="tm-article-body__tags"><div class="tm-article-body__tags-links"><span class="tm-article-body__tags-title">Теги:</span> <span class="tm-article-body__tags-item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Bgpfs%5D" class="tm-article-body__tags-item-link">gpfs</a></span><span class="tm-article-body__tags-item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5B%D1%80%D0%B0%D1%81%D0%BF%D1%80%D0%B5%D0%B4%D0%B5%D0%BB%D0%B5%D0%BD%D0%BD%D1%8B%D0%B5%20%D1%84%D0%B0%D0%B9%D0%BB%D0%BE%D0%B2%D1%8B%D0%B5%20%D1%81%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D1%8B%5D" class="tm-article-body__tags-item-link">распределенные файловые системы</a></span><span class="tm-article-body__tags-item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Binfiniband%5D" class="tm-article-body__tags-item-link">infiniband</a></span><span class="tm-article-body__tags-item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5B%D0%BE%D0%B1%D0%BB%D0%B0%D1%87%D0%BD%D1%8B%D0%B5%20%D0%B2%D1%8B%D1%87%D0%B8%D1%81%D0%BB%D0%B5%D0%BD%D0%B8%D1%8F%5D" class="tm-article-body__tags-item-link">облачные вычисления</a></span><span class="tm-article-body__tags-item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5B%D0%BE%D0%B1%D0%BB%D0%B0%D1%87%D0%BD%D0%B0%D1%8F%20%D0%BF%D0%BB%D0%B0%D1%82%D1%84%D0%BE%D1%80%D0%BC%D0%B0%5D" class="tm-article-body__tags-item-link">облачная платформа</a></span></div> <div class="tm-article-body__tags-links"><span class="tm-article-body__tags-title">Хабы:</span> <span class="tm-article-body__tags-item"><a href="/ru/company/scalaxy/blog/" class="tm-article-body__tags-item-link router-link-active">
                  Блог компании Оверсан-Скалакси
                </a></span></div></div></article> <div class="tm-article__icons-wrapper"><div class="tm-data-icons tm-page-article__counters-panel"><div class="tm-article-rating tm-data-icons__item"><div class="tm-votes-meter tm-article-rating__votes-switcher"><svg height="16" width="16" class="tm-svg-img tm-votes-meter__icon tm-votes-meter__icon_medium"><title>Всего голосов 46: ↑39 и ↓7</title> <use xlink:href="/img/megazord-v24.cee85629.svg#counter-rating"></use></svg> <span title="Всего голосов 46: ↑39 и ↓7" class="tm-votes-meter__value tm-votes-meter__value_positive tm-votes-meter__value_medium">+32</span></div> <DIV class="v-portal" style="display:none;"></DIV></div> <!----> <!----> <button title="Добавить в закладки" type="button" class="bookmarks-button tm-data-icons__item"><span title="Добавить в закладки" class="tm-svg-icon__wrapper bookmarks-button__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Добавить в закладки</title> <use xlink:href="/img/megazord-v24.cee85629.svg#counter-favorite"></use></svg></span> <span title="Количество пользователей, добавивших публикацию в закладки" class="bookmarks-button__counter">
    30
  </span></button> <div title="Читать комментарии" class="tm-article-comments-counter-link tm-data-icons__item"><a href="/ru/company/scalaxy/blog/83353/comments/" class="tm-article-comments-counter-link__link"><svg height="16" width="16" class="tm-svg-img tm-article-comments-counter-link__icon"><title>Комментарии</title> <use xlink:href="/img/megazord-v24.cee85629.svg#counter-comments"></use></svg> <span class="tm-article-comments-counter-link__value">
      10
    </span></a> <!----></div> <div title="Поделиться" class="tm-sharing tm-data-icons__item"><button type="button" class="tm-sharing__button"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="tm-sharing__icon"><path fill="currentColor" d="M10.33.275l9.047 7.572a.2.2 0 010 .306l-9.048 7.572a.2.2 0 01-.328-.153V11c-8 0-9.94 6-9.94 6S-1 5 10 5V.428a.2.2 0 01.328-.153z"></path></svg></button> <!----></div> <DIV class="v-portal" style="display:none;"></DIV></div></div> <!----></div> <!----> <div class="tm-page-article__additional-blocks"><!----> <section class="tm-block tm-block_spacing-bottom"><!----> <div class="tm-block__body"><div class="tm-article-author tm-page-article__author"><div class="tm-article-author__company"><div class="tm-article-author__company-card"><div class="tm-company-snippet"><a href="/ru/company/scalaxy/profile/" class="tm-company-snippet__logo-link"><div class="tm-entity-image"><img alt="" height="40" src="//habrastorage.org/getpro/habr/companies/f40/0aa/5b2/f400aa5b20687ff8671097ec4f4016ed.png" width="40" class="tm-entity-image__pic"></div></a> <div class="tm-company-snippet__info"><a href="/ru/company/scalaxy/profile/" class="tm-company-snippet__title">Оверсан-Скалакси</a> <div class="tm-company-snippet__description">Компания</div></div></div> <div class="tm-article-author__buttons"><!----> <!----></div></div> <!----> <div class="tm-article-author__separator"></div></div> <div class="tm-user-card tm-article-author__user-card tm-user-card_variant-two-column"><div class="tm-user-card__info-container"><div class="tm-user-card__header"><div class="tm-user-card__header-data"><a href="/ru/users/SaveTheRbtz/" class="tm-user-card__userpic tm-user-card__userpic_size-40"><div class="tm-entity-image"><img alt="" src="//habrastorage.org/getpro/habr/avatars/b37/3dd/c4b/b373ddc4b2783a8cbe583cd7eeece149.jpg" class="tm-entity-image__pic"></div></a> <div class="tm-user-card__meta"><div title=" 638 голосов " class="tm-karma tm-user-card__karma"><div class="tm-karma__votes tm-karma__votes_positive">
    452.1
  </div> <div class="tm-karma__text">
    Карма
  </div></div> <div title="Рейтинг пользователя" class="tm-rating tm-user-card__rating"><div class="tm-rating__header"> <div class="tm-rating__counter">0.1</div></div> <div class="tm-rating__text">
    Рейтинг
  </div></div></div></div></div> <div class="tm-user-card__info"><div class="tm-user-card__title"><span class="tm-user-card__name">Алексей</span> <a href="/ru/users/SaveTheRbtz/" class="tm-user-card__nickname">
          @SaveTheRbtz
        </a> <!----></div> <p class="tm-user-card__short-info">SRE</p></div></div> <div class="tm-user-card__buttons tm-user-card__buttons_variant-two-column"><!----> <!----> <!----> <!----> <!----></div></div> <!----></div></div> <!----></section> <div class="tm-page-article__comments"><div class="tm-article-page-comments"><div class="tm-article-comments-counter-link tm-article-comments-counter-button"><a href="/ru/company/scalaxy/blog/83353/comments/" class="tm-article-comments-counter-link__link tm-article-comments-counter-link__link_button-style"><svg height="16" width="16" class="tm-svg-img tm-article-comments-counter-link__icon tm-article-comments-counter-link__icon_contrasted"><title>Комментарии</title> <use xlink:href="/img/megazord-v24.cee85629.svg#counter-comments"></use></svg> <span class="tm-article-comments-counter-link__value tm-article-comments-counter-link__value_contrasted">
       Комментарии 10 
    </span></a> <!----></div></div></div> <!----> <section class="tm-block tm-block_spacing-around"><header class="tm-block__header"><h2 class="tm-block__title">Похожие публикации</h2> <!----></header> <div class="tm-block__body"><ul class="tm-article-list-block__list"><li class="tm-article-list-block__item"><article class="tm-article-snippet-block-block tm-article-snippet-block-block_preview"><div class="tm-article-snippet-block__user-meta"><div class="tm-article-snippet-block__date"><time datetime="2010-02-03T14:01:20.000Z" title="2010-02-03, 17:01">3  февраля  2010 в 17:01</time></div></div> <h2 class="tm-article-title tm-article-title_block"><a href="/ru/company/scalaxy/blog/82997/" class="tm-article-title__link"><span>GPFS. Часть 1. Создание GPFS кластера</span></a></h2> <div class="tm-data-icons"><!----> <div class="tm-votes-meter tm-data-icons__item"><svg height="16" width="16" class="tm-svg-img tm-votes-meter__icon tm-votes-meter__icon_small"><title>Всего голосов 54: ↑44 и ↓10</title> <use xlink:href="/img/megazord-v24.cee85629.svg#counter-rating"></use></svg> <span title="Всего голосов 54: ↑44 и ↓10" class="tm-votes-meter__value tm-votes-meter__value_positive tm-votes-meter__value_small">+34</span></div> <span title="Количество просмотров" class="tm-icon-counter tm-data-icons__item"><svg height="16" width="16" class="tm-svg-img tm-icon-counter__icon"><title>Просмотры</title> <use xlink:href="/img/megazord-v24.cee85629.svg#counter-views"></use></svg> <span class="tm-icon-counter__value">22K</span></span> <button title="Добавить в закладки" type="button" class="bookmarks-button tm-data-icons__item"><span title="Добавить в закладки" class="tm-svg-icon__wrapper bookmarks-button__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Добавить в закладки</title> <use xlink:href="/img/megazord-v24.cee85629.svg#counter-favorite"></use></svg></span> <span title="Количество пользователей, добавивших публикацию в закладки" class="bookmarks-button__counter">
    54
  </span></button> <div title="Читать комментарии" class="tm-article-comments-counter-link tm-data-icons__item"><a href="/ru/company/scalaxy/blog/82997/comments/" class="tm-article-comments-counter-link__link"><svg height="16" width="16" class="tm-svg-img tm-article-comments-counter-link__icon"><title>Комментарии</title> <use xlink:href="/img/megazord-v24.cee85629.svg#counter-comments"></use></svg> <span class="tm-article-comments-counter-link__value">
      27
    </span></a> <!----></div> <!----> <DIV class="v-portal" style="display:none;"></DIV></div></article></li><li class="tm-article-list-block__item"><article class="tm-article-snippet-block-block tm-article-snippet-block-block_preview"><div class="tm-article-snippet-block__user-meta"><div class="tm-article-snippet-block__date"><time datetime="2009-07-23T12:58:52.000Z" title="2009-07-23, 16:58">23  июля  2009 в 16:58</time></div></div> <h2 class="tm-article-title tm-article-title_block"><a href="/ru/company/scalaxy/blog/65228/" class="tm-article-title__link"><span>Cloud computing: кто и как летает в облаках?</span></a></h2> <div class="tm-data-icons"><!----> <div class="tm-votes-meter tm-data-icons__item"><svg height="16" width="16" class="tm-svg-img tm-votes-meter__icon tm-votes-meter__icon_small"><title>Всего голосов 52: ↑43 и ↓9</title> <use xlink:href="/img/megazord-v24.cee85629.svg#counter-rating"></use></svg> <span title="Всего голосов 52: ↑43 и ↓9" class="tm-votes-meter__value tm-votes-meter__value_positive tm-votes-meter__value_small">+34</span></div> <span title="Количество просмотров" class="tm-icon-counter tm-data-icons__item"><svg height="16" width="16" class="tm-svg-img tm-icon-counter__icon"><title>Просмотры</title> <use xlink:href="/img/megazord-v24.cee85629.svg#counter-views"></use></svg> <span class="tm-icon-counter__value">24K</span></span> <button title="Добавить в закладки" type="button" class="bookmarks-button tm-data-icons__item"><span title="Добавить в закладки" class="tm-svg-icon__wrapper bookmarks-button__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Добавить в закладки</title> <use xlink:href="/img/megazord-v24.cee85629.svg#counter-favorite"></use></svg></span> <span title="Количество пользователей, добавивших публикацию в закладки" class="bookmarks-button__counter">
    51
  </span></button> <div title="Читать комментарии" class="tm-article-comments-counter-link tm-data-icons__item"><a href="/ru/company/scalaxy/blog/65228/comments/" class="tm-article-comments-counter-link__link"><svg height="16" width="16" class="tm-svg-img tm-article-comments-counter-link__icon"><title>Комментарии</title> <use xlink:href="/img/megazord-v24.cee85629.svg#counter-comments"></use></svg> <span class="tm-article-comments-counter-link__value">
      66
    </span></a> <!----></div> <!----> <DIV class="v-portal" style="display:none;"></DIV></div></article></li> <!----></ul></div> <!----></section> <!----> <section class="tm-block tm-block_spacing-around"><header class="tm-block__header"><h2 class="tm-block__title">Лучшие публикации за сутки</h2> <!----></header> <div class="tm-block__body"><ul class="tm-article-list-block__list"><li class="tm-article-list-block__item"><article class="tm-article-snippet-block-block tm-article-snippet-block-block_preview"><div class="tm-article-snippet-block__user-meta"><div class="tm-article-snippet-block__date"><time datetime="2021-09-27T09:00:04.000Z" title="2021-09-27, 12:00">вчера в 12:00</time></div></div> <h2 class="tm-article-title tm-article-title_block"><a href="/ru/company/ruvds/blog/580060/" class="tm-article-title__link"><span>Арракис, который мы заслужили</span></a></h2> <div class="tm-data-icons"><!----> <div class="tm-votes-meter tm-data-icons__item"><svg height="16" width="16" class="tm-svg-img tm-votes-meter__icon tm-votes-meter__icon_small"><title>Всего голосов 145: ↑139 и ↓6</title> <use xlink:href="/img/megazord-v24.cee85629.svg#counter-rating"></use></svg> <span title="Всего голосов 145: ↑139 и ↓6" class="tm-votes-meter__value tm-votes-meter__value_positive tm-votes-meter__value_small">+133</span></div> <span title="Количество просмотров" class="tm-icon-counter tm-data-icons__item"><svg height="16" width="16" class="tm-svg-img tm-icon-counter__icon"><title>Просмотры</title> <use xlink:href="/img/megazord-v24.cee85629.svg#counter-views"></use></svg> <span class="tm-icon-counter__value">22K</span></span> <button title="Добавить в закладки" type="button" class="bookmarks-button tm-data-icons__item"><span title="Добавить в закладки" class="tm-svg-icon__wrapper bookmarks-button__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Добавить в закладки</title> <use xlink:href="/img/megazord-v24.cee85629.svg#counter-favorite"></use></svg></span> <span title="Количество пользователей, добавивших публикацию в закладки" class="bookmarks-button__counter">
    40
  </span></button> <div title="Читать комментарии" class="tm-article-comments-counter-link tm-data-icons__item"><a href="/ru/company/ruvds/blog/580060/comments/" class="tm-article-comments-counter-link__link"><svg height="16" width="16" class="tm-svg-img tm-article-comments-counter-link__icon"><title>Комментарии</title> <use xlink:href="/img/megazord-v24.cee85629.svg#counter-comments"></use></svg> <span class="tm-article-comments-counter-link__value">
      114
    </span></a> <!----></div> <!----> <DIV class="v-portal" style="display:none;"></DIV></div></article></li><li class="tm-article-list-block__item"><article class="tm-article-snippet-block-block tm-article-snippet-block-block_preview"><div class="tm-article-snippet-block__user-meta"><div class="tm-article-snippet-block__date"><time datetime="2021-09-27T16:41:21.000Z" title="2021-09-27, 19:41">вчера в 19:41</time></div></div> <h2 class="tm-article-title tm-article-title_block"><a href="/ru/company/lamptest/blog/580228/" class="tm-article-title__link"><span>Идеальная светодиодная лампа за 21 рубль</span></a></h2> <div class="tm-data-icons"><!----> <div class="tm-votes-meter tm-data-icons__item"><svg height="16" width="16" class="tm-svg-img tm-votes-meter__icon tm-votes-meter__icon_small"><title>Всего голосов 82: ↑80 и ↓2</title> <use xlink:href="/img/megazord-v24.cee85629.svg#counter-rating"></use></svg> <span title="Всего голосов 82: ↑80 и ↓2" class="tm-votes-meter__value tm-votes-meter__value_positive tm-votes-meter__value_small">+78</span></div> <span title="Количество просмотров" class="tm-icon-counter tm-data-icons__item"><svg height="16" width="16" class="tm-svg-img tm-icon-counter__icon"><title>Просмотры</title> <use xlink:href="/img/megazord-v24.cee85629.svg#counter-views"></use></svg> <span class="tm-icon-counter__value">11K</span></span> <button title="Добавить в закладки" type="button" class="bookmarks-button tm-data-icons__item"><span title="Добавить в закладки" class="tm-svg-icon__wrapper bookmarks-button__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Добавить в закладки</title> <use xlink:href="/img/megazord-v24.cee85629.svg#counter-favorite"></use></svg></span> <span title="Количество пользователей, добавивших публикацию в закладки" class="bookmarks-button__counter">
    45
  </span></button> <div title="Читать комментарии" class="tm-article-comments-counter-link tm-data-icons__item"><a href="/ru/company/lamptest/blog/580228/comments/" class="tm-article-comments-counter-link__link"><svg height="16" width="16" class="tm-svg-img tm-article-comments-counter-link__icon"><title>Комментарии</title> <use xlink:href="/img/megazord-v24.cee85629.svg#counter-comments"></use></svg> <span class="tm-article-comments-counter-link__value">
      29
    </span></a> <!----></div> <!----> <DIV class="v-portal" style="display:none;"></DIV></div></article></li><li class="tm-article-list-block__item"><article class="tm-article-snippet-block-block tm-article-snippet-block-block_preview"><div class="tm-article-snippet-block__user-meta"><div class="tm-article-snippet-block__date"><time datetime="2021-09-27T13:03:14.000Z" title="2021-09-27, 16:03">вчера в 16:03</time></div></div> <h2 class="tm-article-title tm-article-title_block"><a href="/ru/company/ruvds/blog/580124/" class="tm-article-title__link"><span>Электролюминесцентные индикаторы из прошлого</span></a></h2> <div class="tm-data-icons"><!----> <div class="tm-votes-meter tm-data-icons__item"><svg height="16" width="16" class="tm-svg-img tm-votes-meter__icon tm-votes-meter__icon_small"><title>Всего голосов 75: ↑75 и ↓0</title> <use xlink:href="/img/megazord-v24.cee85629.svg#counter-rating"></use></svg> <span title="Всего голосов 75: ↑75 и ↓0" class="tm-votes-meter__value tm-votes-meter__value_positive tm-votes-meter__value_small">+75</span></div> <span title="Количество просмотров" class="tm-icon-counter tm-data-icons__item"><svg height="16" width="16" class="tm-svg-img tm-icon-counter__icon"><title>Просмотры</title> <use xlink:href="/img/megazord-v24.cee85629.svg#counter-views"></use></svg> <span class="tm-icon-counter__value">5.2K</span></span> <button title="Добавить в закладки" type="button" class="bookmarks-button tm-data-icons__item"><span title="Добавить в закладки" class="tm-svg-icon__wrapper bookmarks-button__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Добавить в закладки</title> <use xlink:href="/img/megazord-v24.cee85629.svg#counter-favorite"></use></svg></span> <span title="Количество пользователей, добавивших публикацию в закладки" class="bookmarks-button__counter">
    37
  </span></button> <div title="Читать комментарии" class="tm-article-comments-counter-link tm-data-icons__item"><a href="/ru/company/ruvds/blog/580124/comments/" class="tm-article-comments-counter-link__link"><svg height="16" width="16" class="tm-svg-img tm-article-comments-counter-link__icon"><title>Комментарии</title> <use xlink:href="/img/megazord-v24.cee85629.svg#counter-comments"></use></svg> <span class="tm-article-comments-counter-link__value">
      13
    </span></a> <!----></div> <!----> <DIV class="v-portal" style="display:none;"></DIV></div></article></li><li class="tm-article-list-block__item"><article class="tm-article-snippet-block-block tm-article-snippet-block-block_preview"><div class="tm-article-snippet-block__user-meta"><div class="tm-article-snippet-block__date"><time datetime="2021-09-27T12:53:02.000Z" title="2021-09-27, 15:53">вчера в 15:53</time></div></div> <h2 class="tm-article-title tm-article-title_block"><a href="/ru/post/580210/" class="tm-article-title__link"><span>PHP Дайджест № 212 (13 – 27 сентября 2021)</span></a></h2> <div class="tm-data-icons"><!----> <div class="tm-votes-meter tm-data-icons__item"><svg height="16" width="16" class="tm-svg-img tm-votes-meter__icon tm-votes-meter__icon_small"><title>Всего голосов 41: ↑41 и ↓0</title> <use xlink:href="/img/megazord-v24.cee85629.svg#counter-rating"></use></svg> <span title="Всего голосов 41: ↑41 и ↓0" class="tm-votes-meter__value tm-votes-meter__value_positive tm-votes-meter__value_small">+41</span></div> <span title="Количество просмотров" class="tm-icon-counter tm-data-icons__item"><svg height="16" width="16" class="tm-svg-img tm-icon-counter__icon"><title>Просмотры</title> <use xlink:href="/img/megazord-v24.cee85629.svg#counter-views"></use></svg> <span class="tm-icon-counter__value">3.7K</span></span> <button title="Добавить в закладки" type="button" class="bookmarks-button tm-data-icons__item"><span title="Добавить в закладки" class="tm-svg-icon__wrapper bookmarks-button__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Добавить в закладки</title> <use xlink:href="/img/megazord-v24.cee85629.svg#counter-favorite"></use></svg></span> <span title="Количество пользователей, добавивших публикацию в закладки" class="bookmarks-button__counter">
    14
  </span></button> <div title="Читать комментарии" class="tm-article-comments-counter-link tm-data-icons__item"><a href="/ru/post/580210/comments/" class="tm-article-comments-counter-link__link"><svg height="16" width="16" class="tm-svg-img tm-article-comments-counter-link__icon"><title>Комментарии</title> <use xlink:href="/img/megazord-v24.cee85629.svg#counter-comments"></use></svg> <span class="tm-article-comments-counter-link__value">
      1
    </span></a> <!----></div> <!----> <DIV class="v-portal" style="display:none;"></DIV></div></article></li><li class="tm-article-list-block__item"><article class="tm-article-snippet-block-block tm-article-snippet-block-block_preview"><div class="tm-article-snippet-block__user-meta"><div class="tm-article-snippet-block__date"><time datetime="2021-09-27T10:50:03.000Z" title="2021-09-27, 13:50">вчера в 13:50</time></div></div> <h2 class="tm-article-title tm-article-title_block"><a href="/ru/company/oleg-bunin/blog/580150/" class="tm-article-title__link"><span>Топ-5 когнитивных искажений при планировании в IT</span></a></h2> <div class="tm-data-icons"><!----> <div class="tm-votes-meter tm-data-icons__item"><svg height="16" width="16" class="tm-svg-img tm-votes-meter__icon tm-votes-meter__icon_small"><title>Всего голосов 40: ↑39 и ↓1</title> <use xlink:href="/img/megazord-v24.cee85629.svg#counter-rating"></use></svg> <span title="Всего голосов 40: ↑39 и ↓1" class="tm-votes-meter__value tm-votes-meter__value_positive tm-votes-meter__value_small">+38</span></div> <span title="Количество просмотров" class="tm-icon-counter tm-data-icons__item"><svg height="16" width="16" class="tm-svg-img tm-icon-counter__icon"><title>Просмотры</title> <use xlink:href="/img/megazord-v24.cee85629.svg#counter-views"></use></svg> <span class="tm-icon-counter__value">6.1K</span></span> <button title="Добавить в закладки" type="button" class="bookmarks-button tm-data-icons__item"><span title="Добавить в закладки" class="tm-svg-icon__wrapper bookmarks-button__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Добавить в закладки</title> <use xlink:href="/img/megazord-v24.cee85629.svg#counter-favorite"></use></svg></span> <span title="Количество пользователей, добавивших публикацию в закладки" class="bookmarks-button__counter">
    54
  </span></button> <div title="Читать комментарии" class="tm-article-comments-counter-link tm-data-icons__item"><a href="/ru/company/oleg-bunin/blog/580150/comments/" class="tm-article-comments-counter-link__link"><svg height="16" width="16" class="tm-svg-img tm-article-comments-counter-link__icon"><title>Комментарии</title> <use xlink:href="/img/megazord-v24.cee85629.svg#counter-comments"></use></svg> <span class="tm-article-comments-counter-link__value">
      7
    </span></a> <!----></div> <!----> <DIV class="v-portal" style="display:none;"></DIV></div></article></li> <!----></ul></div> <!----></section> <!----> <!----></div></div></div> <div class="tm-page__sidebar"><div hl="ru" class="tm-layout-sidebar"><div class="tm-layout-sidebar__placeholder_initial"></div> <div class="tm-sexy-sidebar tm-sexy-sidebar_initial" style="margin-top:0px;"><!----> <section is-sidebar="" class="tm-block tm-block_spacing-bottom"><header class="tm-block__header"><h2 class="tm-block__title">Информация</h2> <!----></header> <div class="tm-block__body"><div class="tm-company-basic-info"><dl class="tm-description-list tm-description-list_variant-columns-nowrap"><dt class="tm-description-list__title tm-description-list__title_variant-columns-nowrap">Дата основания</dt> <dd class="tm-description-list__body tm-description-list__body_variant-columns-nowrap"><time datetime="2008-08-07T20:00:00.000Z" title="2008-08-08, 00:00">8  августа  2008</time></dd></dl> <dl class="tm-description-list tm-description-list_variant-columns-nowrap"><dt class="tm-description-list__title tm-description-list__title_variant-columns-nowrap">Местоположение</dt> <dd class="tm-description-list__body tm-description-list__body_variant-columns-nowrap">
    Россия
  </dd></dl> <dl class="tm-description-list tm-description-list_variant-columns-nowrap"><dt class="tm-description-list__title tm-description-list__title_variant-columns-nowrap">Сайт</dt> <dd class="tm-description-list__body tm-description-list__body_variant-columns-nowrap"><a href="http://scalaxy.ru/" target="_blank" class="tm-company-basic-info__link">
      scalaxy.ru
    </a></dd></dl> <dl class="tm-description-list tm-description-list_variant-columns-nowrap"><dt class="tm-description-list__title tm-description-list__title_variant-columns-nowrap">Численность</dt> <dd class="tm-description-list__body tm-description-list__body_variant-columns-nowrap">
    31–50 человек
  </dd></dl> <dl class="tm-description-list tm-description-list_variant-columns-nowrap"><dt class="tm-description-list__title tm-description-list__title_variant-columns-nowrap">Дата регистрации</dt> <dd class="tm-description-list__body tm-description-list__body_variant-columns-nowrap"><time datetime="2009-07-01T13:43:57.000Z" title="2009-07-01, 17:43">1  июля  2009</time></dd></dl> <!----></div></div> <!----></section> <!----> <section class="tm-block tm-block_spacing-around"><header class="tm-block__header"><h2 class="tm-block__title">Блог на Хабре</h2> <!----></header> <div class="tm-block__body"><ul class="tm-article-list-block__list"><li class="tm-article-list-block__item"><article class="tm-article-snippet-block-sidebar tm-article-snippet-block-sidebar_preview"><div class="tm-article-snippet-block__user-meta"><div class="tm-article-snippet-block__date"><time datetime="2010-05-20T10:40:10.000Z" title="2010-05-20, 14:40">20  мая  2010 в 14:40</time></div></div> <h2 class="tm-article-title tm-article-title_sidebar"><a href="/ru/company/scalaxy/blog/94076/" class="tm-article-title__link"><span>Визит Ехуды Катца в компанию Оверсан-Скалакси</span></a></h2> <div class="tm-data-icons"><!----> <!----> <span title="Количество просмотров" class="tm-icon-counter tm-data-icons__item"><svg height="16" width="16" class="tm-svg-img tm-icon-counter__icon"><title>Просмотры</title> <use xlink:href="/img/megazord-v24.cee85629.svg#counter-views"></use></svg> <span class="tm-icon-counter__value">1.7K</span></span> <!----> <div title="Читать комментарии" class="tm-article-comments-counter-link tm-data-icons__item"><a href="/ru/company/scalaxy/blog/94076/comments/" class="tm-article-comments-counter-link__link"><svg height="16" width="16" class="tm-svg-img tm-article-comments-counter-link__icon"><title>Комментарии</title> <use xlink:href="/img/megazord-v24.cee85629.svg#counter-comments"></use></svg> <span class="tm-article-comments-counter-link__value">
      5
    </span></a> <!----></div> <!----> <DIV class="v-portal" style="display:none;"></DIV></div></article></li><li class="tm-article-list-block__item"><article class="tm-article-snippet-block-sidebar tm-article-snippet-block-sidebar_preview"><div class="tm-article-snippet-block__user-meta"><div class="tm-article-snippet-block__date"><time datetime="2010-04-20T17:49:21.000Z" title="2010-04-20, 21:49">20  апреля  2010 в 21:49</time></div></div> <h2 class="tm-article-title tm-article-title_sidebar"><a href="/ru/company/scalaxy/blog/91554/" class="tm-article-title__link"><span>Наши докладчики на РИФ'е</span></a></h2> <div class="tm-data-icons"><!----> <!----> <span title="Количество просмотров" class="tm-icon-counter tm-data-icons__item"><svg height="16" width="16" class="tm-svg-img tm-icon-counter__icon"><title>Просмотры</title> <use xlink:href="/img/megazord-v24.cee85629.svg#counter-views"></use></svg> <span class="tm-icon-counter__value">1.5K</span></span> <!----> <div title="Читать комментарии" class="tm-article-comments-counter-link tm-data-icons__item"><a href="/ru/company/scalaxy/blog/91554/comments/" class="tm-article-comments-counter-link__link"><svg height="16" width="16" class="tm-svg-img tm-article-comments-counter-link__icon"><title>Комментарии</title> <use xlink:href="/img/megazord-v24.cee85629.svg#counter-comments"></use></svg> <span class="tm-article-comments-counter-link__value">
      17
    </span></a> <!----></div> <!----> <DIV class="v-portal" style="display:none;"></DIV></div></article></li><li class="tm-article-list-block__item"><article class="tm-article-snippet-block-sidebar tm-article-snippet-block-sidebar_preview"><div class="tm-article-snippet-block__user-meta"><div class="tm-article-snippet-block__date"><time datetime="2010-03-22T09:27:02.000Z" title="2010-03-22, 12:27">22  марта  2010 в 12:27</time></div></div> <h2 class="tm-article-title tm-article-title_sidebar"><a href="/ru/company/scalaxy/blog/87312/" class="tm-article-title__link"><span>KIWI Image System: атака клонов</span></a></h2> <div class="tm-data-icons"><!----> <!----> <span title="Количество просмотров" class="tm-icon-counter tm-data-icons__item"><svg height="16" width="16" class="tm-svg-img tm-icon-counter__icon"><title>Просмотры</title> <use xlink:href="/img/megazord-v24.cee85629.svg#counter-views"></use></svg> <span class="tm-icon-counter__value">11K</span></span> <!----> <div title="Читать комментарии" class="tm-article-comments-counter-link tm-data-icons__item"><a href="/ru/company/scalaxy/blog/87312/comments/" class="tm-article-comments-counter-link__link"><svg height="16" width="16" class="tm-svg-img tm-article-comments-counter-link__icon"><title>Комментарии</title> <use xlink:href="/img/megazord-v24.cee85629.svg#counter-comments"></use></svg> <span class="tm-article-comments-counter-link__value">
      24
    </span></a> <!----></div> <!----> <DIV class="v-portal" style="display:none;"></DIV></div></article></li><li class="tm-article-list-block__item"><article class="tm-article-snippet-block-sidebar tm-article-snippet-block-sidebar_preview"><div class="tm-article-snippet-block__user-meta"><div class="tm-article-snippet-block__date"><time datetime="2010-03-12T13:45:07.000Z" title="2010-03-12, 16:45">12  марта  2010 в 16:45</time></div></div> <h2 class="tm-article-title tm-article-title_sidebar"><a href="/ru/company/scalaxy/blog/87302/" class="tm-article-title__link"><span>Chef или как управлять тысячей серверов</span></a></h2> <div class="tm-data-icons"><!----> <!----> <span title="Количество просмотров" class="tm-icon-counter tm-data-icons__item"><svg height="16" width="16" class="tm-svg-img tm-icon-counter__icon"><title>Просмотры</title> <use xlink:href="/img/megazord-v24.cee85629.svg#counter-views"></use></svg> <span class="tm-icon-counter__value">71K</span></span> <!----> <div title="Читать комментарии" class="tm-article-comments-counter-link tm-data-icons__item"><a href="/ru/company/scalaxy/blog/87302/comments/" class="tm-article-comments-counter-link__link"><svg height="16" width="16" class="tm-svg-img tm-article-comments-counter-link__icon"><title>Комментарии</title> <use xlink:href="/img/megazord-v24.cee85629.svg#counter-comments"></use></svg> <span class="tm-article-comments-counter-link__value">
      26
    </span></a> <!----></div> <!----> <DIV class="v-portal" style="display:none;"></DIV></div></article></li><li class="tm-article-list-block__item"><article class="tm-article-snippet-block-sidebar tm-article-snippet-block-sidebar_preview"><div class="tm-article-snippet-block__user-meta"><div class="tm-article-snippet-block__date"><time datetime="2010-02-08T11:05:01.000Z" title="2010-02-08, 14:05">8  февраля  2010 в 14:05</time></div></div> <h2 class="tm-article-title tm-article-title_sidebar"><a href="/ru/company/scalaxy/blog/83353/" aria-current="page" class="tm-article-title__link router-link-exact-active router-link-active"><span>GPFS. Часть 2. Эксплуатация GPFS кластера</span></a></h2> <div class="tm-data-icons"><!----> <!----> <span title="Количество просмотров" class="tm-icon-counter tm-data-icons__item"><svg height="16" width="16" class="tm-svg-img tm-icon-counter__icon"><title>Просмотры</title> <use xlink:href="/img/megazord-v24.cee85629.svg#counter-views"></use></svg> <span class="tm-icon-counter__value">13K</span></span> <!----> <div title="Читать комментарии" class="tm-article-comments-counter-link tm-data-icons__item"><a href="/ru/company/scalaxy/blog/83353/comments/" class="tm-article-comments-counter-link__link"><svg height="16" width="16" class="tm-svg-img tm-article-comments-counter-link__icon"><title>Комментарии</title> <use xlink:href="/img/megazord-v24.cee85629.svg#counter-comments"></use></svg> <span class="tm-article-comments-counter-link__value">
      10
    </span></a> <!----></div> <!----> <DIV class="v-portal" style="display:none;"></DIV></div></article></li> <!----></ul></div> <!----></section></div></div></div></div></div></div></main> <!----></div> <div class="tm-footer-menu"><div class="tm-page-width"><div class="tm-footer-menu__container"><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Ваш аккаунт
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="/kek/v1/auth/habrahabr/?back=/ru/company/scalaxy/blog/83353/&amp;hl=ru" rel="nofollow" target="_self">
                Войти
              </a></li><li class="tm-footer-menu__list-item"><a href="/kek/v1/auth/habrahabr-register/?back=/ru/company/scalaxy/blog/83353/&amp;hl=ru" rel="nofollow" target="_self">
                Регистрация
              </a></li></ul></div></div><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Разделы
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="/ru/" class="footer-menu__item-link router-link-active">
                Публикации
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/news/" class="footer-menu__item-link">
                Новости
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/hubs/" class="footer-menu__item-link">
                Хабы
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/companies/" class="footer-menu__item-link">
                Компании
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/users/" class="footer-menu__item-link">
                Авторы
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/sandbox/" class="footer-menu__item-link">
                Песочница
              </a></li></ul></div></div><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Информация
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="/ru/docs/help/" class="footer-menu__item-link">
                Устройство сайта
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/docs/authors/codex/" class="footer-menu__item-link">
                Для авторов
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/docs/companies/corpblogs/" class="footer-menu__item-link">
                Для компаний
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/docs/docs/transparency/" class="footer-menu__item-link">
                Документы
              </a></li><li class="tm-footer-menu__list-item"><a href="https://account.habr.com/info/agreement" target="_blank">
                Соглашение
              </a></li><li class="tm-footer-menu__list-item"><a href="https://account.habr.com/info/confidential/" target="_blank">
                Конфиденциальность
              </a></li></ul></div></div><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Услуги
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="https://docs.google.com/presentation/d/e/2PACX-1vQLwRfQmXibiUlWaRg-BAc38s7oM3lJiaPju7qmdJsp8ysIvZ_G-Npem0njJLMozE2bPHMpDqiI5hhy/pub?start=false&amp;loop=false&amp;delayms=60000&amp;slide=id.g91a03369cd_4_297" target="_blank">
                Реклама
              </a></li><li class="tm-footer-menu__list-item"><a href="https://habrastorage.org/storage/stuff/habr/service_price.pdf" target="_blank">
                Тарифы
              </a></li><li class="tm-footer-menu__list-item"><a href="https://docs.google.com/presentation/d/e/2PACX-1vQJJds8-Di7BQSP_guHxICN7woVYoN5NP_22ra-BIo4bqnTT9FR6fB-Ku2P0AoRpX0Ds-LRkDeAoD8F/pub?start=false&amp;loop=false&amp;delayms=60000" target="_blank">
                Контент
              </a></li><li class="tm-footer-menu__list-item"><a href="https://tmtm.timepad.ru/" target="_blank">
                Семинары
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/megaprojects/" class="footer-menu__item-link">
                Мегапроекты
              </a></li></ul></div></div></div></div></div> <div class="tm-footer"><div class="tm-page-width"><div class="tm-footer__container"><!----> <div class="tm-footer__social"><a href="https://www.facebook.com/habrahabr.ru" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Facebook</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-facebook"></use></svg></a><a href="https://twitter.com/habr_com" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Twitter</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-twitter"></use></svg></a><a href="https://vk.com/habr" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>VK</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-vkontakte"></use></svg></a><a href="https://telegram.me/habr_com" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Telegram</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-telegram"></use></svg></a><a href="https://www.youtube.com/channel/UCd_sTwKqVrweTt4oAKY5y4w" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Youtube</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-youtube"></use></svg></a><a href="https://zen.yandex.ru/habr" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Яндекс Дзен</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-zen"></use></svg></a></div> <DIV class="v-portal" style="display:none;"></DIV> <button class="tm-footer__link"><!---->
        Настройка языка
      </button> <a href="/ru/about" class="tm-footer__link">
        О сайте
      </a> <a href="/ru/feedback/" class="tm-footer__link">
        Техническая поддержка
      </a> <!----> <a href="/berserk-mode-nope" class="tm-footer__link">
        Вернуться на старую версию
      </a> <div class="tm-footer-copyright"><span class="tm-copyright"><span class="tm-copyright__years">© 2006–2021 </span> <span class="tm-copyright__name">«<a href="https://company.habr.com/" rel="noopener" target="_blank" class="tm-copyright__link">Habr</a>»</span></span></div></div></div></div> <!----> <!----></div> <div class="vue-portal-target"></div></div>
<script>window.__INITIAL_STATE__={"adblock":{"hasAcceptableAdsFilter":false,"hasAdblock":false},"articlesList":{"articlesList":{"65228":{"id":"65228","timePublished":"2009-07-23T12:58:52+00:00","isCorporative":true,"lang":"ru","titleHtml":"Cloud computing: кто и как летает в облаках?","editorVersion":"1.0","postType":"article","postLabels":[],"author":{"id":"48925","alias":"ommo","fullname":null,"avatarUrl":"","speciality":""},"statistics":{"commentsCount":66,"favoritesCount":51,"readingCount":23661,"score":34,"votesCount":52},"hubs":[{"relatedData":null,"id":"10685","alias":"scalaxy","type":"corporative","title":"Блог компании Оверсан-Скалакси","titleHtml":"Блог компании Оверсан-Скалакси","isProfiled":false}],"flows":[],"relatedData":null,"leadData":{"textHtml":"Сегодня «облачными» вычислениями не удивишь никого: они везде и повсюду. А в условиях мирового финансового кризиса многие крупные компании, изначально не обращающие внимания на «облачные» сервисы и услуги, резко перенаправили свои денежные потоки именно туда, осознав давние ошибки и просчеты. В этой статье я не буду рассказывать Вам все о cloud computing’e — это мы сделаем как-нибудь в другой раз. Наша цель — рассказать об обстановке в мире, т.е. рассмотреть вопросы, по типу «кто есть who» в мире «облачных» вычислений.\u003Cbr\u002F\u003E\r\n","imageUrl":null,"buttonTextHtml":"Читать дальше &rarr;","image":null},"status":"published","plannedPublishTime":null,"checked":null,"tags":[{"titleHtml":"cloud computing"},{"titleHtml":"облачные вычисления"},{"titleHtml":"облачный хостинг"},{"titleHtml":"оверсан-скалакси"}]},"65788":{"id":"65788","timePublished":"2009-07-30T14:37:21+00:00","isCorporative":true,"lang":"ru","titleHtml":"Оверсан-Скалакси на iCamp 2009: отчет","editorVersion":"1.0","postType":"article","postLabels":[],"author":{"id":"48925","alias":"ommo","fullname":null,"avatarUrl":"","speciality":""},"statistics":{"commentsCount":36,"favoritesCount":1,"readingCount":3125,"score":14,"votesCount":24},"hubs":[{"relatedData":null,"id":"10685","alias":"scalaxy","type":"corporative","title":"Блог компании Оверсан-Скалакси","titleHtml":"Блог компании Оверсан-Скалакси","isProfiled":false}],"flows":[],"relatedData":null,"leadData":{"textHtml":"Конференции это всегда шумно, многолюдно, но жутко интересно. Особенно, если действо проходит на свежем воздухе, под чистым июльским небом на палубе теплохода, идущего вниз по Волге-матушке. Да, такой была iCamp в этом году. И несмотря на знойную жару, желающих принять участие в не менее горячих обсуждениях меньше не стало. Хотя для нас конференция началась еще на суше, в Нижнем Новгороде…\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"http:\u002F\u002Fscalaxy.ru\u002Fsites\u002Fsite-1\u002Fassets\u002Fic17.jpg?1256136652\"\u002F\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n","imageUrl":null,"buttonTextHtml":"Читать дальше &rarr;","image":null},"status":"published","plannedPublishTime":null,"checked":null,"tags":[{"titleHtml":"icamp2009"},{"titleHtml":"icamp 2009"},{"titleHtml":"оверсан-скалакси"}]},"66213":{"id":"66213","timePublished":"2009-08-04T14:53:28+00:00","isCorporative":true,"lang":"ru","titleHtml":"Оверсан-Скалакси: Мы — команда!","editorVersion":"1.0","postType":"article","postLabels":[],"author":{"id":"48925","alias":"ommo","fullname":null,"avatarUrl":"","speciality":""},"statistics":{"commentsCount":64,"favoritesCount":1,"readingCount":6205,"score":6,"votesCount":60},"hubs":[{"relatedData":null,"id":"10685","alias":"scalaxy","type":"corporative","title":"Блог компании Оверсан-Скалакси","titleHtml":"Блог компании Оверсан-Скалакси","isProfiled":false}],"flows":[],"relatedData":null,"leadData":{"textHtml":"Ни для кого не секрет, что офис — не самое лучшее место для неформального общения и активного отдыха. Конечно, было бы интересно наблюдать за перемещающимися на роликах и велосипедах разработчиками и сисадминами, но… В пятницу работа офиса практически встала — все мысли были только о предстоящем велопробеге длиною в ночь. Даже начальники отделов, сами того не замечая, крутили ногами под своими столами невидимые педали таких же невидимых (но таких желанных!) “железных коней”.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n","imageUrl":null,"buttonTextHtml":"Читать дальше &rarr;","image":null},"status":"published","plannedPublishTime":null,"checked":null,"tags":[{"titleHtml":"оверсан-скалакси"}]},"72283":{"id":"72283","timePublished":"2009-10-13T11:45:58+00:00","isCorporative":true,"lang":"ru","titleHtml":"Движение за эффективность","editorVersion":"1.0","postType":"article","postLabels":[],"author":{"id":"51236","alias":"sclx","fullname":null,"avatarUrl":"\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Favatars\u002F7a4\u002F06d\u002F80c\u002F7a406d80c0c345d12ea7e6749a113a62.png","speciality":""},"statistics":{"commentsCount":31,"favoritesCount":2,"readingCount":2656,"score":-1,"votesCount":45},"hubs":[{"relatedData":null,"id":"10685","alias":"scalaxy","type":"corporative","title":"Блог компании Оверсан-Скалакси","titleHtml":"Блог компании Оверсан-Скалакси","isProfiled":false}],"flows":[],"relatedData":null,"leadData":{"textHtml":"Здравствуй! Мы приветствуем тебя в сообществе Всероссийского Движения за Эффективность, известного также как компания \u003Ca href=\"http:\u002F\u002Fscalaxy.ru\u002F\"\u003E«Оверсан-Скалакси»\u003C\u002Fa\u003E. \u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nНаша компания Оверсан-Скалакси это уникальная команда молодых, но крутых IT-энтузиастов, менее всего готовых следовать замшелым стереотипам и объединённых простой философией. Философия Эффективности это основа нашего бизнеса – мы помогаем нашим клиентам зарабатывать на том, что ещё вчера приносило им обидные, но неизбежные убытки. Мы – специалисты по облачному хостингу, сложной прогрессивной технологии, позволяющей компаниям, связанным с интернет-бизнесом оптимизировать расходы на содержание серверных парков и их обслуживание. Что такое хостинг? Это размещение ресурсов, предназначенных для обслуживания посетителей сайтов на специальных компьютерах, называемых серверами. Что такое облачный хостинг? Это решение при котором сайты с высокой, но нелинейной посетительской нагрузкой (например, новостные ресурсы, социальные сети и т.п.) имеют возможность динамично масштабировать количество ресурсов в соответствии с текущей загрузкой. \u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nИ на этом достаточно про облачный хостинг, всё равно у нас всё время будет возникать желание рассказывать о нём, и мы будем стараться себя ограничивать. Давай лучше дальше про эффективность. Стремление к эффективности научило нас задавать вопрос “Почему?” тогда, когда нам кажется, что есть возможность решить проблему нетрадиционным способом. Почему нужно делать так, как делают все? Почему бы не попробовать решить проблему с другой стороны? Почему? \u003Cbr\u002F\u003E\r\n","imageUrl":null,"buttonTextHtml":"Читать дальше &rarr;","image":null},"status":"published","plannedPublishTime":null,"checked":null,"tags":[{"titleHtml":"облачный хостинг"},{"titleHtml":"оверсан-скалакси"}]},"82997":{"id":"82997","timePublished":"2010-02-03T14:01:20+00:00","isCorporative":true,"lang":"ru","titleHtml":"GPFS. Часть 1. Создание GPFS кластера","editorVersion":"1.0","postType":"article","postLabels":[],"author":{"id":"38942","alias":"SaveTheRbtz","fullname":"Алексей","avatarUrl":"\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Favatars\u002Fb37\u002F3dd\u002Fc4b\u002Fb373ddc4b2783a8cbe583cd7eeece149.jpg","speciality":"SRE"},"statistics":{"commentsCount":27,"favoritesCount":54,"readingCount":21752,"score":34,"votesCount":54},"hubs":[{"relatedData":null,"id":"10685","alias":"scalaxy","type":"corporative","title":"Блог компании Оверсан-Скалакси","titleHtml":"Блог компании Оверсан-Скалакси","isProfiled":false}],"flows":[],"relatedData":null,"leadData":{"textHtml":"\u003Cimg align=\"left\" src=\"http:\u002F\u002Fs40.radikal.ru\u002Fi090\u002F1002\u002F06\u002F267a5c95ad0d.gif\" alt=\"GPFS (General Parallel File System)\" width=\"130\"\u002F\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nПосле одной из моих последних статьей на хабре \u003Ca href=\"http:\u002F\u002Fhabrahabr.ru\u002Fblogs\u002Fserver_side_optimization\u002F70167\u002F\" title=\"серверная оптимизация\"\u003Eпро серверную оптимизацию\u003C\u002Fa\u003E мне прислали множество вопросов про распределенные файловые системы. И теперь я нашел в себе силы и возможности написать про замечательную кластерную файловую систему \u003Cb\u003EGPFS\u003C\u002Fb\u003E.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nОписание тестовой лаборатории:\u003Cbr\u002F\u003E\r\n\u003Cul\u003E\r\n\u003Cli\u003EСервер виртуализации Xen. Dom0 под SLES11\u003C\u002Fli\u003E\r\n\u003Cli\u003E3 Xen DomU виртуальных сервера под quorum-ноды с двумя дополнительно проброшенными блочными устройствами\u003C\u002Fli\u003E\r\n\u003Cli\u003E2 Xen DomU виртуальных сервера под client-ноды\u003C\u002Fli\u003E\r\n\u003C\u002Ful\u003E\u003Cbr\u002F\u003E\r\nТестовый стенд, основанный на технологии Xen, крайне удобен, ибо позволяет на ходу подцеплять\u002Fотцеплять диски от виртуалок, добавлять в них память и процессоры.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n","imageUrl":null,"buttonTextHtml":"Подробнее в примерах","image":null},"status":"published","plannedPublishTime":null,"checked":null,"tags":[{"titleHtml":"gpfs"},{"titleHtml":"распределенные файловые системы"},{"titleHtml":"infiniband"},{"titleHtml":"облачные вычисления"},{"titleHtml":"облачная платформа"}]},"83353":{"id":"83353","timePublished":"2010-02-08T11:05:01+00:00","isCorporative":true,"lang":"ru","titleHtml":"GPFS. Часть 2. Эксплуатация GPFS кластера","leadData":{"textHtml":"\u003Cimg src=\"http:\u002F\u002Fimg23.imageshack.us\u002Fimg23\u002F8917\u002Fibmv.gif\" alt=\"IBM GPFS\" align=\"left\"\u002F\u003EВ продолжение моего \u003Ca href=\"http:\u002F\u002Fhabrahabr.ru\u002Fcompany\u002Fscalaxy\u002Fblog\u002F82997\u002F\"\u003Eпредыдущего поста\u003C\u002Fa\u003E о настройке GPFS-кластера, как и обещал, перехожу к описанию весьма распространённых ситуаций, с которыми можно столкнуться при работе с GPFS.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n","imageUrl":null,"buttonTextHtml":"Читать дальше &rarr;","image":null},"editorVersion":"1.0","postType":"article","postLabels":[],"author":{"scoreStats":{"score":452.1,"votesCount":638},"rating":0.1,"relatedData":null,"contacts":[],"authorContacts":[],"paymentDetails":{"paymentYandexMoney":null,"paymentPayPalMe":null,"paymentWebmoney":null},"id":"38942","alias":"SaveTheRbtz","fullname":"Алексей","avatarUrl":"\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Favatars\u002Fb37\u002F3dd\u002Fc4b\u002Fb373ddc4b2783a8cbe583cd7eeece149.jpg","speciality":"SRE"},"statistics":{"commentsCount":10,"favoritesCount":30,"readingCount":13343,"score":32,"votesCount":46},"hubs":[{"relatedData":null,"id":"10685","alias":"scalaxy","type":"corporative","title":"Блог компании Оверсан-Скалакси","titleHtml":"Блог компании Оверсан-Скалакси","isProfiled":false}],"flows":[],"relatedData":null,"textHtml":"\u003Cdiv xmlns=\"http:\u002F\u002Fwww.w3.org\u002F1999\u002Fxhtml\"\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" alt=\"IBM GPFS\" align=\"left\" data-src=\"http:\u002F\u002Fimg23.imageshack.us\u002Fimg23\u002F8917\u002Fibmv.gif\"\u002F\u003EВ продолжение моего \u003Ca href=\"http:\u002F\u002Fhabrahabr.ru\u002Fcompany\u002Fscalaxy\u002Fblog\u002F82997\u002F\"\u003Eпредыдущего поста\u003C\u002Fa\u003E о настройке GPFS-кластера, как и обещал, перехожу к описанию весьма распространённых ситуаций, с которыми можно столкнуться при работе с GPFS.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ca name=\"habracut\"\u003E\u003C\u002Fa\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cb\u003EИзменение параметров GPFS\u003C\u002Fb\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nПредставим ситуацию, что нам необходимо сменить точку монтирования для нашей GPFS:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs00:~ # mmchfs \u002Fdev\u002Fgpfs0 -T \u002Fgpfs-howto\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nFile system \u002Fdev\u002Fgpfs0 is mounted on nodes:\u003Cbr\u002F\u003E\r\n 10.35.2.66 gpfs04 gpfs-cluster.edu.scalaxy.local 11.05 (3.3.0.2)\u003Cbr\u002F\u003E\r\n 10.35.2.63 gpfs01 gpfs-cluster.edu.scalaxy.local 11.05 (3.3.0.2)\u003Cbr\u002F\u003E\r\n 10.35.2.64 gpfs02 gpfs-cluster.edu.scalaxy.local 11.05 (3.3.0.2)\u003Cbr\u002F\u003E\r\n 10.35.2.65 gpfs03 gpfs-cluster.edu.scalaxy.local 11.05 (3.3.0.2)\u003Cbr\u002F\u003E\r\n 10.35.2.62 gpfs00 gpfs-cluster.edu.scalaxy.local 11.05 (3.3.0.2)\u003Cbr\u002F\u003E\r\nmmchfs: Command failed. Examine previous error messages to determine cause.\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВ ответ мы получили ошибку, что FS примонтирована на нескольких нодах.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nПопытаемся отмонтировать GPFS на всех машинах:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs00:~ # mmumount gpfs0 -a\u003Cbr\u002F\u003E\r\ngpfs04.edu.scalaxy.local: umount: \u002Fgpfs-storage: device is busy.\u003Cbr\u002F\u003E\r\ngpfs04.edu.scalaxy.local: (In some cases useful info about processes that use\u003Cbr\u002F\u003E\r\ngpfs04.edu.scalaxy.local: the device is found by lsof(8) or fuser(1))\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nОбратите внимание, что ошибка приходит от ноды \u003Ci\u003Egpfs04\u003C\u002Fi\u003E, на которой я в данный момент нахожусь в директории \u003Ci\u003E\u002Fgpfs-storage\u003C\u002Fi\u003E. Только после выхода из неё можно без проблем отмонтировать на всех нодах и сменить точку монтирования.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs00:~ # mmchfs \u002Fdev\u002Fgpfs0 -T \u002Fgpfs-howto\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cblockquote\u003EНе все параметры заданные на этапе \u003Ci\u003Emmcrfs\u003C\u002Fi\u003E можно изменить командой \u003Ci\u003Emmchfs\u003C\u002Fi\u003E. Подробнее в мануале.\u003C\u002Fblockquote\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cb\u003EМониторинг GPFS\u003C\u002Fb\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nДавайте теперь примонтируем всё на место и посмотрим, какие есть самые распространённые команды для мониторинга нашей новосозданной GPFS:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs00:~ # mmmount gpfs0 -a\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cblockquote\u003E\u003Ci\u003E-a\u003C\u002Fi\u003E — монтирует все FS на всех нодах кластера\u003C\u002Fblockquote\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nСмотрим, какие ноды есть в кластере:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs00:~ # mmlsnode\u003Cbr\u002F\u003E\r\nGPFS nodeset Node list\u003Cbr\u002F\u003E\r\n------------- -------------------------------------------------------\u003Cbr\u002F\u003E\r\n gpfs-cluster gpfs00 gpfs01 gpfs02 gpfs03 gpfs04\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nСписок NSD в кластере:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs00:~ # mmlsnsd -X\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nDisk name NSD volume ID Device Devtype Node name Remarks \u003Cbr\u002F\u003E\r\n---------------------------------------------------------------------------------------------------\u003Cbr\u002F\u003E\r\n gpfs1nsd 0A23023E4B5DC633 \u002Fdev\u002Fsdb1 generic gpfs00.edu.scalaxy.local server node\u003Cbr\u002F\u003E\r\n gpfs2nsd 0A23023F4B5DC633 \u002Fdev\u002Fsdb1 generic gpfs01.edu.scalaxy.local server node\u003Cbr\u002F\u003E\r\n gpfs3nsd 0A2302404B5DC634 \u002Fdev\u002Fsdb1 generic gpfs02.edu.scalaxy.local server node\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cblockquote\u003E\u003Ci\u003E-X\u003C\u002Fi\u003E — отображает расширенную информацию. Довольно медленная операция, рекомендуется применять только при диагностике неисправностей.\u003Cbr\u002F\u003E\r\n\u003Ci\u003E-F\u003C\u002Fi\u003E — показывает NSD, которые не привязаны к какой-либо FS\u003C\u002Fblockquote\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nМожно посмотреть, сколько осталось места \u002F inode'ов на GPFS:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs00:~ # mmdf gpfs0\u003Cbr\u002F\u003E\r\ndisk disk size failure holds holds&amp;nbsp; free KB    free KB\u003Cbr\u002F\u003E\r\nname   in KB group metadata data in full blocks in fragments\u003Cbr\u002F\u003E\r\n--------------- ------------- -------- -------- ----- -------------------- -------------------\u003Cbr\u002F\u003E\r\nDisks in storage pool: system (Maximum disk size allowed is 125 GB)\u003Cbr\u002F\u003E\r\ngpfs1nsd 2097152 1 yes yes 1934336 ( 92%) 1952 ( 0%)\u003Cbr\u002F\u003E\r\ngpfs2nsd 2097152 2 yes yes 1933312 ( 92%) 2080 ( 0%)\u003Cbr\u002F\u003E\r\ngpfs3nsd 2097152 3 no no 0 ( 0%) 0 ( 0%)\u003Cbr\u002F\u003E\r\n ------------- -------------------- -------------------\u003Cbr\u002F\u003E\r\n(pool total) 6291456 3867648 ( 61%) 4032 ( 0%)\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n============= ==================== ===================\u003Cbr\u002F\u003E\r\n(total) 6291456   3867648 ( 61%) 4032 ( 0%)\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nInode Information\u003Cbr\u002F\u003E\r\n-----------------\u003Cbr\u002F\u003E\r\nNumber of used inodes: 4071\u003Cbr\u002F\u003E\r\nNumber of free inodes: 32793\u003Cbr\u002F\u003E\r\nNumber of allocated inodes: 36864\u003Cbr\u002F\u003E\r\nMaximum number of inodes: 36864\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВ \u003Ca href=\"http:\u002F\u002Fpublib.boulder.ibm.com\u002Finfocenter\u002Fclresctr\u002Fvxrx\u002Findex.jsp?topic=\u002Fcom.ibm.cluster.gpfs33.basicadm.doc\u002Fbl1adm_mmdf.html\"\u003Eдокументации\u003C\u002Fa\u003E написано, что \u003Ci\u003Emmdf\u003C\u002Fi\u003E весьма трудоёмка, и её стоит применять только когда система слабо загружена.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs00:~ # mmlsdisk gpfs0\u003Cbr\u002F\u003E\r\ndisk driver sector failure holds holds storage\u003Cbr\u002F\u003E\r\nname type size group metadata data status availability pool\u003Cbr\u002F\u003E\r\n------------ -------- ------ ------- -------- ----- ------------- ------------ ------------\u003Cbr\u002F\u003E\r\ngpfs1nsd nsd 512 1 yes yes ready up system \u003Cbr\u002F\u003E\r\ngpfs2nsd nsd 512 2 yes yes ready up system \u003Cbr\u002F\u003E\r\ngpfs3nsd nsd 512 3 no no ready up system \u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\ngpfs00:~ # mmlspool gpfs0\u003Cbr\u002F\u003E\r\nStorage pools in file system at '\u002Fgpfs-howto':\u003Cbr\u002F\u003E\r\nName Id BlkSize Data Meta Total Data KB Free Data KB Total Meta KB Free Meta KB\u003Cbr\u002F\u003E\r\nsystem 0 1024 KB yes yes 4194304 3867648 ( 92%) 4194304 3870720 ( 92%)\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nТакже можно посмотреть информацию по кластеру целиком:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs00:~ # mmlscluster\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nGPFS cluster information\u003Cbr\u002F\u003E\r\n========================\u003Cbr\u002F\u003E\r\n GPFS cluster name: gpfs-cluster.edu.scalaxy.local\u003Cbr\u002F\u003E\r\n GPFS cluster id: 730430031139815289\u003Cbr\u002F\u003E\r\n GPFS UID domain: gpfs-cluster.edu.scalaxy.local\u003Cbr\u002F\u003E\r\n Remote shell command: \u002Fusr\u002Fbin\u002Fssh\u003Cbr\u002F\u003E\r\n Remote file copy command: \u002Fusr\u002Fbin\u002Fscp\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nGPFS cluster configuration servers:\u003Cbr\u002F\u003E\r\n-----------------------------------\u003Cbr\u002F\u003E\r\n Primary server: gpfs00.edu.scalaxy.local\u003Cbr\u002F\u003E\r\n Secondary server: gpfs01.edu.scalaxy.local\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nNode Daemon node name IP address Admin node name Designation \u003Cbr\u002F\u003E\r\n-----------------------------------------------------------------------------------------------\u003Cbr\u002F\u003E\r\n 1 gpfs00.edu.scalaxy.local 10.35.2.62 gpfs00.edu.scalaxy.local quorum-manager\u003Cbr\u002F\u003E\r\n 2 gpfs01.edu.scalaxy.local 10.35.2.63 gpfs01.edu.scalaxy.local quorum-manager\u003Cbr\u002F\u003E\r\n 3 gpfs02.edu.scalaxy.local 10.35.2.64   gpfs02.edu.scalaxy.local quorum\u003Cbr\u002F\u003E\r\n  4 gpfs03.edu.scalaxy.local 10.35.2.65 gpfs03.edu.scalaxy.local \u003Cbr\u002F\u003E\r\n 5  gpfs04.edu.scalaxy.local 10.35.2.66 gpfs04.edu.scalaxy.local\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nСледующая команда выводит статус нод в кластере:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs00:\u002Fhome\u002Faivanov # mmgetstate -Lsa\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nNode number Node name Quorum Nodes up Total nodes GPFS state Remarks \u003Cbr\u002F\u003E\r\n------------------------------------------------------------------------------------\u003Cbr\u002F\u003E\r\n 1 gpfs00 2 3 5 active quorum node\u003Cbr\u002F\u003E\r\n 2 gpfs01 2 3 5 active quorum node\u003Cbr\u002F\u003E\r\n 3 gpfs02 2 3 5 active quorum node\u003Cbr\u002F\u003E\r\n 4 gpfs03 2 3 5 active \u003Cbr\u002F\u003E\r\n 5 gpfs04 2 3 5 active \u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nSummary information\u003Cbr\u002F\u003E\r\n---------------------\u003Cbr\u002F\u003E\r\nNumber of nodes defined in the cluster: 5\u003Cbr\u002F\u003E\r\nNumber of local nodes active in the cluster: 5\u003Cbr\u002F\u003E\r\nNumber of remote nodes joined in this cluster: 0\u003Cbr\u002F\u003E\r\nNumber of quorum nodes defined in the cluster:   3\u003Cbr\u002F\u003E\r\nNumber of quorum nodes active in the cluster: 3\u003Cbr\u002F\u003E\r\nQuorum = 2, Quorum achieved\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cblockquote\u003E\u003Ci\u003E-a\u003C\u002Fi\u003E — для всех нод кластера\u003Cbr\u002F\u003E\r\n\u003Ci\u003E-L\u003C\u002Fi\u003E — отображать кворум, количество поднятых нод, общее количество нод и дополнительную информацию\u003Cbr\u002F\u003E\r\n\u003Ci\u003E-s\u003C\u002Fi\u003E — отображать summary\u003C\u002Fblockquote\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nGPFS state бывают следующие:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cblockquote\u003E\u003Ci\u003Eactive\u003C\u002Fi\u003E — всё ОК\u003Cbr\u002F\u003E\r\n\u003Ci\u003Earbitrating\u003C\u002Fi\u003E — нода пытается присоединится к кворуму\u003Cbr\u002F\u003E\r\n\u003Ci\u003Edown\u003C\u002Fi\u003E — GPFS демон не запущен или перезапускается\u003Cbr\u002F\u003E\r\n\u003Ci\u003Eunknown\u003C\u002Fi\u003E — статус машины неизвестен. В большинстве случаев означает, что машина недоступна по сети\u003C\u002Fblockquote\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nПосмотреть какие лицензии установлены и на каких нодах можно следующей командой:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs00:~ # mmlslicense -L\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nNode name Required license Designated license\u003Cbr\u002F\u003E\r\n-------------------------------------------------------------------\u003Cbr\u002F\u003E\r\ngpfs00.edu.scalaxy.local server server\u003Cbr\u002F\u003E\r\ngpfs01.edu.scalaxy.local server server\u003Cbr\u002F\u003E\r\ngpfs02.edu.scalaxy.local server server\u003Cbr\u002F\u003E\r\ngpfs03.edu.scalaxy.local client client\u003Cbr\u002F\u003E\r\ngpfs04.edu.scalaxy.local client client\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nSummary information\u003Cbr\u002F\u003E\r\n---------------------\u003Cbr\u002F\u003E\r\nNumber of nodes defined in the cluster: 5\u003Cbr\u002F\u003E\r\nNumber of nodes with server license designation: 3\u003Cbr\u002F\u003E\r\nNumber of nodes with client license designation: 2\u003Cbr\u002F\u003E\r\nNumber of nodes still requiring server license designation: 0\u003Cbr\u002F\u003E\r\nNumber of nodes still requiring client license designation: 0\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cblockquote\u003E\u003Ci\u003E-L\u003C\u002Fi\u003E — детальная информация по лицензиям, а не только summary\u003C\u002Fblockquote\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nТакже можно посмотреть текущую конфигурацию кластера, но так как я на тестовых виртуалках не пользовался командой \u003Ci\u003E\u003Ca href=\"http:\u002F\u002Fpublib.boulder.ibm.com\u002Finfocenter\u002Fclresctr\u002Fvxrx\u002Findex.jsp?topic=\u002Fcom.ibm.cluster.gpfs33.basicadm.doc\u002Fbl1adm_mmchcl.html\"\u003Emmchconfig\u003C\u002Fa\u003E\u003C\u002Fi\u003E, то она будет весьма не информативной.\u003Cbr\u002F\u003E\r\n \u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs00:~ # mmlsconfig\u003Cbr\u002F\u003E\r\nConfiguration data for cluster gpfs-cluster.edu.scalaxy.local:\u003Cbr\u002F\u003E\r\n--------------------------------------------------------------\u003Cbr\u002F\u003E\r\nclusterName gpfs-cluster.edu.scalaxy.local\u003Cbr\u002F\u003E\r\nclusterId 730430031139815289\u003Cbr\u002F\u003E\r\nautoload yes\u003Cbr\u002F\u003E\r\nminReleaseLevel 3.3.0.2\u003Cbr\u002F\u003E\r\ndmapiFileHandleSize 32\u003Cbr\u002F\u003E\r\n[gpfs02]\u003Cbr\u002F\u003E\r\nunmountOnDiskFail yes\u003Cbr\u002F\u003E\r\n[common]\u003Cbr\u002F\u003E\r\nadminMode central\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nFile systems in cluster gpfs-cluster.edu.scalaxy.local:\u003Cbr\u002F\u003E\r\n-------------------------------------------------------\u003Cbr\u002F\u003E\r\n\u002Fdev\u002Fgpfs0\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ch4\u003EМанипуляции со структурой GPFS\u003C\u002Fh4\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nНаполняем GPFS-диск:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Ecp -r \u002Fusr\u002Fsrc\u002Flinux\u002F* \u002Fgpfs-howto\u002F\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cb\u003EДобавление дисков в GPFS\u003C\u002Fb\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nДавайте теперь сделаем ещё пару NSD дисков на \u003Ci\u003Egpfs00.edu.scalaxy.local\u003C\u002Fi\u003E и \u003Ci\u003Egpfs01.edu.scalaxy.local\u003C\u002Fi\u003E.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nПроцедура уже была \u003Ca href=\"http:\u002F\u002Fhabrahabr.ru\u002Fcompany\u002Fscalaxy\u002Fblog\u002F82997\u002F\"\u003Eописана\u003C\u002Fa\u003E ранее:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs00:~ # cat &lt;&lt;EOF \u003E\u003Egpfs.00.disk\u003Cbr\u002F\u003E\r\n\u002Fdev\u002Fsdb2:gpfs00.edu.scalaxy.local::dataAndMetadata:1\u003Cbr\u002F\u003E\r\nEOF\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\ngpfs00:~ # cat &lt;&lt;EOF \u003E\u003Egpfs.01.disk\u003Cbr\u002F\u003E\r\n\u002Fdev\u002Fsdb2:gpfs01.edu.scalaxy.local::dataAndMetadata:2\u003Cbr\u002F\u003E\r\nEOF\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\ngpfs00:~ # mmcrnsd -F gpfs.00.disk -v no\u003Cbr\u002F\u003E\r\ngpfs00:~ # mmcrnsd -F gpfs.01.disk -v no\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nТеперь сама \u003Ca href=\"http:\u002F\u002Fpublib.boulder.ibm.com\u002Finfocenter\u002Fclresctr\u002Fvxrx\u002Findex.jsp?topic=\u002Fcom.ibm.cluster.gpfs33.basicadm.doc\u002Fbl1adm_mmchcl.html\"\u003Eпроцедура добавления дисков\u003C\u002Fa\u003E в gpfs0:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs00:~ # mmadddisk gpfs0 -F gpfs.00.disk\u003Cbr\u002F\u003E\r\nThe following disks of gpfs0 will be formatted on node gpfs00.edu.scalaxy.local:\u003Cbr\u002F\u003E\r\n gpfs8nsd: size 2097152 KB\u003Cbr\u002F\u003E\r\nExtending Allocation Map\u003Cbr\u002F\u003E\r\nChecking Allocation Map for storage pool 'system'\u003Cbr\u002F\u003E\r\nCompleted adding disks to file system gpfs0.\u003Cbr\u002F\u003E\r\nmmadddisk: Propagating the cluster configuration data to all\u003Cbr\u002F\u003E\r\n affected nodes. This is an asynchronous process.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\ngpfs00:~ # mmadddisk gpfs0 -F gpfs.01.disk\u003Cbr\u002F\u003E\r\nThe following disks of gpfs0 will be formatted on node gpfs00.edu.scalaxy.local:\u003Cbr\u002F\u003E\r\n gpfs9nsd: size 2097152 KB\u003Cbr\u002F\u003E\r\nExtending Allocation Map\u003Cbr\u002F\u003E\r\nChecking Allocation Map for storage pool 'system'\u003Cbr\u002F\u003E\r\nCompleted adding disks to file system gpfs0.\u003Cbr\u002F\u003E\r\nmmadddisk: Propagating the cluster configuration data to all\u003Cbr\u002F\u003E\r\n affected nodes. This is an asynchronous process.\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nТакже у \u003Ci\u003Emmadddisk\u003C\u002Fi\u003E есть параметр \u003Ci\u003E-r\u003C\u002Fi\u003E, который перераспределяет файлы по файловой системе с учётом новых дисков. Мы же этот флаг не используем, а в место него будем применять \u003Ci\u003Emmrestripefs\u003C\u002Fi\u003E.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nЕсли теперь посмотреть на вывод команды \u003Ci\u003Emmdf\u003C\u002Fi\u003E:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs00:~ # mmdf gpfs0\u003Cbr\u002F\u003E\r\ndisk disk size failure holds holds free KB free KB\u003Cbr\u002F\u003E\r\nname in KB group metadata data in full blocks in fragments\u003Cbr\u002F\u003E\r\n--------------- ------------- -------- -------- ----- -------------------- -------------------\u003Cbr\u002F\u003E\r\nDisks in storage pool: system (Maximum disk size allowed is 125 GB)\u003Cbr\u002F\u003E\r\ngpfs1nsd 2097152 1 yes yes 911360 ( 43%) 27712 ( 1%)\u003Cbr\u002F\u003E\r\ngpfs8nsd 2097152 1 yes yes 2094080 (100%) 992 ( 0%)\u003Cbr\u002F\u003E\r\ngpfs9nsd 2097152 2 yes yes 2094080 (100%) 992 ( 0%)\u003Cbr\u002F\u003E\r\ngpfs2nsd 2097152 2 yes yes 904192 ( 43%) 34880 ( 2%)\u003Cbr\u002F\u003E\r\ngpfs3nsd 2097152 3 no no 0 ( 0%) 0 ( 0%)\u003Cbr\u002F\u003E\r\n ------------- -------------------- -------------------\u003Cbr\u002F\u003E\r\n(pool total) 10485760 6003712 ( 57%) 64576 ( 1%)\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n============= ==================== ===================\u003Cbr\u002F\u003E\r\n(total) 10485760 6003712 ( 57%) 64576 ( 1%)\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nInode Information\u003Cbr\u002F\u003E\r\n-----------------\u003Cbr\u002F\u003E\r\nNumber of used inodes: 31531\u003Cbr\u002F\u003E\r\nNumber of free inodes: 5333\u003Cbr\u002F\u003E\r\nNumber of allocated inodes: 36864\u003Cbr\u002F\u003E\r\nMaximum number of inodes: 36864\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nто видно, что диски заняты неравномерно. Дабы \u003Ca href=\"http:\u002F\u002Fpublib.boulder.ibm.com\u002Finfocenter\u002Fclresctr\u002Fvxrx\u002Findex.jsp?topic=\u002Fcom.ibm.cluster.gpfs33.basicadm.doc\u002Fbl1adm_mmrestr.html\"\u003Eэто исправить\u003C\u002Fa\u003E набираем:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs00:~ # mmrestripefs gpfs0 -b\u003Cbr\u002F\u003E\r\nScanning file system metadata, phase 1 ...\u003Cbr\u002F\u003E\r\nScan completed successfully.\u003Cbr\u002F\u003E\r\nScanning file system metadata, phase 2 ...\u003Cbr\u002F\u003E\r\nScan completed successfully.\u003Cbr\u002F\u003E\r\nScanning file system metadata, phase 3 ...\u003Cbr\u002F\u003E\r\nScan completed successfully.\u003Cbr\u002F\u003E\r\nScanning file system metadata, phase 4 ...\u003Cbr\u002F\u003E\r\nScan completed successfully.\u003Cbr\u002F\u003E\r\nScanning user file metadata ...\u003Cbr\u002F\u003E\r\n 11.64 % complete on Wed Jan 27 22:45:13 2010 ( 7435 inodes 502 MB)\u003Cbr\u002F\u003E\r\n 18.72 % complete on Wed Jan 27 22:45:33 2010 ( 12453 inodes 807 MB)\u003Cbr\u002F\u003E\r\n 25.88 % complete on Wed Jan 27 22:45:53 2010 ( 18590 inodes 1116 MB)\u003Cbr\u002F\u003E\r\n 33.05 % complete on Wed Jan 27 22:46:13 2010 ( 24020 inodes 1425 MB)\u003Cbr\u002F\u003E\r\n 39.77 % complete on Wed Jan 27 22:46:33 2010 ( 28585 inodes 1715 MB)\u003Cbr\u002F\u003E\r\n 46.10 % complete on Wed Jan 27 22:46:54 2010 ( 32828 inodes 1988 MB)\u003Cbr\u002F\u003E\r\n 100.00 % complete on Wed Jan 27 22:47:06 2010\u003Cbr\u002F\u003E\r\nScan completed successfully.\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nПосле чего GPFS рестрайпит данные на разделе:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs00:~ # mmdf gpfs0\u003Cbr\u002F\u003E\r\ndisk disk size failure holds holds free KB free KB\u003Cbr\u002F\u003E\r\nname in KB group metadata data in full blocks in fragments\u003Cbr\u002F\u003E\r\n--------------- ------------- -------- -------- ----- -------------------- -------------------\u003Cbr\u002F\u003E\r\nDisks in storage pool: system (Maximum disk size allowed is 125 GB)\u003Cbr\u002F\u003E\r\ngpfs1nsd 2097152 1 yes yes 635904 ( 30%) 808768 (39%)\u003Cbr\u002F\u003E\r\ngpfs8nsd 2097152 1 yes yes 1421312 ( 68%) 168160 ( 8%)\u003Cbr\u002F\u003E\r\ngpfs9nsd   2097152 2 yes yes 1431552 ( 68%) 166944 ( 8%)\u003Cbr\u002F\u003E\r\ngpfs2nsd 2097152 2 yes yes 615424 ( 29%) 820224 (39%)\u003Cbr\u002F\u003E\r\ngpfs3nsd 2097152 3 no no 0 ( 0%) 0 ( 0%)\u003Cbr\u002F\u003E\r\n ------------- -------------------- -------------------\u003Cbr\u002F\u003E\r\n(pool total) 10485760 4104192 ( 39%) 1964096 (19%)\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n============= ==================== ===================\u003Cbr\u002F\u003E\r\n(total) 10485760 4104192 ( 39%) 1964096 (19%)\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cb\u003EДобавление нод в кластер\u003C\u002Fb\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nДалее «на живую» перетащим дополнительные диски из quorum-виртуалок в nonquourum, и поднимем их статус до quorum.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nДля начала удалим дополнительные диски у \u003Ci\u003Egpfs00.edu.scalaxy.local\u003C\u002Fi\u003E и \u003Ci\u003Egpfs01.edu.scalaxy.local\u003C\u002Fi\u003E:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs00:~ # mmdeldisk gpfs0 gpfs8nsd -b\u003Cbr\u002F\u003E\r\ngpfs00:~ # mmdeldisk gpfs0 gpfs9nsd -b\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cblockquote\u003E\u003Ci\u003E-b\u003C\u002Fi\u003E — говорит \u003Ci\u003Emmdeldisk\u003C\u002Fi\u003E перераспределить данные на файловой системе таким образом, как это сделал бы последующий запуск \u003Ci\u003Emmrestripefs\u003C\u002Fi\u003E\u003C\u002Fblockquote\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nПроцесс удаления диска с параметром \u003Ci\u003E-b\u003C\u002Fi\u003E весьма похож на \u003Ci\u003Emmrestripefs\u003C\u002Fi\u003E, так что вывод команды указывать не буду.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВ случае какой-либо ошибки \u003Ci\u003Emmdeldisk\u003C\u002Fi\u003E напишет:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003EAttention: No disks were deleted, but some data was migrated.\u003Cbr\u002F\u003E\r\n The file system may no longer be properly balanced.\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nЭто означает, что диск удалён не был, но файловая система перестала быть сбалансированной, и её требуется «отрестрайпить».\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nТеперь, используя флаг \u003Ci\u003E-F\u003C\u002Fi\u003E, \u003Ca href=\"http:\u002F\u002Fpublib.boulder.ibm.com\u002Finfocenter\u002Fclresctr\u002Fvxrx\u002Findex.jsp?topic=\u002Fcom.ibm.cluster.gpfs33.basicadm.doc\u002Fbl1adm_mmlsnsd.html\"\u003Eможно увидеть NSD\u003C\u002Fa\u003E, которые не присвоены никакой файловой системе:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs00:~ # mmlsnsd -F\u003Cbr\u002F\u003E\r\n File system Disk name NSD servers \u003Cbr\u002F\u003E\r\n---------------------------------------------------------------------------\u003Cbr\u002F\u003E\r\n (free disk) gpfs8nsd gpfs00.edu.scalaxy.local\u003Cbr\u002F\u003E\r\n (free disk) gpfs9nsd gpfs01.edu.scalaxy.local\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nУдалим эти NSD \u003Ca href=\"http:\u002F\u002Fpublib.boulder.ibm.com\u002Finfocenter\u002Fclresctr\u002Fvxrx\u002Findex.jsp?topic=\u002Fcom.ibm.cluster.gpfs33.basicadm.doc\u002Fbl1adm_mmdelns.html\"\u003Eнасовсем\u003C\u002Fa\u003E:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs00:~ # mmdelnsd gpfs9nsd\u003Cbr\u002F\u003E\r\ngpfs00:~ # mmdelnsd gpfs8nsd\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nДалее, в \u003Cb\u003EXEN Dom0\u003C\u002Fb\u003E нужно перетащить «на живую» блочные устройства с машин \u003Ci\u003Egpfs00.edu.scalaxy.local\u003C\u002Fi\u003E и \u003Ci\u003Egpfs01.edu.scalaxy.local\u003C\u002Fi\u003E на \u003Ci\u003Egpfs03.edu.scalaxy.local\u003C\u002Fi\u003E и \u003Ci\u003Egpfs04.edu.scalaxy.local\u003C\u002Fi\u003E соответственно.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003EDom0-0212:~ # xm shell\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nСмотрим id'шники устройств:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Exm\u003E xm block-list gpfs00.edu.scalaxy.local\u003Cbr\u002F\u003E\r\nxm\u003E xm block-list gpfs01.edu.scalaxy.local\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nУдаляем со старых машин:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Exm\u003E xm block-detach gpfs00.edu.scalaxy.local 2066\u003Cbr\u002F\u003E\r\nxm\u003E xm block-detach gpfs01.edu.scalaxy.local 2066\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nДобавляем на новые:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Exm\u003E xm block-attach gpfs03.edu.scalaxy.local phy:\u002Fdev\u002Fuser\u002Fgpfs00-disk1 sdb1 w\u003Cbr\u002F\u003E\r\nxm\u003E xm block-attach gpfs04.edu.scalaxy.local phy:\u002Fdev\u002Fuser\u002Fgpfs01-disk1 sdb1 w\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nПомните, в \u003Ca href=\"http:\u002F\u002Fhabrahabr.ru\u002Fcompany\u002Fscalaxy\u002Fblog\u002F82997\u002F\"\u003Eпервой части\u003C\u002Fa\u003E я говорил про то, как удобен Xen для тестов? =)\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nМеняем лицензии двух других машинах на серверные:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs00:~ # mmchlicense server --accept -N gpfs04.edu.scalaxy.local,gpfs03.edu.scalaxy.local\u003Cbr\u002F\u003E\r\ngpfs00:~ # mmlslicense\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nSummary information\u003Cbr\u002F\u003E\r\n---------------------\u003Cbr\u002F\u003E\r\nNumber of nodes defined in the cluster: 5\u003Cbr\u002F\u003E\r\nNumber of nodes with server license designation: 5\u003Cbr\u002F\u003E\r\nNumber of nodes with client license designation: 0\u003Cbr\u002F\u003E\r\nNumber of nodes still requiring server license designation: 0\u003Cbr\u002F\u003E\r\nNumber of nodes still requiring client license designation: 0\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\ngpfs00:~ # cat &lt;&lt;EOF \u003E\u003E gpfs.03.disk\u003Cbr\u002F\u003E\r\n\u002Fdev\u002Fsdb1:gpfs03.edu.scalaxy.local::dataAndMetadata:1\u003Cbr\u002F\u003E\r\nEOF\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\ngpfs00:~ # cat &lt;&lt;EOF \u003E\u003E gpfs.04.disk\u003Cbr\u002F\u003E\r\n\u002Fdev\u002Fsdb1:gpfs04.edu.scalaxy.local::dataAndMetadata:2\u003Cbr\u002F\u003E\r\nEOF\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nДля чистоты эксперимента удаляем всё, что было на \u003Ci\u003Egpfs0\u003C\u002Fi\u003E и запускаем копирование на GPFS исходников Linux в фоне:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs00:~ # cp -r \u002Fusr\u002Fsrc\u002Flinux\u002F* \u002Fgpfs-howto\u002F&amp;\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nСоздаём NSD из свежеподключённых дисков и добавляем эти NSD в \u003Ci\u003Egpfs0\u003C\u002Fi\u003E:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs00:~ # mmcrnsd -F gpfs.03.disk -v no\u003Cbr\u002F\u003E\r\ngpfs00:~ # mmadddisk gpfs0 -F gpfs.03.disk\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\ngpfs00:~ # mmcrnsd -F gpfs.04.disk -v no\u003Cbr\u002F\u003E\r\ngpfs00:~ # mmadddisk gpfs0 -F gpfs.04.disk\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nЗаметьте, что всё это время у нас производилось копирование файлов на GPFS.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nТеперь на любой из нод можем проверить, что все файлы на месте:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs02:\u002Fgpfs-howto # ls\u003Cbr\u002F\u003E\r\narch Documentation init lib net REPORTING-BUGS usr\u003Cbr\u002F\u003E\r\nblock drivers ipc .mailmap .patches samples virt\u003Cbr\u002F\u003E\r\nCOPYING firmware Kbuild MAINTAINERS perfmon scripts\u003Cbr\u002F\u003E\r\nCREDITS fs kdb Makefile README security\u003Cbr\u002F\u003E\r\ncrypto include kernel mm README.SUSE sound\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nТак как мы добавили диски только на середине копирования файлов, а в \u003Ci\u003Emmadddisk\u003C\u002Fi\u003E мы не использовали опцию \u003Ci\u003E-r\u003C\u002Fi\u003E, то в выводе \u003Ci\u003Emmdf\u003C\u002Fi\u003E мы увидим несбалансированность распределения файлов на GPFS. Так что нам потребуется выполнить уже известную процедуру:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs00:~ # mmrestripefs gpfs0 -b\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cb\u003EРазваливаем GPFS кластер\u003C\u002Fb\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nКаждая единица данных и метаданных в GPFS-кластере хранится в максимум двух экземплярах. Поэтому, чтобы часть данных стала недоступна, нам нужно положить 2 ноды из разных failure-групп. Чтобы развалить кластер нам нужно либо не соблюсти quorum по дискам (более половины дисков \u003Ci\u003Edown\u003C\u002Fi\u003E), либо по нодам (более половины нод окажется недоступно, например при \u003Ci\u003Enet split\u003C\u002Fi\u003E).\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nМы развалим кворум по дискам, положив 2 ноды в разных failure-группах, тем самым нарушив quorum по дискам:\u003Cbr\u002F\u003E\r\n \u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs03:~ # halt\u003Cbr\u002F\u003E\r\ngpfs04:~ # halt\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nПроверяем, что показывает статус:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs00:~ # mmgetstate -Lsa\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nNode number Node name Quorum Nodes up Total nodes GPFS state Remarks \u003Cbr\u002F\u003E\r\n------------------------------------------------------------------------------------\u003Cbr\u002F\u003E\r\n 1 gpfs00 2 3 5 active quorum node\u003Cbr\u002F\u003E\r\n 2 gpfs01 2 3 5 active quorum node\u003Cbr\u002F\u003E\r\n 3 gpfs02 2 3 5 active quorum node\u003Cbr\u002F\u003E\r\n 4 gpfs03 0 0 5 unknown \u003Cbr\u002F\u003E\r\n 5 gpfs04 0 0 5 unknown \u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nSummary information\u003Cbr\u002F\u003E\r\n---------------------\u003Cbr\u002F\u003E\r\nNumber of nodes defined in the cluster: 5\u003Cbr\u002F\u003E\r\nNumber of local nodes active in the cluster: 3\u003Cbr\u002F\u003E\r\nNumber of remote nodes joined in this cluster: 0\u003Cbr\u002F\u003E\r\nNumber of quorum nodes defined in the cluster: 3\u003Cbr\u002F\u003E\r\nNumber of quorum nodes active in the cluster:  3\u003Cbr\u002F\u003E\r\nQuorum = 2, Quorum achieved\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВидим, что quorum по нодам соблюдён, однако:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs00:~ # ls \u002Fgpfs-howto\u003Cbr\u002F\u003E\r\nls: cannot access \u002Fgpfs-howto: Stale NFS file handle\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nЛоги, \u003Ci\u003Emmlsdisk\u003C\u002Fi\u003E и \u003Ci\u003Emmlsnsd\u003C\u002Fi\u003E показывают, что 2 диска отвалились:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs00:~ # grep \"mmfs:\" \u002Fvar\u002Flog\u002Fmessages\u003Cbr\u002F\u003E\r\nJan 28 12:36:14 gpfs00 mmfs: Error=MMFS_DISKFAIL, ID=0x9C6C05FA, Tag=6368843: Disk failure. Volume gpfs0. rc = 5. Physical volume gpfs10nsd\u003Cbr\u002F\u003E\r\nJan 28 14:43:11 gpfs00 mmfs: Error=MMFS_DISKFAIL, ID=0x9C6C05FA, Tag=6368846: Disk failure. Volume gpfs0. rc = 19. Physical volume gpfs11nsd\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\ngpfs00:~ # less \u002Fvar\u002Fadm\u002Fras\u002Fmmfs.log.latest\u003Cbr\u002F\u003E\r\nThu Jan 28 12:36:14.863 2010: Disk failure from node 10.35.2.64 (gpfs02) Volume\u003Cbr\u002F\u003E\r\ngpfs0. Physical volume gpfs10nsd.\u003Cbr\u002F\u003E\r\nThu Jan 28 14:43:11.688 2010: Disk failure. Volume gpfs0. rc = 19. Physical vol\u003Cbr\u002F\u003E\r\nume gpfs11nsd.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\ngpfs00:~ # mmlsdisk gpfs0 -L\u003Cbr\u002F\u003E\r\ndisk driver sector failure holds holds storage\u003Cbr\u002F\u003E\r\nname type size group metadata data status availability disk id pool remarks \u003Cbr\u002F\u003E\r\n------------ -------- ------ ------- -------- ----- ------------- ------------ ------- ------------ ---------\u003Cbr\u002F\u003E\r\ngpfs1nsd nsd 512 1 yes yes ready up 1 system desc\u003Cbr\u002F\u003E\r\ngpfs2nsd nsd 512 2 yes yes ready up 2 system desc\u003Cbr\u002F\u003E\r\ngpfs3nsd nsd 512 3 no no ready up 3 system desc\u003Cbr\u002F\u003E\r\ngpfs10nsd nsd 512 1 yes yes ready down 4 system desc\u003Cbr\u002F\u003E\r\ngpfs11nsd nsd 512 2 yes yes ready down 5 system desc\u003Cbr\u002F\u003E\r\nNumber of quorum disks: 5\u003Cbr\u002F\u003E\r\nRead quorum value: 3\u003Cbr\u002F\u003E\r\nWrite quorum value: 3\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\ngpfs00:~ # mmlsnsd -X\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nDisk name NSD volume ID Device Devtype Node name Remarks \u003Cbr\u002F\u003E\r\n---------------------------------------------------------------------------------------------------\u003Cbr\u002F\u003E\r\n gpfs10nsd 0A2302414B6154F4 - - gpfs03.edu.scalaxy.local (not found) server node\u003Cbr\u002F\u003E\r\n gpfs11nsd 0A2302424B6154F8 - - gpfs04.edu.scalaxy.local (not found) server node\u003Cbr\u002F\u003E\r\n gpfs1nsd 0A23023E4B5DC633 \u002Fdev\u002Fsdb1 generic gpfs00.edu.scalaxy.local server node\u003Cbr\u002F\u003E\r\n gpfs2nsd 0A23023F4B5DC633 \u002Fdev\u002Fsdb1 generic gpfs01.edu.scalaxy.local server node\u003Cbr\u002F\u003E\r\n gpfs3nsd 0A2302404B5DC634 \u002Fdev\u002Fsdb1 generic gpfs02.edu.scalaxy.local server node\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nmmlsnsd: The following nodes could not be reached:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\ngpfs03.edu.scalaxy.local\u003Cbr\u002F\u003E\r\ngpfs04.edu.scalaxy.local\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cb\u003EВосстановление GPFS кластера после сбоя\u003C\u002Fb\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nЗапускаем все остановленные виртуалки с \u003Cb\u003EDom0\u003C\u002Fb\u003E:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003EDom0-0212:\u002Fetc\u002Fxen\u002Fvm # for i in gpfs*.edu.scalaxy.local ; do xm create $i; done\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nПосле загрузки машин проверим, поднялся ли GPFS-демон на серверах:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs00:~ # mmgetstate -a\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nNode number Node name GPFS state\u003Cbr\u002F\u003E\r\n------------------------------------------\u003Cbr\u002F\u003E\r\n 1 gpfs00 active\u003Cbr\u002F\u003E\r\n 2 gpfs01 active\u003Cbr\u002F\u003E\r\n 3 gpfs02 active\u003Cbr\u002F\u003E\r\n 4 gpfs03 active\u003Cbr\u002F\u003E\r\n 5 gpfs04 active\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nПосле того, как машины запустились, прилегающие к ним NSD-устройства остаются в состоянии «down» и не поднимаются автоматически. Сделано это из-за того, что причины смерти системы могут быть совершенно разные, и оператор должен сам решить, стоит ли эту систему отправлять обратно в бой или нет. Если же наблюдается серьёзная проблема с системой, то, чтобы подстраховаться от двойного сбоя, лучше выполнить \u003Ci\u003Emmrestripefs -m\u003C\u002Fi\u003E, которая мигрирует данные и метаданные, которые, в свою очередь, после выхода из строя одной машины остались в единичном экземпляре. Однако, данную команду лучше использовать с умом, ибо она потребляет много ресурсов и занимает кучу времени.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nОднако, вернувшись к нашему GPFSу: чтобы вернуть в строй диски и собрать заново GPFS, нужно выполнить команду:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs00:~ # mmchdisk gpfs0 start -a\u003Cbr\u002F\u003E\r\nScanning file system metadata, phase 1 ...\u003Cbr\u002F\u003E\r\nScan completed successfully.\u003Cbr\u002F\u003E\r\nScanning file system metadata, phase 2 ...\u003Cbr\u002F\u003E\r\nScan completed successfully.\u003Cbr\u002F\u003E\r\nScanning file system metadata, phase 3 ...\u003Cbr\u002F\u003E\r\nScan completed successfully.\u003Cbr\u002F\u003E\r\nScanning file system metadata, phase 4 ...\u003Cbr\u002F\u003E\r\nScan completed successfully.\u003Cbr\u002F\u003E\r\nScanning user file metadata ...\u003Cbr\u002F\u003E\r\n 100.00 % complete on Thu Jan 28 16:38:47 2010\u003Cbr\u002F\u003E\r\nScan completed successfully.\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nПараметр \u003Ci\u003E-a\u003C\u002Fi\u003E запустит все остановленные диски.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВ случае, если какой-то диск не поднялся — команда может выдать ошибку:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003ENo such device\u003Cbr\u002F\u003E\r\nInitial disk state was updated successfully, but another error may have changed the state again.\u003Cbr\u002F\u003E\r\nmmchdisk: Command failed. Examine previous error messages to determine cause.\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nКоманда \u003Ci\u003Emmlsdisk\u003C\u002Fi\u003E пометит этот диск как «unrecovered»:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs00:~ # mmlsdisk gpfs0\u003Cbr\u002F\u003E\r\ndisk driver sector failure holds holds storage\u003Cbr\u002F\u003E\r\nname type size group metadata data status availability pool\u003Cbr\u002F\u003E\r\n------------ -------- ------ ------- -------- ----- ------------- ------------ ------------\u003Cbr\u002F\u003E\r\ngpfs1nsd nsd 512 1 yes yes ready up system \u003Cbr\u002F\u003E\r\ngpfs2nsd nsd 512 2 yes yes ready up system \u003Cbr\u002F\u003E\r\ngpfs3nsd nsd 512 3 no no ready up system \u003Cbr\u002F\u003E\r\ngpfs10nsd nsd 512 2 yes yes ready up system \u003Cbr\u002F\u003E\r\ngpfs11nsd nsd 512 1 yes yes ready unrecovered system\u003C\u002Fcode\u003E \u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nНо даже с одним мёртвым NSD файловая система будет вполне работоспособна на всех нодах кластера.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВ нашем случае, с дисками всё нормально и наш мини-кластер собрался нормально, так что необходимо примонтировать GPFS-раздел на всех нодах командой:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs00:~ # mmmount gpfs0 -a\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nПосле сборки развалившегося кластера проверим, действительно ли все данные выжили:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs00:~ # diff -ru \u002Fusr\u002Fsrc\u002Flinux\u002F \u002Fgpfs-howto\u002F\u003Cbr\u002F\u003E\r\ngpfs00:~ #\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nДа, все данные оказались нетронутыми даже после полного развала всего кластера.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nТеперь можно удалить подключённые для теста диски, с ребалансировкой данных:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs00:~ # mmdeldisk gpfs0 gpfs10nsd -b\u003Cbr\u002F\u003E\r\nDeleting disks ...\u003Cbr\u002F\u003E\r\nScanning system storage pool\u003Cbr\u002F\u003E\r\nScanning file system metadata, phase 1 ...\u003Cbr\u002F\u003E\r\nScan completed successfully.\u003Cbr\u002F\u003E\r\nScanning file system metadata, phase 2 ...\u003Cbr\u002F\u003E\r\nScan completed successfully.\u003Cbr\u002F\u003E\r\nScanning file system metadata, phase 3 ...\u003Cbr\u002F\u003E\r\nScan completed successfully.\u003Cbr\u002F\u003E\r\nScanning file system metadata, phase 4 ...\u003Cbr\u002F\u003E\r\nScan completed successfully.\u003Cbr\u002F\u003E\r\nScanning user file metadata ...\u003Cbr\u002F\u003E\r\n 100.00 % complete on Thu Jan 28 17:18:41 2010\u003Cbr\u002F\u003E\r\nScan completed successfully.\u003Cbr\u002F\u003E\r\nChecking Allocation Map for storage pool 'system'\u003Cbr\u002F\u003E\r\ntsdeldisk completed.\u003Cbr\u002F\u003E\r\nmmdeldisk: Propagating the cluster configuration data to all\u003Cbr\u002F\u003E\r\n affected nodes. This is an asynchronous process.\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nЕсли одновременно с другого узла попытаться удалить ещё один диск, то мы будем ждать пока предыдущая операция освободит Lock:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs01:~ # mmdeldisk gpfs0 gpfs6nsd -b\u003Cbr\u002F\u003E\r\nmmdeldisk: The main GPFS cluster configuration file is locked. Retrying...\u003Cbr\u002F\u003E\r\nmmdeldisk: Lock creation successful.\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nЕсли GPFS поймёт, что после удаления диска файлы не влезут на файловую систему, то \u003Ci\u003Emmdeldisk\u003C\u002Fi\u003E выдаст следующую ошибку:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003EDeleting disks ...\u003Cbr\u002F\u003E\r\nScanning system storage pool\u003Cbr\u002F\u003E\r\nScanning file system metadata, phase 1 ...\u003Cbr\u002F\u003E\r\nError processing inodes.\u003Cbr\u002F\u003E\r\nNo space left on device\u003Cbr\u002F\u003E\r\nAttention: No disks were deleted, but some data was migrated.\u003Cbr\u002F\u003E\r\n The file system may no longer be properly balanced.\u003Cbr\u002F\u003E\r\ntsdeldisk completed.\u003Cbr\u002F\u003E\r\nmmdeldisk: tsdeldisk failed.\u003Cbr\u002F\u003E\r\nVerifying file system configuration information ...\u003Cbr\u002F\u003E\r\nmmdeldisk: Propagating the cluster configuration data to all\u003Cbr\u002F\u003E\r\n affected nodes. This is an asynchronous process.\u003Cbr\u002F\u003E\r\nmmdeldisk: Command failed. Examine previous error messages to determine cause.\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cb\u003EПадение quorum-ноды при копировании файлов\u003C\u002Fb\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nТеперь мы «положим» нашу \u003Ci\u003Egpfs00.edu.scalaxy.local\u003C\u002Fi\u003E во время интенсивной работы с диском другими нодами.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nЯ проверял бесперебойность работы на команде:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs03:\u002Fgpfs-howto# dd if=\u002Fdev\u002Fzero bs=1M | pv | dd of=zero03 bs=1M\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cblockquote\u003EОбратите внимание, что размер буфера равен страйпу файловой системы, заданному на этапе \u003Ci\u003Emmcrfs\u003C\u002Fi\u003E\u003C\u002Fblockquote\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nМашину я «прибивал» как \u003Ci\u003Eshutdown -h now\u003C\u002Fi\u003E так и \u003Ci\u003Exm destroy\u003C\u002Fi\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВсё прошло успешно — поднятия и остановки \u003Ci\u003Egpfs00.edu.scalaxy.local\u003C\u002Fi\u003E никак не повлияли на скорость копирования.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cb\u003EЧто происходит при нехватке inode'ов\u003C\u002Fb\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВспомним наш пример с исходниками Linux. При создании файловой системы мы неправильно выбрали размер блока потому, что файлы исходников крайне малы и им никак не подходит размер блока 1M, а соответственно, минимальный размер файла будет равняться 32Kb.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs04:\u002Fgpfs-howto # make oldconfig\u003Cbr\u002F\u003E\r\ngpfs04:\u002Fgpfs-howto # make\u003Cbr\u002F\u003E\r\n.....\u003Cbr\u002F\u003E\r\n.....\u003Cbr\u002F\u003E\r\nfs\u002Fdmapi\u002Fdmapi_session.c:1824: fatal error: opening dependency file fs\u002Fdmapi\u002F.dmapi_session.o.d: No space left on device\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВот и всё, inode'ы кончились, можем это проверить:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs04:\u002Fgpfs-howto # mmdf gpfs0 -F\u003Cbr\u002F\u003E\r\nInode Information\u003Cbr\u002F\u003E\r\n-----------------\u003Cbr\u002F\u003E\r\nNumber of used inodes: 36864\u003Cbr\u002F\u003E\r\nNumber of free inodes: 0\u003Cbr\u002F\u003E\r\nNumber of allocated inodes: 36864\u003Cbr\u002F\u003E\r\nMaximum number of inodes: 36864\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nЕсли посмотреть лог, то будет видно, что на самом деле GPFS предупредил нас об этом заранее, правда мы этого не увидели:\u003Cbr\u002F\u003E\r\n \u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs04:\u002Fgpfs-howto # grep \"mmfs:\" \u002Fvar\u002Flog\u002Fmessages\u003Cbr\u002F\u003E\r\nJan 25 22:36:31 gpfs01 mmfs: Error=MMFS_SYSTEM_WARNING, ID=0x4DC797C6, Tag=6153238: File system warning. Volume gpfs0. Reason: File system gpfs0 is approaching the limit for the maximum number of inodes\u002Ffiles.\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nЧтобы решить эту проблему нужно увеличить количество inode'ов:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs00:~ # mmchfs gpfs0 -F 100000\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nТакже желательно не оставлять на GPFS inode'ов меньше 5%:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cblockquote\u003EFor file systems that will be creating parallel files, if the total number of free inodes is not greater than 5% of the total number of inodes, file system access might slow down. Take this into consideration when creating your file system\u003C\u002Fblockquote\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cb\u003EСнапшоты в GPFS\u003C\u002Fb\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nИх я опишу совсем вкратце.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВозьмём README файл линукса и скопируем его на GPFS:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs00:~ # cp \u002Fusr\u002Fsrc\u002Flinux\u002FREADME \u002Fgpfs-howto\u002F\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ca href=\"http:\u002F\u002Fpublib.boulder.ibm.com\u002Finfocenter\u002Fclresctr\u002Fvxrx\u002Findex.jsp?topic=\u002Fcom.ibm.cluster.gpfs33.basicadm.doc\u002Fbl1adm_crsnap.html\"\u003EСделаем снапшот\u003C\u002Fa\u003E файловой системы:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs00:~ # mmcrsnapshot gpfs0 gpfs-snapshot-`date +%Y-%m-%d`\u003Cbr\u002F\u003E\r\nWriting dirty data to disk\u003Cbr\u002F\u003E\r\nQuiescing all file system operations\u003Cbr\u002F\u003E\r\nWriting dirty data to disk again\u003Cbr\u002F\u003E\r\nCreating snapshot.\u003Cbr\u002F\u003E\r\nResuming operations.\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nУдаляем файл, который только что скопировали:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs00:~ # rm \u002Fgpfs-howto\u002FREADME\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nИ смотрим, остался ли он жив в подпапке \u003Ci\u003E.snapshots\u003C\u002Fi\u003E:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs00:~ # ls -al \u002Fgpfs-howto\u002F.snapshots\u002Fgpfs-snapshot-2010-01-28\u002F\u003Cbr\u002F\u003E\r\n-rw-r--r-- 1 root root 16930 2010-01-26 19:58 README\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cb\u003EТесты производительности GPFS\u003C\u002Fb\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nТесты, скорее всего выложу позже, когда развернём всё это на InfiniBand-ферме, а не на 5-ти виртуалках в одном Dom0.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nТесты производительности, которые обитают в интернете, в основном направлены на сравнении производительности MPI-I\u002FO vs POSIX, threaded I\u002FO, block sizes. Интересные сравнения можно посмотреть тут:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ca href=\"http:\u002F\u002Fwww.nersc.gov\u002Fnews\u002Freports\u002Ftechnical\u002Fseaborg_scaling\u002Fio.php\"\u003Ewww.nersc.gov\u002Fnews\u002Freports\u002Ftechnical\u002Fseaborg_scaling\u002Fio.php\u003C\u002Fa\u003E\u003Cbr\u002F\u003E\r\n\u003Ca href=\"http:\u002F\u002Farcos.inf.uc3m.es\u002F~dcio\u002FALEX-gpfs.ppt\"\u003Ehttp:\u002F\u002Farcos.inf.uc3m.es\u002F~dcio\u002FALEX-gpfs.ppt\u003C\u002Fa\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cb\u003EЧто осталось за кадром?\u003C\u002Fb\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cul\u003E\r\n\u003Cli\u003EКвоты\u003C\u002Fli\u003E\r\n\u003Cli\u003EПолитики\u003C\u002Fli\u003E\r\n\u003Cli\u003EПулы\u003C\u002Fli\u003E\r\n\u003Cli\u003EFilesets\u003C\u002Fli\u003E\r\n\u003Cli\u003EDMAPI\u003C\u002Fli\u003E\r\n\u003Cli\u003EWindows и AIX специфика GPFS\u003C\u002Fli\u003E\r\n\u003C\u002Ful\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n… а также доверенный доступ GPFS-кластеров друг к другу и внутренний API gpfs, через который можно вытянуть метаданные миллиарда файлов за пару секунд :)\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nЗа кадром осталась и замечательная команда, которая может всё-всё-всё =)\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003Egpfs00:~ # mmfsadm\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ccode\u003EEnter commands (type \"help\" or \"?\" for help):\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nmmfsadm\u003E help\u003Cbr\u002F\u003E\r\nCommands:\u003Cbr\u002F\u003E\r\ndump what Dump data structures and statistics, where 'what' can be:\u003Cbr\u002F\u003E\r\n alloc, alloc all, alloc stats, allocmgr, allocmgr all,\u003Cbr\u002F\u003E\r\n allocmgr stats, allocmgr hint, brt, buffers, cfgmgr,\u003Cbr\u002F\u003E\r\n condvar, config, DACspy, dealloc, dealloc stats,\u003Cbr\u002F\u003E\r\n dealloc all, disk, dmapi, eventsExporter, files, filesets,\u003Cbr\u002F\u003E\r\n filocks, fs, fsck, fsmgr, ialloc, ialloc all, iallocmgr,\u003Cbr\u002F\u003E\r\n iallocmgr all, indblocks, indirect, instance, iocounters,\u003Cbr\u002F\u003E\r\n iohist, kthread, llfile, lock, log, lstat, malloc, mb,\u003Cbr\u002F\u003E\r\n mmap, mutex, mutex all, nsd, pcache, perfmon,\u003Cbr\u002F\u003E\r\n pgalloc, pgalloc all, pit, quorumState, quota, reclock,\u003Cbr\u002F\u003E\r\n reclockSleepers, reclockStats, res, sanergy, sgmgr, stripe,\u003Cbr\u002F\u003E\r\n sxlock, thread, thread all, threadstacks, threadstats,\u003Cbr\u002F\u003E\r\n tmstats, tokenmgr, tokens, tmcomm, updatelogger,\u003Cbr\u002F\u003E\r\n disk, verbs, version, vfsstats, vnodes, waiters, winsec,\u003Cbr\u002F\u003E\r\n or all\u003Cbr\u002F\u003E\r\nsaferdump what Like the dump command but with safety locks. (Might hang)\u003Cbr\u002F\u003E\r\neventsExporter Control event exporter\u003Cbr\u002F\u003E\r\nshowCfgValue parm Show the value of the requested parameter\u003Cbr\u002F\u003E\r\nshowtrace Show current trace levels and trace flag settings\u003Cbr\u002F\u003E\r\nshowprocs Display the process table\u003Cbr\u002F\u003E\r\nvfsstats [keyword] Display vfs statistics. Keywords are enable, disable,\u003Cbr\u002F\u003E\r\n reset, show\u003Cbr\u002F\u003E\r\nverifytrace Verify trace levels and trace flag settings\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\ntrace class n Set level for given trace class to n, where \"class\" can be:\u003Cbr\u002F\u003E\r\n alloc, allocmgr, basic, brl, cleanup, cmd, defrag,\u003Cbr\u002F\u003E\r\n dentryexit, disk, dmapi, ds, errlog, fs, fsck,\u003Cbr\u002F\u003E\r\n kentryexit, io, klockl, ksvfs, lock, log, malloc, mb,\u003Cbr\u002F\u003E\r\n memmgr, mnode, msg, mutex, perfmon, pgalloc, pin, pit,\u003Cbr\u002F\u003E\r\n quota, sp, tasking, thread, tm, ts, user1, user2, vnode,\u003Cbr\u002F\u003E\r\n vnop, block, dentry, ialloc, file, super, shared, nsd,\u003Cbr\u002F\u003E\r\n disklease, smb, eventsExporter, sec, sanergy, kernel,\u003Cbr\u002F\u003E\r\n mmpmon, vdisk, rdma, pcache, vdb, vhosp, or all\u003Cbr\u002F\u003E\r\nshutdown -or- sd Shutdown the system\u003Cbr\u002F\u003E\r\ncleanup Clean up the shared segment, etc.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nquorum reset or n Set quorum to value n or reset\u003Cbr\u002F\u003E\r\ntokenmgr Token manager command\u003Cbr\u002F\u003E\r\nrecOrient create\u002F{open inodeNum} create\u002Fopen record oriented file and run debug function\u003Cbr\u002F\u003E\r\ndumpmem addr [len] [width]\u003Cbr\u002F\u003E\r\n Dump memory at address addr (hex) for length len (decimal)\u003Cbr\u002F\u003E\r\n using given word width\u003Cbr\u002F\u003E\r\ntest what Invoke test routine in mmfsd. The \"what\" string is\u003Cbr\u002F\u003E\r\n interpreted by the daemon\u003Cbr\u002F\u003E\r\nerrlog on\u002Foff Activate or deactivate error logging\u003Cbr\u002F\u003E\r\nerrlog query Display error logging info\u003Cbr\u002F\u003E\r\nquiesce Disable new sessions\u003Cbr\u002F\u003E\r\nresume Enable new sessions\u003Cbr\u002F\u003E\r\nnomessages Accept no session messages at all\u003Cbr\u002F\u003E\r\nresume thread Resume the thread with the given address\u003Cbr\u002F\u003E\r\nsignalcond cond Signal the condition variable with the given address\u003Cbr\u002F\u003E\r\nsleep n.m Sleep for requested number of seconds (floating point\u003Cbr\u002F\u003E\r\n number, so fractional seconds are allowed.) Sleeps the\u003Cbr\u002F\u003E\r\n mmfsadm command parser, not the daemon.\u003Cbr\u002F\u003E\r\nwritecore [type] Write a core dump without terminating the daemon.\u003Cbr\u002F\u003E\r\ngraceperiod [t] Start grace period for t seconds.\u003Cbr\u002F\u003E\r\n set t to 0 to get default grace period.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nexit, quit -or- q Terminate this program\u003C\u002Fcode\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cb\u003EСсылки по теме\u003C\u002Fb\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cul\u003E\r\n\u003Cli\u003E\u003Ca href=\"http:\u002F\u002Fpublib.boulder.ibm.com\u002Finfocenter\u002Fclresctr\u002Fvxrx\u002Findex.jsp?topic=\u002Fcom.ibm.cluster.gpfs33.diagnosis.doc\u002Fbl1pdg11_xtoc.html\"\u003EGPFS V3.3 Advanced Administration Guide\u003C\u002Fa\u003E\u003Cbr\u002F\u003E\r\n\u003C\u002Fli\u003E\r\n\u003Cli\u003E\u003Ca href=\"http:\u002F\u002Fpublib.boulder.ibm.com\u002Finfocenter\u002Fclresctr\u002Fvxrx\u002Findex.jsp?topic=\u002Fcom.ibm.cluster.gpfs33.basicadm.doc\u002Fbl1adm11_xtoc.html\"\u003EGPFS V3.3 Administration and Programming Reference\u003C\u002Fa\u003E\u003C\u002Fli\u003E\r\n\u003Cli\u003E\u003Ca href=\"http:\u002F\u002Fpublib.boulder.ibm.com\u002Finfocenter\u002Fclresctr\u002Fvxrx\u002Findex.jsp?topic=\u002Fcom.ibm.cluster.gpfs33.install.doc\u002Fbl1ins11_xtoc.html\"\u003EGPFS V3.3 Concepts, Planning, and Installation Guide\u003C\u002Fa\u003E\u003C\u002Fli\u003E\r\n\u003Cli\u003E\u003Ca href=\"http:\u002F\u002Fpublib.boulder.ibm.com\u002Finfocenter\u002Fclresctr\u002Fvxrx\u002Findex.jsp?topic=\u002Fcom.ibm.cluster.gpfs33.diagnosis.doc\u002Fbl1pdg11_xtoc.html\"\u003EGPFS V3.3 Problem Determination Guide\u003C\u002Fa\u003E\u003C\u002Fli\u003E\r\n\u003Cli\u003E\u003Ca href=\"http:\u002F\u002Fpublib.boulder.ibm.com\u002Finfocenter\u002Fclresctr\u002Fvxrx\u002Findex.jsp?topic=\u002Fcom.ibm.cluster.gpfs33.dmapi.doc\u002Fbl1dmp11_xtoc.html\"\u003EGPFS V3.3 Data Management API Guide\u003C\u002Fa\u003E\u003C\u002Fli\u003E\r\n\u003Cli\u003E\u003Ca href=\"http:\u002F\u002Fbook.opensourceproject.org.cn\u002Fenterprise\u002Fcluster\u002Fibmcluster\u002Findex.html?page=opensource\u002F7819\u002Fddu0080.html\"\u003ELinux Clustering with CSM and GPFS Linux Clustering with CSM and GPFS\u003C\u002Fa\u003E\u003C\u002Fli\u003E\r\n\u003Cli\u003E\u003Ca href=\"http:\u002F\u002Fwww.ibm.com\u002Fdeveloperworks\u002Fforums\u002Fforum.jspa?forumID=479\"\u003EGeneral Parallel File System (GPFS) Forum\u003C\u002Fa\u003E\u003C\u002Fli\u003E\r\n\u003Cli\u003E\u003Ca href=\"http:\u002F\u002Fwww.ibm.com\u002Fdeveloperworks\u002Fforums\u002Fforum.jspa?forumID=1606&amp;start=0\"\u003EGeneral Parallel File System — Announce (GPFS — Announce) Forum\u003C\u002Fa\u003E\u003C\u002Fli\u003E\r\n\u003Cli\u003E\u003Ca href=\"http:\u002F\u002Fdocs.google.com\u002Fviewer?a=v&amp;q=cache:_vIGaw5NX98J:www.cs.berkeley.edu\u002F~andreye\u002Fpapers\u002Fgpfs_dr.pdf+DescOnly+GPFS&amp;hl=ru&amp;gl=ru&amp;sig=AHIEtbT8546CoPxEP7LDkIIo2haLiaHbWw\"\u003EDisaster Recovery with General Parallel File System\u003C\u002Fa\u003E\u003C\u002Fli\u003E\r\n\u003Cli\u003E\u003Ca href=\"http:\u002F\u002Fdocs.google.com\u002Fviewer?a=v&amp;q=cache:_vIGaw5NX98J:www.cs.berkeley.edu\u002F~andreye\u002Fpapers\u002Fgpfs_dr.pdf+DescOnly+GPFS&amp;hl=ru&amp;gl=ru&amp;sig=AHIEtbT8546CoPxEP7LDkIIo2haLiaHbWw\"\u003EDisaster Recovery with General Parallel File System\u003C\u002Fa\u003E\u003C\u002Fli\u003E\r\n\u003Cli\u003E\u003Ca href=\"http:\u002F\u002Fwww.linux.org.ru\u002Fwiki\u002Fen\u002FGPFS\"\u003EGPFS@LOR\u003C\u002Fa\u003E\u003C\u002Fli\u003E\r\n\u003Cli\u003E\u003Ca href=\"https:\u002F\u002Fhelp.ubuntu.com\u002Fcommunity\u002FSettingUpGPFSHowTo\"\u003EGPFS@Ubuntu\u003C\u002Fa\u003E\u003C\u002Fli\u003E\r\n\u003Cli\u003E\u003Ca href=\"http:\u002F\u002Fwww.ibm.com\u002Fdeveloperworks\u002Fwikis\u002Fdisplay\u002Fhpccentral\u002FGeneral+Parallel+File+System+%28GPFS%29\"\u003EGPFS@IBM wiki\u003C\u002Fa\u003E\u003Cbr\u002F\u003E\r\n\u003C\u002Fli\u003E\r\n\u003C\u002Ful\u003E\u003C\u002Fdiv\u003E","tags":[{"titleHtml":"gpfs"},{"titleHtml":"распределенные файловые системы"},{"titleHtml":"infiniband"},{"titleHtml":"облачные вычисления"},{"titleHtml":"облачная платформа"}],"metadata":{"stylesUrls":[],"scriptUrls":[],"shareImageUrl":"https:\u002F\u002Fhabr.com\u002Fshare\u002Fpublication\u002F83353\u002F501bbfd6798b8ee4103d4d6c2e293789\u002F","shareImageWidth":1200,"shareImageHeight":630,"vkShareImageUrl":"https:\u002F\u002Fhabr.com\u002Fshare\u002Fpublication\u002F83353\u002F501bbfd6798b8ee4103d4d6c2e293789\u002F?format=vk","schemaJsonLd":"{\"@context\":\"http:\\\u002F\\\u002Fschema.org\",\"@type\":\"Article\",\"mainEntityOfPage\":{\"@type\":\"WebPage\",\"@id\":\"https:\\\u002F\\\u002Fhabr.com\\\u002Fru\\\u002Fcompany\\\u002Fscalaxy\\\u002Fblog\\\u002F83353\\\u002F\"},\"headline\":\"GPFS. Часть 2. Эксплуатация GPFS кластера\",\"datePublished\":\"2010-02-08T14:05:01+03:00\",\"dateModified\":\"2010-03-29T22:52:32+04:00\",\"author\":{\"@type\":\"Person\",\"name\":\"Алексей\"},\"publisher\":{\"@type\":\"Organization\",\"name\":\"Habr\",\"logo\":{\"@type\":\"ImageObject\",\"url\":\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fa_\\\u002Flk\\\u002F9m\\\u002Fa_lk9mjkccjox-zccjrpfolmkmq.png\"}},\"description\":\"В продолжение моего предыдущего поста о настройке GPFS-кластера, как и обещал, перехожу к описанию весьма распространённых ситуаций, с которыми можно столкнуться...\",\"url\":\"https:\\\u002F\\\u002Fhabr.com\\\u002Fru\\\u002Fcompany\\\u002Fscalaxy\\\u002Fblog\\\u002F83353\\\u002F#post-content-body\",\"about\":[\"c_scalaxy\"],\"image\":[\"http:\\\u002F\\\u002Fimg23.imageshack.us\\\u002Fimg23\\\u002F8917\\\u002Fibmv.gif\"]}","metaDescription":"В продолжение моего предыдущего поста о настройке GPFS-кластера, как и обещал, перехожу к описанию весьма распространённых ситуаций, с которыми можно столкнуться при работе с...","mainImageUrl":null,"amp":false},"polls":[],"commentsEnabled":true,"votesEnabled":true,"status":"published","plannedPublishTime":null,"checked":null,"isEditorial":false},"87302":{"id":"87302","timePublished":"2010-03-12T13:45:07+00:00","isCorporative":true,"lang":"ru","titleHtml":"Chef или как управлять тысячей серверов","editorVersion":"1.0","postType":"article","postLabels":[],"author":{"id":"38942","alias":"SaveTheRbtz","fullname":"Алексей","avatarUrl":"\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Favatars\u002Fb37\u002F3dd\u002Fc4b\u002Fb373ddc4b2783a8cbe583cd7eeece149.jpg","speciality":"SRE"},"statistics":{"commentsCount":26,"favoritesCount":336,"readingCount":71445,"score":85,"votesCount":97},"hubs":[{"relatedData":null,"id":"10685","alias":"scalaxy","type":"corporative","title":"Блог компании Оверсан-Скалакси","titleHtml":"Блог компании Оверсан-Скалакси","isProfiled":false}],"flows":[],"relatedData":null,"leadData":{"textHtml":"\u003Cimg src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fpost_images\u002F9c6\u002Fbb5\u002Fef6\u002F9c6bb5ef658bd1e86c0ddecb07a2852c.jpg\" align=\"left\" alt=\"Suck on my chocolate salty balls (c) Chef\"\u002F\u003EДавайте каждый попробует ответить на вопрос: как установить apache на сервер? Этот вопрос порождает ещё десяток: какая ОС стоит на сервере, какую версию ставить, где лежат конфиги по-умолчанию и т.д. и т.п.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nА теперь давайте попробуем ответить на вопрос: как установить apache на 1000 серверов? Тут, при стандартном подходе, вопросов возникнет ровно в 1000 раз больше. Часть из вас наверняка подумали, что можно написать скрипт на shell\u002Fperl\u002Fpython\u002Fruby, который будет обходить все сервера и устанавливать apache, другая часть подумала о distributed shell'ах (\u003Ca href=\"http:\u002F\u002Fsourceforge.net\u002Fprojects\u002Fpdsh\"\u003EPDsh\u003C\u002Fa\u003E, \u003Ca href=\"http:\u002F\u002Fwww.netfort.gr.jp\u002F~dancer\u002Fsoftware\u002Fdsh.html.en\"\u003Edsh\u003C\u002Fa\u003E, etc), кто-то же подумал монтировать rootfs серверов по NFS.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВ ряде случаев выше предложенные варианты решений удовлетворительны, но на практике я нигде не видел полностью гомогенных систем (зачастую, внутри компании можно встретить не только разные версии ОС, но и различные дистрибутивы. Также в \u003Ca href=\"http:\u002F\u002Fwww.google.ru\u002Ftrends?q=freebsd&amp;ctab=0&amp;geo=all&amp;date=all&amp;sort=0\"\u003EРоссии\u002FСНГ\u003C\u002Fa\u003E очень распространена каша из FreeBSD\u002FLinux в ядре проектов), так что вряд ли за адекватное время будет возможно написать скрипт, который установит и настроит apache на зоопарке в 1000 машин под CentOS, Debian, Ubuntu, FreeBSD всевозможных версий.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nПо моим наблюдениям, очень мало IT подразделений, даже очень крупных компаниий, используют в своей работе \u003Ca href=\"http:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FConfiguration_management#Software_configuration_management\"\u003ESCM (Software Configuration Management)\u003C\u002Fa\u003E. В этом посте я постараюсь описать все преимущества использования Chef в IT инфраструктуре на простых примерах и больших масштабах.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nЕсли же, после столь короткого вступления, вы не прониклись идеей Chef, да и времени читать длинный технический пост у вас нет, то рекомендую вам пролистать до конца и посмотреть как используем Chef мы, Engine Yard, 37signals и подумать, можете ли вы переложить на него часть своей работы.\u003Cbr\u002F\u003E\r\n","imageUrl":null,"buttonTextHtml":"Читать дальше &rarr;","image":null},"status":"published","plannedPublishTime":null,"checked":null,"tags":[{"titleHtml":"chef"},{"titleHtml":"scm"},{"titleHtml":"управление конфигурацией"},{"titleHtml":"puppet"},{"titleHtml":"ruby"},{"titleHtml":"инфраструктура"},{"titleHtml":"системная интеграция"}]},"87312":{"id":"87312","timePublished":"2010-03-22T09:27:02+00:00","isCorporative":true,"lang":"ru","titleHtml":"KIWI Image System: атака клонов","editorVersion":"1.0","postType":"article","postLabels":[],"author":{"id":"39523","alias":"stolen","fullname":"Данил Загоскин","avatarUrl":"\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Favatars\u002F68a\u002F2e6\u002F3b7\u002F68a2e63b764331ade2c865576a2a9048.jpg","speciality":""},"statistics":{"commentsCount":24,"favoritesCount":27,"readingCount":10546,"score":28,"votesCount":46},"hubs":[{"relatedData":null,"id":"10685","alias":"scalaxy","type":"corporative","title":"Блог компании Оверсан-Скалакси","titleHtml":"Блог компании Оверсан-Скалакси","isProfiled":false}],"flows":[],"relatedData":null,"leadData":{"textHtml":"\u003Cimg src=\"http:\u002F\u002Fkiwi.berlios.de\u002Findex.png\" align=\"left\"\u002F\u003E \u003Ch4\u003E⇒Введение\u003C\u002Fh4\u003E\u003Cbr\u002F\u003E\r\nКогда у вас есть очень много одинаковых машин (кластер веб-серверов, куча терминалов оплаты, зал с публичными компьютерами), возникает вопрос о поддержании всех машин синхронизированными по версиям установленного ПО.\u003Cbr\u002F\u003E\r\nТрадиционным решением является настройка репозиториев и регулярное обновление всех машин средствами пакетного менеджера. Не менее традиционным — сборка в одном месте и почти ручное раскладывание по всем машинам новой версии пакета.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nПро очевидную ущербность второго способа говорить, думаю, смысла не имеет. С первым тоже не все гладко. Например, если во время массового обновления некоторые машины были недоступны, то при возвращении в бой ПО на них окажется устаревшим, что может негативно сказаться на целостности системы (например, изменения в протоколе общения между машинами без обратной совместимости). Вписывать в автозагрузку автообновление — тоже не вполне хороший вариант, так как можно получить не доконца оттестированный пакет или из-за проблем со связью не обновиться.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Chr\u002F\u003E","imageUrl":null,"buttonTextHtml":"А потом пришли фрукты и спасли мир","image":null},"status":"published","plannedPublishTime":null,"checked":null,"tags":[{"titleHtml":"KIWI"},{"titleHtml":"SUSE"},{"titleHtml":"SLES"},{"titleHtml":"SLES11"},{"titleHtml":"PXE"},{"titleHtml":"FlexBoot"},{"titleHtml":"diskless"},{"titleHtml":"thin client"}]},"91554":{"id":"91554","timePublished":"2010-04-20T17:49:21+00:00","isCorporative":true,"lang":"ru","titleHtml":"Наши докладчики на РИФ'е","editorVersion":"1.0","postType":"article","postLabels":[],"author":{"id":"5643","alias":"baldahin","fullname":"baldahin","avatarUrl":"\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Favatars\u002Fcbb\u002F191\u002F7da\u002Fcbb1917da5744d12d0a4921f95ce312b.jpg","speciality":"Пользователь"},"statistics":{"commentsCount":17,"favoritesCount":0,"readingCount":1470,"score":2,"votesCount":26},"hubs":[{"relatedData":null,"id":"10685","alias":"scalaxy","type":"corporative","title":"Блог компании Оверсан-Скалакси","titleHtml":"Блог компании Оверсан-Скалакси","isProfiled":false}],"flows":[],"relatedData":null,"leadData":{"textHtml":"Сегодня вечером на РИФ стартуют первые ласточки «Оверсан-Скалакси». Завтра с утра к ним присоединится основная часть команды.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nУвидеть нас можно будет везде :) Но об этом позже. Сейчас речь пойдет о том, где нас можно будет услышать.\u003Cbr\u002F\u003E\r\n","imageUrl":null,"buttonTextHtml":"Читать дальше &rarr;","image":null},"status":"published","plannedPublishTime":null,"checked":null,"tags":[{"titleHtml":"риф+киб 2010"},{"titleHtml":"риф"},{"titleHtml":"риф2010"},{"titleHtml":"скалакси"},{"titleHtml":"конференция"}]},"94076":{"id":"94076","timePublished":"2010-05-20T10:40:10+00:00","isCorporative":true,"lang":"ru","titleHtml":"Визит Ехуды Катца в компанию Оверсан-Скалакси","editorVersion":"1.0","postType":"article","postLabels":[],"author":{"id":"51236","alias":"sclx","fullname":null,"avatarUrl":"\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Favatars\u002F7a4\u002F06d\u002F80c\u002F7a406d80c0c345d12ea7e6749a113a62.png","speciality":""},"statistics":{"commentsCount":5,"favoritesCount":0,"readingCount":1705,"score":-14,"votesCount":42},"hubs":[{"relatedData":null,"id":"10685","alias":"scalaxy","type":"corporative","title":"Блог компании Оверсан-Скалакси","titleHtml":"Блог компании Оверсан-Скалакси","isProfiled":false}],"flows":[],"relatedData":null,"leadData":{"textHtml":"Недавно в Москве прошла конференция devConf, в которой приняли участие разработчики программного обеспечения со всего мира. Среди них был Ехуда Катц (Yehuda Katz), основной контрибьютор третьей версии Ruby on Rails. Так как наша компания использует для своих WEB-разработок именно этот фреймворк, а наши программисты — настоящие фанаты своего дела, мы с большим удовольствием пригласили господина Катца в свой офис, на что он любезно согласился.\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fpost_images\u002Fc47\u002F767\u002F895\u002Fc47767895f5fa5bd082ec0e9181c149a.jpg\" alt=\"image\"\u002F\u003E\u003Cbr\u002F\u003E\r\nДеятельность Ехуды по созданию Ruby on Rails 3 спонсируется его работодателем — компанией EngineYard, бизнес-модель работы которой во многом схожа с той, которую приняла компания Оверсан-Скалакси. По нашей просьбе, Ехуда рассказал нам об истории его компании, о том, какие цели она преследует, на какой рынок ориентируется, какую бизнес-модель использует для продвижения своих услуг. Также он поделился с нами тем, какие инструменты используются внутри компании EngineYard и как организована работа внутри неё.\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fpost_images\u002Fc9b\u002F533\u002Fdbb\u002Fc9b533dbb939c60e868f76937ec254e6.jpg\" alt=\"image\"\u002F\u003E\u003Cbr\u002F\u003E\r\nНаши программисты задали множество вопросов господину Катцу, вплоть до конкретных технических деталей конкретных программ. К нашему удивлению, он подробно ответил на все из них, будто он не в гостях у компании Оверсан-Скалакси, а в кругу своих коллег за решением рабочей задачи.\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fpost_images\u002F879\u002F687\u002Fb51\u002F879687b5170fde38ac7e9e3afa783236.jpg\" alt=\"image\"\u002F\u003E\u003Cbr\u002F\u003E\r\nБудем надеятся, что это не последний визит господина Катца в Россию и компанию Оверсан-Скалакси в частности.","imageUrl":null,"buttonTextHtml":null,"image":null},"status":"published","plannedPublishTime":null,"checked":null,"tags":[{"titleHtml":"devConf"},{"titleHtml":"Оверсан-Скалакси"}]},"572164":{"id":"572164","timePublished":"2021-09-27T11:37:23+00:00","isCorporative":false,"lang":"ru","titleHtml":"Первые шаги в ОТО: прецессия орбиты Меркурия","editorVersion":"2.0","postType":"article","postLabels":[{"type":"tutorial","data":null}],"author":{"id":"1832999","alias":"Yermack","fullname":null,"avatarUrl":"\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Favatars\u002F690\u002F140\u002F823\u002F690140823f555d03574a59d46f648d24.jpg","speciality":"Пользователь"},"statistics":{"commentsCount":2,"favoritesCount":26,"readingCount":3226,"score":18,"votesCount":18},"hubs":[{"relatedData":null,"id":"18840","alias":"julia","type":"collective","title":"Julia","titleHtml":"Julia","isProfiled":true},{"relatedData":null,"id":"21910","alias":"popular_science","type":"collective","title":"Научно-популярное","titleHtml":"Научно-популярное","isProfiled":false},{"relatedData":null,"id":"21968","alias":"physics","type":"collective","title":"Физика","titleHtml":"Физика","isProfiled":false},{"relatedData":null,"id":"22022","alias":"astronomy","type":"collective","title":"Астрономия","titleHtml":"Астрономия","isProfiled":false}],"flows":[{"id":"1","alias":"develop","title":"Разработка"},{"id":"7","alias":"popsci","title":"Научпоп"}],"relatedData":null,"leadData":{"textHtml":"\u003Cp\u003EКогда речь заходит о теории относительности, частенько на ровном месте разрастаются споры, которые были занесены в почву непонимания и обильно удобрены мифами, недосказанностью и недостаточной математической подготовкой. Даже на лекциях от некоторых профессоров можно услышать, что детище гения Эйнштейна не имеет практической пользы, а на робкие попытки пролепетать что-то про спутниковые системы навигации они пренебрежительно отмахиваются, дескать, там все сложно и двояко. \u003C\u002Fp\u003E\u003Cp\u003EТак что совершенно естественно желание попробовать провести некоторые расчеты самолично, потрогать формулы, покрутить параметры, чтобы постепенно заложить интуицию в столь горячей теме.\u003C\u002Fp\u003E","imageUrl":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002Fa9f\u002Ff59\u002Fb65\u002Fa9ff59b65da6e8b1e6f59314aadb8e3d.png","buttonTextHtml":"Читать далее","image":{"url":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002Fa9f\u002Ff59\u002Fb65\u002Fa9ff59b65da6e8b1e6f59314aadb8e3d.png","fit":"cover","positionY":0,"positionX":0}},"status":"published","plannedPublishTime":null,"checked":null,"tags":[{"titleHtml":"прецессия"},{"titleHtml":"меркурий"},{"titleHtml":"теория относительности"},{"titleHtml":"уравнения эйнштейна"},{"titleHtml":"метрики"},{"titleHtml":"спасибо scihub"},{"titleHtml":"спасибо mathpix"},{"titleHtml":"астрология_точная_наука"}]},"579772":{"id":"579772","timePublished":"2021-09-27T05:32:01+00:00","isCorporative":true,"lang":"ru","titleHtml":"Сливы процветают. Эксперт-«параноик» Майкл Баззель о защите личных данных","editorVersion":"2.0","postType":"article","postLabels":[{"type":"translation","data":{"originalAuthorName":"Michael Bazzell","originalUrl":"https:\u002F\u002Finteltechniques.com\u002Fblog\u002F2021\u002F07\u002F23\u002Fpersonal-ransomware-exposure\u002F"}}],"author":{"id":"2297567","alias":"SearchInform_team","fullname":null,"avatarUrl":"","speciality":"Пользователь"},"statistics":{"commentsCount":0,"favoritesCount":8,"readingCount":2435,"score":9,"votesCount":9},"hubs":[{"relatedData":null,"id":"22418","alias":"searchinform","type":"corporative","title":"Блог компании SearchInform","titleHtml":"Блог компании SearchInform","isProfiled":false},{"relatedData":null,"id":"50","alias":"infosecurity","type":"collective","title":"Информационная безопасность","titleHtml":"Информационная безопасность","isProfiled":true}],"flows":[{"id":"1","alias":"develop","title":"Разработка"}],"relatedData":null,"leadData":{"textHtml":"\u003Cp\u003EНаш очередной пост из серии «интересное на иностранном языке» – рассказ Майкла Баззеля о том, как сберечь свои персональные данные от утечек. Майкл – знаковая фигура в сфере OSINT, работал в правительстве США и ФБР, его приглашали в качестве технического эксперта в сериал «Мистер Робот», который считают достойным с точки зрения достоверности. В личной жизни эксперт придерживается настолько жестких правил в отношении информационной гигиены, что некоторые считают его «неадекватом». Так ли это – может быть несколько мнений. \u003C\u002Fp\u003E\u003Cp\u003EОдин из факторов, который убеждает в правильном подходе Майкла, – что риски обнаружить свои данные в интернете стали существенно выше, потому что шифровальщики без разбору сливают в сеть все, до чего дотягиваются при атаках на бизнес. Приводим перевод \u003Ca href=\"https:\u002F\u002Finteltechniques.com\u002Fblog\u002F2021\u002F07\u002F23\u002Fpersonal-ransomware-exposure\u002F\"\u003Eпоста Майкла Баззеля\u003C\u002Fa\u003E. \u003C\u002Fp\u003E\u003Cp\u003E\u003Cstrong\u003EАтакуют корпорации, а страдают люди\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\u003Cp\u003EБольшинство людей не задумываются о том, как их касается проблема распространения вирусов-шифровальщиков. Логика такова: речь идет о проблемах компаний, это они вынуждены платить выкуп. При чем тут, казалось бы, обычные люди?! \u003C\u002Fp\u003E\u003Cp\u003EА при том, что преступники сменили тактику: сейчас они не просто шифруют данные, но и скачивают их, выкладывают в открытый доступ, если компании не платят им выкуп. Теперь давайте подумаем, что в этих слитых базах? Множество данных о сотрудниках, клиентах, контрагентах, с которыми компания-жертва работает.\u003C\u002Fp\u003E\u003Cp\u003EХочу сразу уточнить: я это пишу не потому что выступаю за уплату выкупа. Я за то, чтобы сопротивляться избыточному сбору данных там, где это не обязательно. Мы халатно относимся к своим ПДн, раздавая их по первому требованию.\u003C\u002Fp\u003E","imageUrl":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002Fe3b\u002F3e1\u002F2c2\u002Fe3b3e12c2036d90018b804276e31ebea.png","buttonTextHtml":"Читать далее","image":{"url":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002Fe3b\u002F3e1\u002F2c2\u002Fe3b3e12c2036d90018b804276e31ebea.png","fit":"cover","positionY":0,"positionX":0}},"status":"published","plannedPublishTime":null,"checked":null,"tags":[{"titleHtml":"персональные данные"},{"titleHtml":"пдн"},{"titleHtml":"сёрчинформ"},{"titleHtml":"Майкл Баззел"},{"titleHtml":"утечки информации"}]},"579854":{"id":"579854","timePublished":"2021-09-27T06:03:01+00:00","isCorporative":true,"lang":"ru","titleHtml":"Видишь уязвимости? А они есть! Наше исследование популярных CMS-систем","editorVersion":"2.0","postType":"article","postLabels":[],"author":{"id":"2684283","alias":"Solar_Pentest","fullname":null,"avatarUrl":"","speciality":""},"statistics":{"commentsCount":8,"favoritesCount":25,"readingCount":4086,"score":27,"votesCount":29},"hubs":[{"relatedData":null,"id":"20826","alias":"solarsecurity","type":"corporative","title":"Блог компании Ростелеком-Солар","titleHtml":"Блог компании Ростелеком-Солар","isProfiled":false},{"relatedData":null,"id":"50","alias":"infosecurity","type":"collective","title":"Информационная безопасность","titleHtml":"Информационная безопасность","isProfiled":true},{"relatedData":null,"id":"260","alias":"php","type":"collective","title":"PHP","titleHtml":"PHP","isProfiled":true}],"flows":[{"id":"1","alias":"develop","title":"Разработка"}],"relatedData":null,"leadData":{"textHtml":"\u003Cp\u003EЛьвиная доля всех работ по анализу защищенности внешнего периметра – это тестирование веб-приложений. Здесь могут быть как корпоративные решения, так и «домашние» разработки на базе различных публичных систем управления контентом (CMS). Мы всегда проводим глубокий анализ подобных решений на тестовых стендах и зачастую находим уязвимости нулевого дня. Собственно, из опыта таких проектов и родилась идея собрать исследовательскую команду и провести глубокий анализ популярных CMS-систем и различных плагинов для них. В этом посте мы поделимся результатами нашего исследования, а также продемонстрируем примеры уязвимого кода наиболее интересных, на наш взгляд, уязвимостей и примеры их эксплуатации. Конечно все эти уязвимости уже исправлены и описываются здесь с разрешения владельцев систем.\u003C\u002Fp\u003E","imageUrl":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F6df\u002F317\u002F4e6\u002F6df3174e60bbe263a70bcafdf9e51e6b.jpg","buttonTextHtml":"Не всё то в безопасности, что с Bug Bounty","image":{"url":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F6df\u002F317\u002F4e6\u002F6df3174e60bbe263a70bcafdf9e51e6b.jpg","fit":"cover","positionY":0,"positionX":0}},"status":"published","plannedPublishTime":null,"checked":null,"tags":[{"titleHtml":"cms"},{"titleHtml":"уязвимости"},{"titleHtml":"уязвимости и их эксплуатация"},{"titleHtml":"уязвимость нулевого дня"}]},"580008":{"id":"580008","timePublished":"2021-09-27T06:30:02+00:00","isCorporative":false,"lang":"ru","titleHtml":"Летний Магнитогорск","editorVersion":"2.0","postType":"article","postLabels":[],"author":{"id":"2614609","alias":"city_scraper","fullname":null,"avatarUrl":"\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Favatars\u002F8f8\u002Fd6c\u002F328\u002F8f8d6c328ec3a513103b6757c2c21610.png","speciality":"Пользователь"},"statistics":{"commentsCount":6,"favoritesCount":3,"readingCount":3853,"score":14,"votesCount":20},"hubs":[{"relatedData":null,"id":"22012","alias":"Ecology","type":"collective","title":"Экология","titleHtml":"Экология","isProfiled":false},{"relatedData":null,"id":"22024","alias":"urban","type":"collective","title":"Урбанизм","titleHtml":"Урбанизм","isProfiled":false}],"flows":[{"id":"7","alias":"popsci","title":"Научпоп"}],"relatedData":null,"leadData":{"textHtml":"\u003Cp\u003EМагнитогорск Челябинской области – один из крупнейших мировых центров чёрной металлургии. В России это шестой из крупнейших городов, которые не являются центрами субъектов страны. \u003C\u002Fp\u003E\u003Cp\u003EСовсем недавно город был одним из наиболее неблагополучных с точки зрения загрязнения атмосферного воздуха, но в 2021 году был зафиксирован «повышенный» уровень – то есть не «высокий» или «очень высокий», как раньше. \u003C\u002Fp\u003E\u003Cp\u003EКак этот город выглядит летом? Где и как его жители могут проводить время?\u003C\u002Fp\u003E","imageUrl":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F030\u002F0d1\u002Fcff\u002F0300d1cff2029948d33d803000331724.jpg","buttonTextHtml":"Читать далее","image":{"url":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F030\u002F0d1\u002Fcff\u002F0300d1cff2029948d33d803000331724.jpg","fit":"cover","positionY":0,"positionX":0}},"status":"published","plannedPublishTime":null,"checked":null,"tags":[{"titleHtml":"Магнитогорск"},{"titleHtml":"промышленность"},{"titleHtml":"промышленные города"},{"titleHtml":"урбанизм\u002Fурбания"},{"titleHtml":"урбанистика"},{"titleHtml":"города России"},{"titleHtml":"города"}]},"580050":{"id":"580050","timePublished":"2021-09-27T10:23:25+00:00","isCorporative":false,"lang":"ru","titleHtml":"Один человек ответил на 85+ тысяч вопросов на Stack Overflow (24,1 ответа в день)","editorVersion":"2.0","postType":"article","postLabels":[],"author":{"id":"1585037","alias":"sahsAGU","fullname":"Александр Гуреев","avatarUrl":"\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Favatars\u002F43c\u002F6c7\u002F0ab\u002F43c6c70ab024d45474e6abe8db797573.jpg","speciality":"Автор"},"statistics":{"commentsCount":36,"favoritesCount":10,"readingCount":11176,"score":12,"votesCount":20},"hubs":[{"relatedData":null,"id":"260","alias":"php","type":"collective","title":"PHP","titleHtml":"PHP","isProfiled":true},{"relatedData":null,"id":"306","alias":"mysql","type":"collective","title":"MySQL","titleHtml":"MySQL","isProfiled":true},{"relatedData":null,"id":"359","alias":"programming","type":"collective","title":"Программирование","titleHtml":"Программирование","isProfiled":true},{"relatedData":null,"id":"594","alias":"sql","type":"collective","title":"SQL","titleHtml":"SQL","isProfiled":true},{"relatedData":null,"id":"7152","alias":"data_mining","type":"collective","title":"Data Mining","titleHtml":"Data Mining","isProfiled":true}],"flows":[{"id":"1","alias":"develop","title":"Разработка"}],"relatedData":null,"leadData":{"textHtml":"\u003Cp\u003E\u003Cstrong\u003EВ среднем 24,1 ответа в день (если все 365 дней в году считать рабочими) на протяжении почти 10 лет.\u003C\u002Fstrong\u003E \u003C\u002Fp\u003E\u003Cp\u003EНесколько дней назад на некоторых англоязычных ресурсах началось обсуждение одного очень необычного пользователя Stack Overflow. Его зовут Гордон Линофф (Gordon Linoff), он из Нью-Йорка, и за 9 лет и 8 месяцев своего присутствия на платформе он дал 85,201 ответов на различные вопросы, в основном связанные с SQL и дата-майнингом (цифра актуальна на 27.09.2021). \u003C\u002Fp\u003E\u003Cp\u003EЧто это за маг?\u003C\u002Fp\u003E","imageUrl":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F396\u002F5ac\u002Fef4\u002F3965acef48ae14917c514fa091f60d1a.png","buttonTextHtml":"Читать далее","image":{"url":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F396\u002F5ac\u002Fef4\u002F3965acef48ae14917c514fa091f60d1a.png","fit":"cover","positionY":0,"positionX":0}},"status":"published","plannedPublishTime":null,"checked":null,"tags":[{"titleHtml":"sql"},{"titleHtml":"mysql"},{"titleHtml":"stackoverflow"},{"titleHtml":"базы данных"},{"titleHtml":"дата майнинг"},{"titleHtml":"data mining"}]},"580060":{"id":"580060","timePublished":"2021-09-27T09:00:04+00:00","isCorporative":true,"lang":"ru","titleHtml":"Арракис, который мы заслужили","editorVersion":"1.0","postType":"article","postLabels":[],"author":{"id":"238277","alias":"Zelenyikot","fullname":"Виталий Егоров","avatarUrl":"\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Favatars\u002F22b\u002F2d7\u002F7a5\u002F22b2d77a57b687aae24784a3e53089c9.jpg","speciality":"Популяризатор космонавтики"},"statistics":{"commentsCount":114,"favoritesCount":40,"readingCount":22424,"score":133,"votesCount":145},"hubs":[{"relatedData":null,"id":"19791","alias":"ruvds","type":"corporative","title":"Блог компании RUVDS.com","titleHtml":"Блог компании RUVDS.com","isProfiled":false},{"relatedData":null,"id":"21910","alias":"popular_science","type":"collective","title":"Научно-популярное","titleHtml":"Научно-популярное","isProfiled":false},{"relatedData":null,"id":"21962","alias":"space","type":"collective","title":"Космонавтика","titleHtml":"Космонавтика","isProfiled":false},{"relatedData":null,"id":"21984","alias":"sci-fi","type":"collective","title":"Научная фантастика","titleHtml":"Научная фантастика","isProfiled":false},{"relatedData":null,"id":"22014","alias":"futurenow","type":"collective","title":"Будущее здесь","titleHtml":"Будущее здесь","isProfiled":false}],"flows":[{"id":"7","alias":"popsci","title":"Научпоп"}],"relatedData":null,"leadData":{"textHtml":"\u003Ca href=\"https:\u002F\u002Fhabr.com\u002Fru\u002Fcompany\u002Fruvds\u002Fblog\u002F580060\u002F\"\u003E\u003Cdiv style=\"text-align:center;\"\u003E\u003Cimg src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fk0\u002Fds\u002Fy5\u002Fk0dsy5npxclyjdytiroqga7-leu.jpeg\"\u003E\u003C\u002Fdiv\u003E\u003C\u002Fa\u003E\u003Cbr\u003E\r\nВо вселенной писателя-фантаста Фрэнка Герберта, Дюна, она же Арракис &mdash; это пустынная и маловодная планета с двумя лунами. По сюжету, она находится за пределами Солнечной системы, но если мы захотим поискать ближайшую схожую параллель,&nbsp;то больше всего подходит планета Марс. Предлагаю воспользоваться возможностями, которые даёт современная космонавтика, и совершить воображаемую прогулку на нашу Дюну.\u003Cbr\u003E","imageUrl":null,"buttonTextHtml":"Читать дальше &rarr;","image":null},"status":"published","plannedPublishTime":null,"checked":null,"tags":[{"titleHtml":"Марс"},{"titleHtml":"Дюна"},{"titleHtml":"MRO"},{"titleHtml":"Curiosity"},{"titleHtml":"марсоход"},{"titleHtml":"ruvds_статьи"}]},"580124":{"id":"580124","timePublished":"2021-09-27T13:03:14+00:00","isCorporative":true,"lang":"ru","titleHtml":"Электролюминесцентные индикаторы из прошлого","editorVersion":"1.0","postType":"article","postLabels":[],"author":{"id":"146371","alias":"radiolok","fullname":"Артем Кашканов","avatarUrl":"\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Favatars\u002Fa46\u002Fc6a\u002F151\u002Fa46c6a15193f7c0cac79d2736b107358.jpg","speciality":"Релейно-декатронный маньяк"},"statistics":{"commentsCount":13,"favoritesCount":37,"readingCount":5204,"score":75,"votesCount":75},"hubs":[{"relatedData":null,"id":"19791","alias":"ruvds","type":"corporative","title":"Блог компании RUVDS.com","titleHtml":"Блог компании RUVDS.com","isProfiled":false},{"relatedData":null,"id":"21484","alias":"electronics","type":"collective","title":"Производство и разработка электроники","titleHtml":"Производство и разработка электроники","isProfiled":true},{"relatedData":null,"id":"21906","alias":"history","type":"collective","title":"История IT","titleHtml":"История IT","isProfiled":false},{"relatedData":null,"id":"21930","alias":"antikvariat","type":"collective","title":"Старое железо","titleHtml":"Старое железо","isProfiled":false}],"flows":[{"id":"1","alias":"develop","title":"Разработка"},{"id":"7","alias":"popsci","title":"Научпоп"}],"relatedData":null,"leadData":{"textHtml":"Сегодня речь пойдёт об электролюминесцентных индикаторах. Но, не о тех, которые окружают вас повсюду и к которым вы привыкли, а о других — получивших огромную популярность в 60-е годы прошлого века, и так же стремительно канувших в небытие. Заодно запущу свою коллекцию индикаторов, как серийно выпускавшихся, так и уникальных опытных и даже — лабораторных образцов.\u003Cbr\u003E\r\n\u003Cbr\u003E\r\n\u003Ca href=\"https:\u002F\u002Fhabr.com\u002Fru\u002Fcompany\u002Fruvds\u002Fblog\u002F523004\u002F\"\u003E\u003Cdiv style=\"text-align:center;\"\u003E\u003Cimg src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F94e\u002F51f\u002F459\u002F94e51f459ae59c9d2fe6c448cb07bcca.gif\"\u003E\u003C\u002Fdiv\u003E\u003C\u002Fa\u003E","imageUrl":null,"buttonTextHtml":"Читать дальше &rarr;","image":null},"status":"published","plannedPublishTime":null,"checked":null,"tags":[{"titleHtml":"Индикатор"},{"titleHtml":"электролюминесцентность"},{"titleHtml":"ruvds_статьи"}]},"580150":{"id":"580150","timePublished":"2021-09-27T10:50:03+00:00","isCorporative":true,"lang":"ru","titleHtml":"Топ-5 когнитивных искажений при планировании в IT","editorVersion":"2.0","postType":"article","postLabels":[],"author":{"id":"2794469","alias":"KM_QA","fullname":null,"avatarUrl":"","speciality":""},"statistics":{"commentsCount":7,"favoritesCount":54,"readingCount":6059,"score":38,"votesCount":40},"hubs":[{"relatedData":null,"id":"14332","alias":"oleg-bunin","type":"corporative","title":"Блог компании Конференции Олега Бунина (Онтико)","titleHtml":"Блог компании Конференции Олега Бунина (Онтико)","isProfiled":false},{"relatedData":null,"id":"19583","alias":"dev_management","type":"collective","title":"Управление разработкой","titleHtml":"Управление разработкой","isProfiled":true},{"relatedData":null,"id":"20736","alias":"hr_management","type":"collective","title":"Управление персоналом","titleHtml":"Управление персоналом","isProfiled":true},{"relatedData":null,"id":"20754","alias":"tech_events","type":"collective","title":"Конференции","titleHtml":"Конференции","isProfiled":false},{"relatedData":null,"id":"21990","alias":"brain","type":"collective","title":"Мозг","titleHtml":"Мозг","isProfiled":false}],"flows":[{"id":"3","alias":"management","title":"Менеджмент"},{"id":"4","alias":"marketing","title":"Маркетинг"},{"id":"7","alias":"popsci","title":"Научпоп"}],"relatedData":null,"leadData":{"textHtml":"\u003Cp\u003EЭта статья подходит для тимлидов и их подопечных, а также для всех, кто оценивает проекты и задачи. Я расскажу, как и почему мы делаем ошибки из-за когнитивных искажений. Попадаем в них мы почти все, просто потому что мы живые люди. И на примере одного дня из жизни тимлида я хочу показать, в какие искажения чаще всего влетают в IT, и&nbsp; — самое полезное&nbsp; —&nbsp; как из них можно выходить.\u003C\u002Fp\u003E\u003Cp\u003E\u003Cstrong\u003EЗамечу, что искать когнитивные искажения стоит, в первую очередь, у себя, а не у коллег. \u003C\u002Fstrong\u003EИ что рассказывать про искажения намного проще, чем не влетать в их на практике, однако, если этому научиться, то в перспективе это изрядно окупается, потому что экономит и время, и деньги, помогая и нам, и команде.\u003C\u002Fp\u003E","imageUrl":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002Fb78\u002F76f\u002F001\u002Fb7876f0010e85c328462a735df0b76e8.jpg","buttonTextHtml":"Читать далее","image":{"url":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002Fb78\u002F76f\u002F001\u002Fb7876f0010e85c328462a735df0b76e8.jpg","fit":"cover","positionY":0,"positionX":0}},"status":"published","plannedPublishTime":null,"checked":null,"tags":[{"titleHtml":"когнитивные искажения"},{"titleHtml":"нейрофизиология"},{"titleHtml":"мозг"},{"titleHtml":"психология"},{"titleHtml":"тимлидство"},{"titleHtml":"тимлид"},{"titleHtml":"управление людьми"},{"titleHtml":"управление проектами и командой"},{"titleHtml":"управление командой"},{"titleHtml":"управление персоналом"}]},"580164":{"id":"580164","timePublished":"2021-09-27T11:17:58+00:00","isCorporative":true,"lang":"ru","titleHtml":"Измеряем производительность String.format() в Java","editorVersion":"2.0","postType":"article","postLabels":[{"type":"translation","data":{"originalAuthorName":"@cowtowncoder","originalUrl":"https:\u002F\u002Fcowtowncoder.medium.com\u002Fmeasuring-performance-of-java-string-format-or-lack-thereof-2e1c6a13362c"}}],"author":{"id":"2571061","alias":"GolovinDS","fullname":"Дмитрий Головин","avatarUrl":"\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Favatars\u002Fd27\u002Fccd\u002F743\u002Fd27ccd743d8bccbf1a885e5dadaa7ffe.jpg","speciality":"Контент-маркетолог"},"statistics":{"commentsCount":0,"favoritesCount":16,"readingCount":1749,"score":9,"votesCount":11},"hubs":[{"relatedData":null,"id":"21052","alias":"otus","type":"corporative","title":"Блог компании OTUS","titleHtml":"Блог компании OTUS","isProfiled":false},{"relatedData":null,"id":"4","alias":"hi","type":"collective","title":"Высокая производительность","titleHtml":"Высокая производительность","isProfiled":true},{"relatedData":null,"id":"375","alias":"java","type":"collective","title":"Java","titleHtml":"Java","isProfiled":true}],"flows":[{"id":"1","alias":"develop","title":"Разработка"}],"relatedData":null,"leadData":{"textHtml":"\u003Cp\u003EЯ раньше считал, что JDK в целом хорошо оптимизирована, и если в JDK есть простой способ решения какой-то задачи, то он вполне подойдет для большинства ситуаций и будет работать хорошо.\u003C\u002Fp\u003E\u003Cp\u003EНо я обнаружил, что иногда некоторые классы или методы работают на удивление плохо. Знание таких аномалий полезно при работе с требовательным к производительности кодом.\u003C\u002Fp\u003E\u003Cp\u003EВ этом посте рассмотрим один из подобных кейсов: поразительно низкая производительность \u003Ccode\u003EString.format()\u003C\u002Fcode\u003E при простой конкатенации строк.\u003C\u002Fp\u003E","imageUrl":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002Fed4\u002F612\u002F7ef\u002Fed46127ef6d1b8f8d650482dfd335220.png","buttonTextHtml":"Читать далее","image":{"url":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002Fed4\u002F612\u002F7ef\u002Fed46127ef6d1b8f8d650482dfd335220.png","fit":"cover","positionY":0,"positionX":0}},"status":"published","plannedPublishTime":null,"checked":null,"tags":[{"titleHtml":"java"},{"titleHtml":"performance"},{"titleHtml":"jdk"}]},"580166":{"id":"580166","timePublished":"2021-09-27T11:22:03+00:00","isCorporative":false,"lang":"ru","titleHtml":"Новости из жизни Haiku за август-сентябрь 2021","editorVersion":"2.0","postType":"article","postLabels":[],"author":{"id":"375413","alias":"petr97","fullname":"Ахламов Петр","avatarUrl":"\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Favatars\u002Fadf\u002F830\u002F79c\u002Fadf83079c33fd56935b929935559572a.jpg","speciality":"Пользователь"},"statistics":{"commentsCount":2,"favoritesCount":3,"readingCount":1759,"score":8,"votesCount":8},"hubs":[{"relatedData":null,"id":"144","alias":"open_source","type":"collective","title":"Open source","titleHtml":"Open source","isProfiled":true},{"relatedData":null,"id":"559","alias":"cpp","type":"collective","title":"C++","titleHtml":"C++","isProfiled":true},{"relatedData":null,"id":"7330","alias":"qt_software","type":"collective","title":"Qt","titleHtml":"Qt","isProfiled":true},{"relatedData":null,"id":"21918","alias":"soft","type":"collective","title":"Софт","titleHtml":"Софт","isProfiled":false}],"flows":[{"id":"1","alias":"develop","title":"Разработка"},{"id":"7","alias":"popsci","title":"Научпоп"}],"relatedData":null,"leadData":{"textHtml":"\u003Cp\u003EЗдравствуйте, дорогие друзья. Продолжаю Вас знакомить на Хабре с новостями проекта Haiku.\u003C\u002Fp\u003E","imageUrl":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F877\u002Fa0f\u002Fc9c\u002F877a0fc9c92663d8cd2acc965493dacc.jpg","buttonTextHtml":"Читать далее","image":{"url":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F877\u002Fa0f\u002Fc9c\u002F877a0fc9c92663d8cd2acc965493dacc.jpg","fit":"cover","positionY":0,"positionX":0}},"status":"published","plannedPublishTime":null,"checked":null,"tags":[{"titleHtml":"Haiku"},{"titleHtml":"Intel"},{"titleHtml":"VESA"},{"titleHtml":"RISC-V"},{"titleHtml":"Веб-камера"},{"titleHtml":"Превью"},{"titleHtml":"Куба"},{"titleHtml":"Wine"},{"titleHtml":"Менеджер окон"}]},"580172":{"id":"580172","timePublished":"2021-09-27T11:45:49+00:00","isCorporative":true,"lang":"ru","titleHtml":"Небинарный ngIf*","editorVersion":"2.0","postType":"article","postLabels":[],"author":{"id":"1050218","alias":"Waterplea","fullname":"Александр Инкин","avatarUrl":"\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Favatars\u002Fa70\u002F569\u002Ff31\u002Fa70569f31346559ce2b8b875e7f97480.jpg","speciality":"Google Developer Expert | Angular"},"statistics":{"commentsCount":1,"favoritesCount":13,"readingCount":941,"score":15,"votesCount":15},"hubs":[{"relatedData":null,"id":"17420","alias":"tinkoff","type":"corporative","title":"Блог компании TINKOFF","titleHtml":"Блог компании TINKOFF","isProfiled":false},{"relatedData":null,"id":"91","alias":"webdev","type":"collective","title":"Разработка веб-сайтов","titleHtml":"Разработка веб-сайтов","isProfiled":true},{"relatedData":null,"id":"18109","alias":"angular","type":"collective","title":"Angular","titleHtml":"Angular","isProfiled":true}],"flows":[{"id":"1","alias":"develop","title":"Разработка"}],"relatedData":null,"leadData":{"textHtml":"\u003Cp\u003EВам когда-нибудь хотелось отобразить состояние загрузки, пока \u003Ccode\u003EngIf\u003C\u002Fcode\u003E ждет ответа от \u003Ccode\u003Easync\u003C\u002Fcode\u003E-пайпа? Или, может, вы мечтали передать в \u003Ccode\u003EngFor\u003C\u002Fcode\u003E шаблон для пустого массива? Возможно, вы бросили это, потому что вам не хотелось реализовывать базовую логику этих директив самому. На самом деле в этом нет нужды! Один и тот же селектор может подцепить несколько директив, что позволяет расширить функциональность встроенных директив дополнительной логикой.\u003C\u002Fp\u003E","imageUrl":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F846\u002F786\u002F3e2\u002F8467863e2df65db32cb31f4b16c822ef.png","buttonTextHtml":"Читать далее","image":{"url":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F846\u002F786\u002F3e2\u002F8467863e2df65db32cb31f4b16c822ef.png","fit":"cover","positionY":0,"positionX":0}},"status":"published","plannedPublishTime":null,"checked":null,"tags":[{"titleHtml":"template"},{"titleHtml":"directive"},{"titleHtml":"angular"},{"titleHtml":"structural"}]},"580194":{"id":"580194","timePublished":"2021-09-27T12:36:12+00:00","isCorporative":true,"lang":"ru","titleHtml":"Сотрудники на карте: отвечаем на 10 важных вопросов о трекинге","editorVersion":"2.0","postType":"article","postLabels":[],"author":{"id":"1254716","alias":"Axelus","fullname":null,"avatarUrl":"\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Favatars\u002F118\u002Fc4f\u002F08f\u002F118c4f08ffa66438ad6be22e205d563d.png","speciality":"Разработчик"},"statistics":{"commentsCount":0,"favoritesCount":7,"readingCount":1096,"score":13,"votesCount":15},"hubs":[{"relatedData":null,"id":"20758","alias":"regionsoft","type":"corporative","title":"Блог компании RegionSoft","titleHtml":"Блог компании RegionSoft","isProfiled":false},{"relatedData":null,"id":"6398","alias":"it-infrastructure","type":"collective","title":"IT-инфраструктура","titleHtml":"IT-инфраструктура","isProfiled":true},{"relatedData":null,"id":"12365","alias":"saas","type":"collective","title":"SaaS \u002F S+S","titleHtml":"SaaS \u002F S+S","isProfiled":true},{"relatedData":null,"id":"17783","alias":"geo","type":"collective","title":"Геоинформационные сервисы","titleHtml":"Геоинформационные сервисы","isProfiled":true},{"relatedData":null,"id":"20736","alias":"hr_management","type":"collective","title":"Управление персоналом","titleHtml":"Управление персоналом","isProfiled":true}],"flows":[{"id":"1","alias":"develop","title":"Разработка"},{"id":"3","alias":"management","title":"Менеджмент"},{"id":"6","alias":"admin","title":"Администрирование"}],"relatedData":null,"leadData":{"textHtml":"\u003Cp\u003EЛюбой контроль сотрудников — опасный и болезненный вопрос, особенно в небольших компаниях. Часто в дружеские и открытые отношения компании не вписывается ни одна из форм контроля, рассчитывать можно только на доверие. Но пресловутый ковид и здесь внёс свои коррективы: расширение удалённой работы, увеличение штата мобильных сотрудников, частичная занятость пополнили ряды полевых сисадминов, аутсорсеров поддержки и остальных «разъездных» работников. Увы, люди разные и вслед за приятными плодами и бонусами удалёнки пришли негативные истории про поведение курьеров, опоздания и откровенные нарушения сотрудников на территории клиентов, неявки на работу или к заказчику и т.д. С этим столкнулись и ритейл, и ИТ, и любая сфера с мобильными сотрудниками. Очень хочется верить в лучшее, но без минимального контроля можно просто потерять бизнес — и тогда пострадают коллеги нерадивых сотрудников.\u003C\u002Fp\u003E","imageUrl":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002Fe4a\u002F5b9\u002Fa9d\u002Fe4a5b9a9d62c342fa897f4531ec9301b.png","buttonTextHtml":"Читать далее","image":{"url":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002Fe4a\u002F5b9\u002Fa9d\u002Fe4a5b9a9d62c342fa897f4531ec9301b.png","fit":"cover","positionY":0,"positionX":0}},"status":"published","plannedPublishTime":null,"checked":null,"tags":[{"titleHtml":"geomonitor"},{"titleHtml":"геолокация"},{"titleHtml":"геозона"},{"titleHtml":"трекинг"}]},"580196":{"id":"580196","timePublished":"2021-09-27T12:28:15+00:00","isCorporative":true,"lang":"ru","titleHtml":"Зачем нужен динамический анализ кода, на примере проекта PVS-Studio","editorVersion":"1.0","postType":"article","postLabels":[],"author":{"id":"2302295","alias":"MrROBUST","fullname":"Алексей Говоров","avatarUrl":"","speciality":"Пользователь"},"statistics":{"commentsCount":0,"favoritesCount":4,"readingCount":709,"score":9,"votesCount":9},"hubs":[{"relatedData":null,"id":"18095","alias":"pvs-studio","type":"corporative","title":"Блог компании PVS-Studio","titleHtml":"Блог компании PVS-Studio","isProfiled":false},{"relatedData":null,"id":"559","alias":"cpp","type":"collective","title":"C++","titleHtml":"C++","isProfiled":true},{"relatedData":null,"id":"11606","alias":"vs","type":"collective","title":"Visual Studio","titleHtml":"Visual Studio","isProfiled":true},{"relatedData":null,"id":"21456","alias":"win_dev","type":"collective","title":"Разработка под Windows","titleHtml":"Разработка под Windows","isProfiled":true}],"flows":[{"id":"1","alias":"develop","title":"Разработка"}],"relatedData":null,"leadData":{"textHtml":"\u003Cp\u003EВ разговоре с Маршаллом Клоу на подкасте CppCast #300 ABI Stability была затронута достаточно давняя новость о поддержке компиляторами Visual Studio инструмента AddressSanitizer (ASan). Мы уже достаточно давно внедрили ASan в свою систему тестирования и хотим рассказать о паре интересных ошибок, которые он помог найти.\u003C\u002Fp\u003E\u003Cbr\u003E\r\n\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fpost_images\u002F7ef\u002F2db\u002F210\u002F7ef2db210d677f9a8c07026d4361d3ba.png\" alt=\"0868_PVS-Studio_ASan_ru\u002Fimage2.png\"\u003E\u003C\u002Fp\u003E","imageUrl":null,"buttonTextHtml":"Читать дальше &rarr;","image":null},"status":"published","plannedPublishTime":null,"checked":null,"tags":[{"titleHtml":"pvs-studio"},{"titleHtml":"clang"},{"titleHtml":"asan"},{"titleHtml":"sanitizer"},{"titleHtml":"динамический анализ кода"}]},"580204":{"id":"580204","timePublished":"2021-09-27T12:31:54+00:00","isCorporative":false,"lang":"ru","titleHtml":"Почему using namespace std; это плохо","editorVersion":"2.0","postType":"article","postLabels":[{"type":"translation","data":{"originalAuthorName":"sbi, Greg Hewgill","originalUrl":"https:\u002F\u002Fstackoverflow.com\u002Fquestions\u002F1452721\u002Fwhy-is-using-namespace-std-considered-bad-practice"}}],"author":{"id":"936030","alias":"F0iL","fullname":"K. just K.","avatarUrl":"\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Favatars\u002Fbcd\u002F9c7\u002F270\u002Fbcd9c7270c0727e164ac404a7f929971.jpg","speciality":"Разработчик"},"statistics":{"commentsCount":12,"favoritesCount":13,"readingCount":4886,"score":16,"votesCount":24},"hubs":[{"relatedData":null,"id":"359","alias":"programming","type":"collective","title":"Программирование","titleHtml":"Программирование","isProfiled":true},{"relatedData":null,"id":"524","alias":"complete_code","type":"collective","title":"Совершенный код","titleHtml":"Совершенный код","isProfiled":true},{"relatedData":null,"id":"559","alias":"cpp","type":"collective","title":"C++","titleHtml":"C++","isProfiled":true},{"relatedData":null,"id":"17188","alias":"compilers","type":"collective","title":"Компиляторы","titleHtml":"Компиляторы","isProfiled":true}],"flows":[{"id":"1","alias":"develop","title":"Разработка"}],"relatedData":null,"leadData":{"textHtml":"\u003Cp\u003EТо, что написано ниже, для многих квалифицированных C++ разработчиков будет прекрасно известной и очевидной вещью, но тем не менее, я периодически встречаю using namespace std; в коде различных проектов, а недавно в \u003Ca href=\"https:\u002F\u002Fhabr.com\u002Fru\u002Fpost\u002F579998\" rel=\"noopener noreferrer nofollow\"\u003Eнашумевшей статье про впечатления от высшего образования\u003C\u002Fa\u003E было упомянуто, что студентов так учат писать код в вузах, поэтому давайте повторим очевидное еще раз.\u003C\u002Fp\u003E\u003Cp\u003EИтак... многие слышали, что \u003Cstrong\u003Eusing namespace std;\u003C\u002Fstrong\u003E в C++ считается плохой практикой. Касательно недопустимости использования using namespace в header-файлах вопросов обычно не возникает, если мы хоть немного понимаем, как работает препроцессор компилятора: .hpp-файлы при использовании директивы #include вставляются в код \"как есть\", и соответственно using автоматически распространится на все затронутые  .hpp- и .cpp-файлы, если файл с ним был заинклюден хоть в одном звене цепочки (на одном из сайтов это метко обозвали как \"заболевание, передающеемя половым путем\"). Но вот про .cpp-файлы все не так очевидно, так что давайте еще раз разберем, что же именно здесь не так.\u003C\u002Fp\u003E","imageUrl":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F662\u002F8a9\u002Fe33\u002F6628a9e3322ab1dbca4e4976098da83d.jpg","buttonTextHtml":"Читать далее","image":{"url":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F662\u002F8a9\u002Fe33\u002F6628a9e3322ab1dbca4e4976098da83d.jpg","fit":"cover","positionY":0,"positionX":0}},"status":"published","plannedPublishTime":null,"checked":null,"tags":[{"titleHtml":"с++"},{"titleHtml":"namespace"},{"titleHtml":"namespaces"},{"titleHtml":"best practices"},{"titleHtml":"антипаттерны"}]},"580206":{"id":"580206","timePublished":"2021-09-27T12:51:03+00:00","isCorporative":false,"lang":"ru","titleHtml":"МТС отказался от скрытых мобильных подписок?","editorVersion":"2.0","postType":"article","postLabels":[],"author":{"id":"2467147","alias":"Plusodin","fullname":"Владимир","avatarUrl":"\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Favatars\u002F343\u002Fb77\u002Fd12\u002F343b77d12f047368849a9880276f936e.jpg","speciality":"Пользователь"},"statistics":{"commentsCount":11,"favoritesCount":4,"readingCount":5171,"score":14,"votesCount":14},"hubs":[{"relatedData":null,"id":"22008","alias":"cellular","type":"collective","title":"Сотовая связь","titleHtml":"Сотовая связь","isProfiled":false}],"flows":[{"id":"7","alias":"popsci","title":"Научпоп"}],"relatedData":null,"leadData":{"textHtml":"\u003Cp\u003EПривет, Хабр!\u003C\u002Fp\u003E\u003Cp\u003EНу что, подходит к концу первый сезон сериала «О скрытых мобильных подписках и операторах связи». Предыдущие три серии: \u003Ca href=\"https:\u002F\u002Fhabr.com\u002Fru\u002Fpost\u002F550448\u002F\" rel=\"noopener noreferrer nofollow\"\u003EМегафон\u003C\u002Fa\u003E, \u003Ca href=\"https:\u002F\u002Fhabr.com\u002Fru\u002Fpost\u002F563260\u002F\" rel=\"noopener noreferrer nofollow\"\u003EБилайн\u003C\u002Fa\u003E, \u003Ca href=\"https:\u002F\u002Fhabr.com\u002Fru\u002Fpost\u002F571256\u002F\" rel=\"noopener noreferrer nofollow\"\u003ETele2\u003C\u002Fa\u003E.\u003C\u002Fp\u003E\u003Cp\u003EНу и вишенка на этом торте – МТС.\u003C\u002Fp\u003E","imageUrl":null,"buttonTextHtml":"Читать далее","image":null},"status":"published","plannedPublishTime":null,"checked":null,"tags":[{"titleHtml":"мтс"},{"titleHtml":"мобильные подписки"},{"titleHtml":"подписки"},{"titleHtml":"оператор связи"},{"titleHtml":"теле2"},{"titleHtml":"мегафон"},{"titleHtml":"билайн"}]},"580208":{"id":"580208","timePublished":"2021-09-27T12:52:27+00:00","isCorporative":false,"lang":"ru","titleHtml":"Основная проблема образования","editorVersion":"2.0","postType":"article","postLabels":[{"type":"recovery","data":null}],"author":{"id":"2270142","alias":"Chronicler","fullname":"Пушиз де Хрониклер","avatarUrl":"\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Favatars\u002Faa3\u002F149\u002Fdb0\u002Faa3149db0de5f6c071dfade7285fcb99.jpg","speciality":"Исследователь ближнего заполярья, почетный манул"},"statistics":{"commentsCount":17,"favoritesCount":15,"readingCount":2547,"score":8,"votesCount":20},"hubs":[{"relatedData":null,"id":"359","alias":"programming","type":"collective","title":"Программирование","titleHtml":"Программирование","isProfiled":true},{"relatedData":null,"id":"17189","alias":"itstandarts","type":"collective","title":"IT-стандарты","titleHtml":"IT-стандарты","isProfiled":true},{"relatedData":null,"id":"20682","alias":"pm","type":"collective","title":"Управление проектами","titleHtml":"Управление проектами","isProfiled":true}],"flows":[{"id":"1","alias":"develop","title":"Разработка"},{"id":"3","alias":"management","title":"Менеджмент"}],"relatedData":null,"leadData":{"textHtml":"\u003Cp\u003EНа днях на Хабре появилась \u003Ca href=\"https:\u002F\u002Fhabr.com\u002Fru\u002Fpost\u002F579998\u002F\" rel=\"noopener noreferrer nofollow\"\u003Eкритическая статья\u003C\u002Fa\u003E о бакалавриате, что называется \"из первых уст\", от очередного первохода. Статья далеко не лишена смысла, однако главная проблема не была в ней затронута. А заключается она вовсе не в обилии посторонних дисциплин и даже не в том, что в учебных заведениях так мало разъясняют суровую конкретику жизни \"научиться штамповать JavaScript сайты за месяц\".  Да, эти проблемы присутствуют, наряду с плохой подготовкой педагогов и отношением к студентам, но не они на корню обесценивают нынешнее образование.\u003C\u002Fp\u003E","imageUrl":null,"buttonTextHtml":"Что же на самом деле не так?","image":null},"status":"published","plannedPublishTime":null,"checked":null,"tags":[{"titleHtml":"программирование"},{"titleHtml":"образование"},{"titleHtml":"курсы не нужны"},{"titleHtml":"вуз"}]},"580210":{"id":"580210","timePublished":"2021-09-27T12:53:02+00:00","isCorporative":false,"lang":"ru","titleHtml":"PHP Дайджест № 212 (13 – 27 сентября 2021)","editorVersion":"1.0","postType":"article","postLabels":[],"author":{"id":"100489","alias":"pronskiy","fullname":"Роман Пронский","avatarUrl":"\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Favatars\u002F27f\u002Fb99\u002Feb3\u002F27fb99eb3e30e3221c5839e88be02395.jpg","speciality":"PHP"},"statistics":{"commentsCount":1,"favoritesCount":14,"readingCount":3667,"score":41,"votesCount":41},"hubs":[{"relatedData":null,"id":"91","alias":"webdev","type":"collective","title":"Разработка веб-сайтов","titleHtml":"Разработка веб-сайтов","isProfiled":true},{"relatedData":null,"id":"260","alias":"php","type":"collective","title":"PHP","titleHtml":"PHP","isProfiled":true},{"relatedData":null,"id":"477","alias":"symfony","type":"collective","title":"Symfony","titleHtml":"Symfony","isProfiled":true},{"relatedData":null,"id":"9554","alias":"yii","type":"collective","title":"Yii","titleHtml":"Yii","isProfiled":true},{"relatedData":null,"id":"18812","alias":"laravel","type":"collective","title":"Laravel","titleHtml":"Laravel","isProfiled":true}],"flows":[{"id":"1","alias":"develop","title":"Разработка"}],"relatedData":null,"leadData":{"textHtml":"\u003Cdiv style=\"text-align:center;\"\u003E\u003Cimg src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fek\u002F6r\u002Fr1\u002Fek6rr1odvyzb89tfv0lq4cmfxi4.jpeg\"\u003E\u003C\u002Fdiv\u003E\u003Cbr\u003E\r\nПодборка свежих новостей и материалов из мира PHP.\u003Cbr\u003E\r\n\u003Cbr\u003E\r\nВышел PHP 8.1 RC2 и уже доступен первый пакет с использованием перечислений, будет сделан форк Magento, новый тип стандартов PER в дополнение к PSR, стартовала PhpStorm 2021.3 EAP, Symfony 6 будет полностью типизирован — как обновляться?\u003Cbr\u003E\r\n\u003Cbr\u003E\r\nДля PHP 8.2 предложены новые оптимизированные структуры данных.\u003Cbr\u003E\r\n\u003Cbr\u003E\r\nТакже в выпуске порция инструментов, полезные статьи, видео и анонсы двух митапов.\u003Cbr\u003E\r\n\u003Cbr\u003E\r\nПриятного чтения!\u003Cbr\u003E","imageUrl":null,"buttonTextHtml":"Читать дальше &rarr;","image":null},"status":"published","plannedPublishTime":null,"checked":null,"tags":[{"titleHtml":"дайджест"},{"titleHtml":"php-дайджест"},{"titleHtml":"PHP"},{"titleHtml":"Symfony"},{"titleHtml":"Laravel"},{"titleHtml":"Magento"},{"titleHtml":"PHPUnit"},{"titleHtml":"PHP 8.1"},{"titleHtml":"PHP 8.2"}]},"580228":{"id":"580228","timePublished":"2021-09-27T16:41:21+00:00","isCorporative":true,"lang":"ru","titleHtml":"Идеальная светодиодная лампа за 21 рубль","editorVersion":"1.0","postType":"article","postLabels":[],"author":{"id":"108988","alias":"AlexeyNadezhin","fullname":"Алексей Надежин","avatarUrl":"\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Favatars\u002Ffdc\u002F3ac\u002F9a2\u002Ffdc3ac9a2dc0107cc956f1bd0cf5fc2b.jpg","speciality":"Блогер"},"statistics":{"commentsCount":29,"favoritesCount":45,"readingCount":10885,"score":78,"votesCount":82},"hubs":[{"relatedData":null,"id":"21646","alias":"lamptest","type":"corporative","title":"Блог компании LampTest","titleHtml":"Блог компании LampTest","isProfiled":false},{"relatedData":null,"id":"21894","alias":"gadgets","type":"collective","title":"Гаджеты","titleHtml":"Гаджеты","isProfiled":false}],"flows":[{"id":"7","alias":"popsci","title":"Научпоп"}],"relatedData":null,"leadData":{"textHtml":"Удивительно осознавать, что достаточно сложное электронное устройство, которым является светодиодная лампочка, может стоить 21 рубль. \u003Cbr\u003E\r\n\u003Cbr\u003E\r\nЕщё сложнее поверить, что эта лампочка безукоризненна по всем параметрам.\u003Cbr\u003E\r\n\u003Cbr\u003E\r\n\u003Cdiv style=\"text-align:center;\"\u003E\u003Cimg src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fpost_images\u002F20f\u002F849\u002Ffcd\u002F20f849fcd6a3891f506676fc87223bdf.jpg\"\u003E\u003C\u002Fdiv\u003E","imageUrl":null,"buttonTextHtml":"Читать дальше &rarr;","image":null},"status":"published","plannedPublishTime":null,"checked":null,"tags":[{"titleHtml":"led"},{"titleHtml":"светодиодные лампы"},{"titleHtml":"тест"}]},"580304":{"id":"580304","timePublished":"2021-09-27T18:31:25+00:00","isCorporative":true,"lang":"ru","titleHtml":"Как сделать 248MP фотографию Солнца","editorVersion":"1.0","postType":"article","postLabels":[{"type":"translation","data":{"originalAuthorName":"Simon Tang","originalUrl":"https:\u002F\u002Fpetapixel.com\u002F2021\u002F09\u002F15\u002Fa-closer-look-how-i-created-a-248mp-photo-of-the-sun\u002F"}}],"author":{"id":"2192534","alias":"Itelma","fullname":"T-800","avatarUrl":"\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Favatars\u002Fc3a\u002Fd1e\u002F43d\u002Fc3ad1e43d500046c3228c9494b510912.jpg","speciality":"Пользователь"},"statistics":{"commentsCount":4,"favoritesCount":4,"readingCount":1446,"score":13,"votesCount":13},"hubs":[{"relatedData":null,"id":"22356","alias":"itelma","type":"corporative","title":"Блог компании НПП ИТЭЛМА","titleHtml":"Блог компании НПП ИТЭЛМА","isProfiled":false},{"relatedData":null,"id":"17175","alias":"image_processing","type":"collective","title":"Обработка изображений","titleHtml":"Обработка изображений","isProfiled":true},{"relatedData":null,"id":"21910","alias":"popular_science","type":"collective","title":"Научно-популярное","titleHtml":"Научно-популярное","isProfiled":false},{"relatedData":null,"id":"21932","alias":"photo","type":"collective","title":"Фототехника","titleHtml":"Фототехника","isProfiled":false},{"relatedData":null,"id":"22022","alias":"astronomy","type":"collective","title":"Астрономия","titleHtml":"Астрономия","isProfiled":false}],"flows":[{"id":"1","alias":"develop","title":"Разработка"},{"id":"7","alias":"popsci","title":"Научпоп"}],"relatedData":null,"leadData":{"textHtml":"\u003Cimg src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fpost_images\u002Fe02\u002F643\u002Fa55\u002Fe02643a550e20aa10c366e20956e4b40.jpg\" alt=\"image\"\u003E\u003Cbr\u003E\r\n\u003Cbr\u003E\r\n\u003Ci\u003EЭто изображение диска нашего Солнца создано с помощью большого рефракторного (линзового) телескопа и высокоскоростной монохромной CMOS-камеры.\u003C\u002Fi\u003E\u003Cbr\u003E\r\n\u003Cbr\u003E\r\nКаждый день над нашими головами висит большой шар света. Он там всегда, и никто не обращает на него внимания. Разумеется, мы не советуем вам долго смотреть на него и при этом ослепнуть, тем не менее, наука дала нам возможность смотреть прямо на солнце совершенно безопасно.\u003Cbr\u003E\r\n\u003Cbr\u003E\r\nПоскольку техника стала более доступной, обычный человек может заглянуть в многочисленные слои Солнца с помощью специального оборудования, которое может купить в любом хорошем магазине телескопов.\u003Cbr\u003E\r\n\u003Cbr\u003E\r\nВ этой статье мы подробно рассмотрим слой, известный как хромосфера: область Солнца, видимая в оранжево-красном спектре. При помощи специального фильтра это устройство блокирует весь нежелательный свет, пропуская при этом определенный диапазон частот, который нас интересует.\u003Cbr\u003E","imageUrl":null,"buttonTextHtml":"Читать дальше &rarr;","image":null},"status":"published","plannedPublishTime":null,"checked":null,"tags":[{"titleHtml":"обработка изображений"},{"titleHtml":"фототехника"}]},"580326":{"id":"580326","timePublished":"2021-09-27T22:44:08+00:00","isCorporative":false,"lang":"ru","titleHtml":"Почему инженеры презирают Agile","editorVersion":"2.0","postType":"article","postLabels":[{"type":"translation","data":{"originalAuthorName":"Stefan Wolpers","originalUrl":"https:\u002F\u002Fage-of-product.com\u002Fengineers-despise-agile\u002F"}}],"author":{"id":"2015227","alias":"kantocoder","fullname":null,"avatarUrl":"","speciality":"C++"},"statistics":{"commentsCount":21,"favoritesCount":3,"readingCount":1439,"score":8,"votesCount":16},"hubs":[{"relatedData":null,"id":"19583","alias":"dev_management","type":"collective","title":"Управление разработкой","titleHtml":"Управление разработкой","isProfiled":true},{"relatedData":null,"id":"20692","alias":"agile","type":"collective","title":"Agile","titleHtml":"Agile","isProfiled":true}],"flows":[{"id":"3","alias":"management","title":"Менеджмент"}],"relatedData":null,"leadData":{"textHtml":"\u003Cp\u003EМы продолжаем цикл публикаций о недостатках Аgile методологии.  Сегодня перевод статьи о том, почему инженеры презирают Agile (много новых удивительных наблюдений!)\u003C\u002Fp\u003E","imageUrl":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F34a\u002Ffbe\u002F0e8\u002F34afbe0e8166313ff883d59e59da0785.png","buttonTextHtml":"Читать далее","image":{"url":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F34a\u002Ffbe\u002F0e8\u002F34afbe0e8166313ff883d59e59da0785.png","fit":"cover","positionY":0,"positionX":0}},"status":"published","plannedPublishTime":null,"checked":null,"tags":[{"titleHtml":"agile development"},{"titleHtml":"микроменеджмент"},{"titleHtml":"agile"}]}},"articlesIds":{"ARTICLES_LIST_TOP_PERIOD_DAILY":["580060","580228","580124","580210","580150","579854","572164","580204","580172","580008","580206","580304","580194","580050","580196","580164","579772","580326","580208","580166"],"ARTICLES_LIST_BY_COMPANY_SCALAXY":["94076","91554","87312","87302","83353","82997","72283","66213","65788","65228"]},"isLoading":false,"pagesCount":{"ARTICLES_LIST_TOP_PERIOD_DAILY":3,"ARTICLES_LIST_BY_COMPANY_SCALAXY":1},"route":{"name":"ARTICLES_LIST_BY_COMPANY","params":{"name":"scalaxy"},"query":{}},"reasonsList":null,"view":"cards","lastVisitedRoute":{},"ssrCommentsArticleIds":[""],"karma":{}},"authorContribution":{"authors":{}},"betaTest":{"currentAnnouncement":null,"announcements":{},"announcementCards":null,"announcementComments":{},"announcementCommentThreads":{},"announcementCommentingStatuses":{},"archivedList":[]},"authorStatistics":{"articleRefs":{},"articleIds":{},"pagesCount":{},"route":{},"viewsCount":[],"maxStatsCount":{}},"comments":{"articleComments":{},"searchCommentsResults":null,"previewComment":null,"pagesCount":null,"commentAccess":{},"scrollParents":{},"pageArticleComments":{"lastViewedComment":0,"postId":null,"lastCommentTimestamp":"","moderated":[],"moderatedIds":[],"commentRoute":""}},"companies":{"companyRefs":{"scalaxy":{"alias":"scalaxy","imageUrl":"\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fcompanies\u002Ff40\u002F0aa\u002F5b2\u002Ff400aa5b20687ff8671097ec4f4016ed.png","titleHtml":"Оверсан-Скалакси","descriptionHtml":null,"relatedData":null,"statistics":{"postsCount":10,"newsCount":0,"vacanciesCount":0,"employeesCount":14,"careerRating":null,"subscribersCount":183,"rating":0,"invest":null},"foundationDate":{"year":"2008","month":"08","day":"08"},"location":{"city":null,"region":{"id":"1885","title":"Москва и Московская обл."},"country":{"id":"168","title":"Россия"}},"siteUrl":"http:\u002F\u002Fscalaxy.ru\u002F","staffNumber":"31–50 человек","registrationDate":"2009-07-01T13:43:57+00:00","representativeUser":null,"contacts":[],"settings":{"analyticsSettings":[],"branding":[],"status":"expired"},"metadata":{"titleHtml":"Оверсан-Скалакси, Россия -  с 8 августа 2008 г.","title":"Оверсан-Скалакси, Россия -  с 8 августа 2008 г.","keywords":[],"descriptionHtml":"10 статей от авторов компании Оверсан-Скалакси","description":"10 статей от авторов компании Оверсан-Скалакси"},"aDeskSettings":null,"careerAlias":null,"maxCustomTrackerLinks":0}},"companyIds":{},"companyTopIds":{},"pagesCount":{},"companyProfiles":{},"companiesCategories":[],"companiesCategoriesTotalCount":0,"companiesWidgets":{},"companiesWorkers":{},"companiesFans":{},"route":{},"isLoading":false,"companyWorkersLoading":false,"companyFansLoading":false,"vacancies":{}},"companiesContribution":{"hubs":{},"flows":{},"companyRefs":{}},"companyHubsContribution":{"contributionRefs":{"hubRefs":{},"hubIds":{}}},"conversation":{"messages":[],"respondent":null,"isLoadMore":false},"conversations":{"conversations":[],"unreadCount":0,"pagesCount":0,"isLoadMore":false},"desktopState":{"desktopFl":null,"desktopHl":null,"isChecked":false,"isLoginDemanded":false},"dfp":{"slotsDict":{}},"docs":{"menu":{},"articles":{},"mainMenu":[],"loading":{"main":false,"dropdown":false,"article":false}},"feature":{"isProbablyVisible":"true"},"flows":{"flows":[{"alias":"develop","id":1,"route":{"name":"FLOW_PAGE","params":{"flowName":"develop"}}},{"alias":"admin","id":6,"route":{"name":"FLOW_PAGE","params":{"flowName":"admin"}}},{"alias":"design","id":2,"route":{"name":"FLOW_PAGE","params":{"flowName":"design"}}},{"alias":"management","id":3,"route":{"name":"FLOW_PAGE","params":{"flowName":"management"}}},{"alias":"marketing","id":4,"route":{"name":"FLOW_PAGE","params":{"flowName":"marketing"}}},{"alias":"popsci","id":7,"route":{"name":"FLOW_PAGE","params":{"flowName":"popsci"}}}]},"global":{"isPwa":false,"device":"desktop","isHabrCom":true},"hubs":{"hubRefs":{},"hubIds":{},"pagesCount":{},"isLoading":false,"route":{}},"hubsBlock":{"hubRefs":{},"hubIds":{}},"i18n":{"fl":"ru","hl":"ru"},"info":{"infoPage":{},"isLoading":true},"location":{"urlStruct":{"protocol":null,"slashes":null,"auth":null,"host":null,"port":null,"hostname":null,"hash":null,"search":null,"query":{},"pathname":null,"path":null,"href":""},"searchQuery":null},"me":{"user":null,"ppgDemanded":false,"karmaResetInfo":{"canReincarnate":null,"wasReincarnated":null,"currentScore":null},"notes":null},"mostReadingList":{"mostReadingListIds":[],"mostReadingListRefs":null,"promoPost":null},"pinnedPost":{"pinnedPost":null},"ppa":{"articles":{},"card":null,"transactions":null,"totalTransactions":null,"isAccessible":null},"projectsBlocks":{"activeBlocks":{}},"pullRefresh":{"shouldRefresh":false},"sandbox":{"articleIds":[],"articleRefs":{},"pagesCount":null,"route":{},"lastVisitedRoute":{},"isLoading":false},"settingsOther":{"inputs":{"uiLang":{"errors":[],"ref":null,"value":""},"articlesLangEnglish":{"errors":[],"ref":null,"value":false},"articlesLangRussian":{"errors":[],"ref":null,"value":false},"agreement":{"errors":[],"ref":null,"value":false},"email":{"errors":[],"ref":null,"value":true},"digest":{"errors":[],"ref":null,"value":true}}},"similarList":{"similarListIds":["82997","65228"],"similarListRefs":{"65228":{"id":"65228","timePublished":"2009-07-23T12:58:52+00:00","isCorporative":true,"lang":"ru","titleHtml":"Cloud computing: кто и как летает в облаках?","editorVersion":"1.0","postType":"article","postLabels":[],"author":{"id":"48925","alias":"ommo","fullname":null,"avatarUrl":null,"speciality":null},"statistics":{"commentsCount":66,"favoritesCount":51,"readingCount":23661,"score":34,"votesCount":52},"hubs":[{"id":"10685","alias":"scalaxy","type":"corporative","title":"Блог компании Оверсан-Скалакси","titleHtml":"Блог компании Оверсан-Скалакси","isProfiled":false}],"flows":[],"relatedData":null,"leadData":{"textHtml":"Сегодня «облачными» вычислениями не удивишь никого: они везде и повсюду. А в условиях мирового финансового кризиса многие крупные компании, изначально не обращающие внимания на «облачные» сервисы и услуги, резко перенаправили свои денежные потоки именно туда, осознав давние ошибки и просчеты. В этой статье я не буду рассказывать Вам все о cloud computing’e — это мы сделаем как-нибудь в другой раз. Наша цель — рассказать об обстановке в мире, т.е. рассмотреть вопросы, по типу «кто есть who» в мире «облачных» вычислений.\u003Cbr\u002F\u003E\r\n","imageUrl":null,"buttonTextHtml":"Читать дальше &rarr;","image":null},"status":"published","plannedPublishTime":null,"checked":null},"82997":{"id":"82997","timePublished":"2010-02-03T14:01:20+00:00","isCorporative":true,"lang":"ru","titleHtml":"GPFS. Часть 1. Создание GPFS кластера","editorVersion":"1.0","postType":"article","postLabels":[],"author":{"id":"38942","alias":"SaveTheRbtz","fullname":"Алексей","avatarUrl":"\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Favatars\u002Fb37\u002F3dd\u002Fc4b\u002Fb373ddc4b2783a8cbe583cd7eeece149.jpg","speciality":"SRE"},"statistics":{"commentsCount":27,"favoritesCount":54,"readingCount":21752,"score":34,"votesCount":54},"hubs":[{"id":"10685","alias":"scalaxy","type":"corporative","title":"Блог компании Оверсан-Скалакси","titleHtml":"Блог компании Оверсан-Скалакси","isProfiled":false}],"flows":[],"relatedData":null,"leadData":{"textHtml":"\u003Cimg align=\"left\" src=\"http:\u002F\u002Fs40.radikal.ru\u002Fi090\u002F1002\u002F06\u002F267a5c95ad0d.gif\" alt=\"GPFS (General Parallel File System)\" width=\"130\"\u002F\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nПосле одной из моих последних статьей на хабре \u003Ca href=\"http:\u002F\u002Fhabrahabr.ru\u002Fblogs\u002Fserver_side_optimization\u002F70167\u002F\" title=\"серверная оптимизация\"\u003Eпро серверную оптимизацию\u003C\u002Fa\u003E мне прислали множество вопросов про распределенные файловые системы. И теперь я нашел в себе силы и возможности написать про замечательную кластерную файловую систему \u003Cb\u003EGPFS\u003C\u002Fb\u003E.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nОписание тестовой лаборатории:\u003Cbr\u002F\u003E\r\n\u003Cul\u003E\r\n\u003Cli\u003EСервер виртуализации Xen. Dom0 под SLES11\u003C\u002Fli\u003E\r\n\u003Cli\u003E3 Xen DomU виртуальных сервера под quorum-ноды с двумя дополнительно проброшенными блочными устройствами\u003C\u002Fli\u003E\r\n\u003Cli\u003E2 Xen DomU виртуальных сервера под client-ноды\u003C\u002Fli\u003E\r\n\u003C\u002Ful\u003E\u003Cbr\u002F\u003E\r\nТестовый стенд, основанный на технологии Xen, крайне удобен, ибо позволяет на ходу подцеплять\u002Fотцеплять диски от виртуалок, добавлять в них память и процессоры.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n","imageUrl":null,"buttonTextHtml":"Подробнее в примерах","image":null},"status":"published","plannedPublishTime":null,"checked":null}}},"ssr":{"error":null,"isDataLoaded":false,"isDataLoading":false,"isHydrationFailed":false,"isServer":false},"userHubsContribution":{"contributionRefs":{"hubRefs":{},"hubIds":{}}},"userInvites":{"availableInvites":0,"usedInvitesIds":[],"usedInvitesRefs":{},"usedInvitesPagesCount":0,"unusedInvitesIds":[],"unusedInvitesRefs":{},"unusedInvitesPagesCount":0},"users":{"authorRefs":{"savetherbtz":{"scoreStats":{"score":452.1,"votesCount":638},"rating":0.1,"relatedData":null,"contacts":[],"authorContacts":[],"paymentDetails":{"paymentYandexMoney":null,"paymentPayPalMe":null,"paymentWebmoney":null},"id":"38942","alias":"SaveTheRbtz","fullname":"Алексей","avatarUrl":"\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Favatars\u002Fb37\u002F3dd\u002Fc4b\u002Fb373ddc4b2783a8cbe583cd7eeece149.jpg","speciality":"SRE"}},"authorIds":{},"pagesCount":{},"authorProfiles":{},"userHubs":{},"userInvitations":{},"authorFollowers":{},"authorFollowed":{},"karmaStats":[],"statistics":null,"isLoading":false,"authorFollowersLoading":false,"authorFollowedLoading":false,"userHubsLoading":false,"userInvitationsLoading":false,"route":{}},"viewport":{"prevScrollY":{},"scrollY":0,"width":0},"tracker":{"items":{},"pagesCache":{},"markedViewedSilently":{},"markedRead":{},"unreadCounters":{"applications":null,"system":null,"mentions":null,"subscribers":null,"posts_and_comments":null},"unviewedCounters":{"applications":null,"system":null,"mentions":null,"subscribers":null,"posts_and_comments":null}}};(function(){var s;(s=document.currentScript||document.scripts[document.scripts.length-1]).parentNode.removeChild(s);}());</script>
<script src="https://assets.habr.com/habr-web/js/chunk-vendors.670ab961.js" defer></script><script src="https://assets.habr.com/habr-web/js/chunk-f458c7c4.6e221df6.js" defer></script><script src="https://assets.habr.com/habr-web/js/page-article.edfb668d.js" defer></script><script src="https://assets.habr.com/habr-web/js/app.76acc47b.js" defer></script>



    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    </script>
  
  <script type="text/javascript" >
    (function(m,e,t,r,i,k,a){m[i]=m[i]||function(){(m[i].a=m[i].a||[]).push(arguments)};
    m[i].l=1*new Date();k=e.createElement(t),a=e.getElementsByTagName(t)[0],k.async=1,k.src=r,a.parentNode.insertBefore(k,a)})
    (window, document, "script", "https://mc.yandex.ru/metrika/tag.js", "ym");

    ym(24049213, "init", {
      defer:true,
      trackLinks:true,
      accurateTrackBounce:true,
      webvisor:false,
    });
  </script>
  <noscript>
    <div>
      <img src="https://mc.yandex.ru/watch/24049213" style="position:absolute; left:-9999px;" alt="" />
    </div>
  </noscript>
  
    <script type="text/javascript">
      window.addEventListener('load', function () {
        setTimeout(() => {
          const img = new Image();
          img.src = 'https://vk.com/rtrg?p=VK-RTRG-421343-57vKE';
        }, 0);
      });
    </script>
  
</body>
</html>
